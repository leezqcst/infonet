random_seed: 42
experiment_dir: /Users/thomaseffland/Development/infonet/experiments/

preprocess:
  count: 0
  splits_dir: /Users/thomaseffland/Development/infonet/data/ACE 2005/splits/
  data_dir: /Users/thomaseffland/Development/infonet/data/ACE 2005/yaat/
  map_func_name: E_BIO_map
  train_vocab_only: &EMBED_BACKPROP False
  oversample_unks: True

train:
  n_epoch: 50
  batch_size: 400
  patience: 20

optimizer:
  type: Adam
  learning_rate: .01
  weight_decay: 0.0
  grad_clip: 10.

tagger:
  word_vector_size: /Users/thomaseffland/Development/infonet/data/word_vectors/glove.6B.200d.txt
  backprop_to_words: *EMBED_BACKPROP
  word_dropout: .5
  pos_vector_size: 0
  pos_dropout: .25
  gru_state_sizes: [ 100 ]  # more than one creates stacked grus
  bidirectional: True
  gru_dropouts: [ .5 ]      # dropouts on outputs of gru
  gru_hdropouts: [ .5 ]     # horizontal dropouts on gru (overrides gru_dropouts if > 0)
  mlp_sizes: [ 100 ]            # hidden layer sizes
  mlp_activations: [ leaky_relu ]      # eg, sigmoid or leaky_relu
  mlp_dropouts: [.5 ]         # dropout for mlp layers
  crf_type: bilinear        # choose from [None, simple, linear, simple_bilinear, bilinear]
