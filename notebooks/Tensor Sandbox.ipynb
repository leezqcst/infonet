{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing around with the functional ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.map_fn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "def double(v):\n",
    "    return 2 * v\n",
    "\n",
    "a = tf.Variable([[1,1],[2,2],[3,3],[4,4]])\n",
    "f = tf.map_fn(double, a)\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "print sess.run(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a sparse cross entropy that works on unknown batch size and seq len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sparse_xent((logits, labels)):\n",
    "    return tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels)\n",
    "\n",
    "# shape will be [n_time, n_batch, n_class]\n",
    "# with 2 timesteps, 3 sequences in the batch, and 2 classes (for brevity)\n",
    "logits = tf.Variable([[[.4, .6], [.7, .3], [.1, .9]],\n",
    "           [[.6, .4], [.3, .7], [.8, .2]],])\n",
    "labels = tf.Variable([[1, 0, 1], [0, 1, 0]])\n",
    "xent = tf.map_fn(sparse_xent, (logits, labels), dtype=tf.float32, back_prop=True)\n",
    "loss = tf.reduce_mean(xent)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "print sess.run(xent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tf.Variable(1e50, trainable=False, name=\"best_valid_loss\")\n",
    "sess.run(a.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(a.assign(1))\n",
    "a.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Playing around with `while_loop`, `TensorArray`, and `scatter` to build a function that extracts an entity mention tensor from the sequence label tensor\n",
    "\n",
    "The output of the sequence tagging layer encodes the boundaries of the entity mentions.  In a batch, there may be hugely different number of mentions per sequence.\n",
    "\n",
    "To predict relations between mentions, we need to know what the extracted mentions are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to extract the mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init\n",
      "(2,)\n",
      "(2,)\n",
      "Done\n",
      "Running\n",
      "Done\n",
      "[[0 1 2 0 1 2 2 0]\n",
      " [1 2 0 1 0 1 0 1]]\n",
      "[[ 1  4 -1 -1]\n",
      " [ 0  3  5  7]]\n",
      "[[ 3  7 -1 -1]\n",
      " [ 2  4  6  8]]\n"
     ]
    }
   ],
   "source": [
    "# create fake sequences over a 'batch'\n",
    "# sequences are \n",
    "# [ O B I O B I I O ]\n",
    "# [ B I O O O B O B ]\n",
    "fake_tagged_seqs = np.array([[0,1,2,0,1,2,2,0],\n",
    "                             [1,2,0,1,0,1,0,1]])\n",
    "\n",
    "def extract_mentions(seqs, outside_token):\n",
    "    \"\"\" Iterate over a batch of sequences, extracting the mentions encoded in them.\n",
    "    \n",
    "    Args:\n",
    "      seqs: Tensor with shape [batch_size, max_timesteps]\n",
    "      \n",
    "    Returns:\n",
    "      mentions: Tensor with shape [batch_size, max_extracted_mentions, 3].\n",
    "        This tensor is padded to the max number of extracted mentions.\n",
    "        The final dimension `3` encodes mention metadata where:\n",
    "          0: mention left boundary index `i`\n",
    "          1: mention right boundary index `j` (inclusive)\n",
    "          2: mention group\n",
    "      mentions_mask: Tensor with shape [batch_size, max_extracted_mentions].\n",
    "        This tensor encodes the `pad` locations of the mentions tensor.\n",
    "        \n",
    "    Example (pseudocode):\n",
    "      # fake sequences [ O B I O B I I O ]\n",
    "      #                [ B I O O O B O B ]\n",
    "      fake_tagged_seqs = np.array([[0,1,2,0,1,2,2,0],\n",
    "                             [1,2,0,1,0,1,0,1]])\n",
    "                             \n",
    "      mentions = extract_mentions(seqs, outside_token) \n",
    "      print mentions[:,:,0] # starting boundaries\n",
    "      >>> [[ 1  4 -1 -1]\n",
    "           [ 0  3  5  7]]\n",
    "      print mentions[:,:,1] # end boundaries (inclusive)\n",
    "      >>> [[ 2  6 -1 -1]\n",
    "           [ 1  3  5  7]]\n",
    "            \n",
    "    \"\"\" \n",
    "    def _sparse_update(update_mask, stitch_range, update_range, old_values, new_values):\n",
    "        \"\"\" Return as sparsely updated tensor according to the mask.\n",
    "        \n",
    "        This allows for scattered updates to a `Tensor` (not just a `Variable`)\n",
    "        by using dynamic stitch to overwrite values\"\"\"\n",
    "        update_indices = tf.boolean_mask(update_range, update_mask)\n",
    "        update_values = tf.boolean_mask(new_values, update_mask)\n",
    "        return tf.dynamic_stitch([stitch_range, update_indices],\n",
    "                                 [old_values, update_values])\n",
    "    \n",
    "    begin_tokens = tf.constant([[1]])\n",
    "    outside_tokens = tf.constant([[0]])\n",
    "    outside_token = tf.constant(0)\n",
    "    def _start_mention(tags):\n",
    "        start_mention = tf.reduce_any(tf.equal(tags, begin_tokens), \n",
    "                                      reduction_indices=[0])\n",
    "        start_mention.set_shape((None,))\n",
    "        return start_mention\n",
    "    \n",
    "    def _in_mention(tags):\n",
    "#         in_mention = tf.reduce_any(tf.not_equal(tags, outside_tokens),\n",
    "#                                    reduction_indices=[0])\n",
    "        in_mention = tf.not_equal(tags, outside_token)\n",
    "        print in_mention.get_shape()\n",
    "#         in_mention.set_shape((batch_size,))\n",
    "        return in_mention\n",
    "    \n",
    "    def _end_current_mention(in_mention, already_in_mention):\n",
    "        end_current_mention = tf.logical_and(tf.logical_not(in_mention), already_in_mention)\n",
    "        end_current_mention.set_shape((None,))\n",
    "        return end_current_mention\n",
    "        \n",
    "    # first figure out the maximum number of mentions\n",
    "    def _count_only_step(time, seqs_ta, batch_range, mention_counts, already_in_mention):\n",
    "        \"\"\" Update mentions_count using the mention detection update rules. \n",
    "        \n",
    "        This is done by marking if we are starting at a mention\n",
    "        and then adding to the count to sequences in the batch \n",
    "        where we detect the end of a mention.\n",
    "        \n",
    "        This is done by stitching in the updates to overwrite the current\n",
    "        values.  \n",
    "        \n",
    "        NOTE: Overwriting dynammic stitch may seem weird\n",
    "          but it's due to some scatter/while_loop idiosyncrasies of tf\n",
    "          (this finally works after my 4th implementation attempt)\n",
    "        \"\"\"\n",
    "        tags = seqs_ta.read(time)\n",
    "        in_mention = _in_mention(tags)\n",
    "        end_current_mention = _end_current_mention(in_mention, already_in_mention)\n",
    "        mention_counts = _sparse_update(end_current_mention,\n",
    "                                        batch_range, batch_range,\n",
    "                                        mention_counts, mention_counts+1)\n",
    "        already_in_mention = in_mention\n",
    "        return time+1, seqs_ta, batch_range, mention_counts, already_in_mention\n",
    "\n",
    "        \n",
    "#         in_mention = tf.not_equal(tags, outside_token)\n",
    "#         end_current_mention = tf.logical_and(tf.logical_not(in_mention), already_in_mention)\n",
    "#         end_current_mention.set_shape((None,))\n",
    "#         update_indices = tf.boolean_mask(batch_range, end_current_mention)\n",
    "#         update_values = tf.boolean_mask(mention_counts+1, end_current_mention)\n",
    "#         mention_counts = tf.dynamic_stitch([batch_range, update_indices],\n",
    "#                                            [mention_counts, update_values])\n",
    "#         already_in_mention = in_mention\n",
    "#         return time+1, seqs_ta, batch_range, mention_counts, already_in_mention\n",
    "    \n",
    "    # fill in empty bookkeeping tensors that encode the mentions\n",
    "    def _extraction_step(time, \n",
    "                         seqs_ta,\n",
    "                         outside_token,\n",
    "                         linear_range,\n",
    "                         linear_index,\n",
    "                         batch_range,\n",
    "                         mention_starts,\n",
    "                         mention_ends,\n",
    "                         mention_counts, \n",
    "                         already_in_mention):\n",
    "        \"\"\" Extract mention boundaries at this timestep.\n",
    "        \n",
    "        Args:\n",
    "          time: the current timestep in the batch of sequences\n",
    "          seqs_ta: the batch of sequences\n",
    "          mention_starts: the Tensor holding the start boundaries \n",
    "            of the extracted mentions so far\n",
    "          mention_ends: the Tensor holding the end boundaries \n",
    "            of the extracted mentions so far\n",
    "          mention_counts: the current number of mentions found\n",
    "            for a single sequence in the batch.  This is used to \n",
    "            dynamically scatter extracted mentions into the `mentions`\n",
    "            TensorArray so that it can be abstracted away from the \n",
    "            underlying sequence.\n",
    "          in_mentions: whether or not the sequence is in a mention or not.\n",
    "            As we scan, we extract mentions by looking for contiguous groups\n",
    "            of non-'Outside' tags.  \n",
    "            This way we can extract multi-token mentions into single elements.\n",
    "        \"\"\"\n",
    "        # get the sequence tags at the current timestep\n",
    "        tags = seqs_ta.read(time)\n",
    "        \n",
    "        # decide if they are in mention or not\n",
    "        in_mention = _in_mention(tags)\n",
    "        \n",
    "        ### IF they are a mention but weren't before, start a new mention\n",
    "        # do this by applying scattered updates (via dynamic_stitch) \n",
    "        # to the masked, linearly indexed locations of new mentions, \n",
    "        # where the updated values are the current timestep\n",
    "        # eg, the location in the sequence where this mention is being started\n",
    "        boundary = time * tf.ones_like(tags, dtype=tf.int32) \n",
    "        offsets = mention_counts + linear_index \n",
    "        start_new_mention = _start_mention(tags)\n",
    "        mention_starts = _sparse_update(start_new_mention,\n",
    "                                        linear_range, offsets,\n",
    "                                        mention_starts, boundary)\n",
    "#         start_new_mention = tf.logical_and(in_mention, tf.logical_not(already_in_mention))\n",
    "#         start_new_mention.set_shape((None,))\n",
    "#         update_indices = tf.boolean_mask(offsets, start_new_mention)\n",
    "#         update_values = tf.boolean_mask(boundary, start_new_mention)\n",
    "#         mention_starts = tf.dynamic_stitch([linear_range, update_indices],\n",
    "#                                            [mention_starts, update_values])\n",
    "        \n",
    "        ### IF they aren't but were before, end the mention at t-1\n",
    "        # first, compute the potential new end boundary for all mentions\n",
    "        # this will be the previous timestep\n",
    "        # and also increment the count if we finished the mention\n",
    "#         boundary = boundary - 1\n",
    "        end_current_mention = _end_current_mention(in_mention, already_in_mention)\n",
    "#         end_current_mention = tf.logical_and(tf.logical_not(in_mention), already_in_mention)\n",
    "#         end_current_mention.set_shape((None,))\n",
    "        mention_ends = _sparse_update(end_current_mention,\n",
    "                                      linear_range, offsets,\n",
    "                                      mention_ends, boundary)\n",
    "#         update_indices = tf.boolean_mask(offsets, end_current_mention)\n",
    "#         update_values = tf.boolean_mask(boundary, end_current_mention)\n",
    "#         mention_ends = tf.dynamic_stitch([linear_range, update_indices],\n",
    "#                                            [mention_ends, update_values]\n",
    "\n",
    "        # update mention counts where we've ended an extraction (same as `_count_step()`)\n",
    "        mention_counts = _sparse_update(end_current_mention,\n",
    "                                        batch_range, batch_range,\n",
    "                                        mention_counts, mention_counts+1)\n",
    "#         update_indices = tf.boolean_mask(batch_range, end_current_mention)\n",
    "#         update_values = tf.boolean_mask(mention_counts+1, end_current_mention)\n",
    "#         mention_counts = tf.dynamic_stitch([batch_range, update_indices],\n",
    "#                                            [mention_counts, update_values])\n",
    "        \n",
    "        already_in_mention = in_mention\n",
    "        \n",
    "        return (time + 1, \n",
    "                seqs_ta,\n",
    "                outside_token,\n",
    "                linear_range,\n",
    "                linear_index,\n",
    "                batch_range,\n",
    "                mention_starts, \n",
    "                mention_ends,\n",
    "                mention_counts, \n",
    "                already_in_mention)\n",
    "    \n",
    "    # convert the sequences\n",
    "    seqs_shape = tf.shape(seqs)\n",
    "    batch_size = seqs_shape[0]\n",
    "    time_steps = seqs_shape[1]\n",
    "    \n",
    "    # `TensorArray`'s read in time-major, so transpose\n",
    "    seqs_ta = tf.TensorArray(dtype=seqs.dtype, size=time_steps, clear_after_read=False)\n",
    "    seqs_ta = seqs_ta.unpack(tf.transpose(seqs, [1,0]))\n",
    "    \n",
    "    # bookkeeping tensors\n",
    "    time = tf.constant(0, dtype=tf.int32)\n",
    "    batch_range = tf.range(batch_size)\n",
    "    mention_counts = tf.zeros(dtype=tf.int32, shape=(batch_size,))\n",
    "    already_in_mention = tf.cast(mention_counts, tf.bool)\n",
    "        \n",
    "    # find the maximum number of mentions in batch\n",
    "    (_, _, _,mention_counts, already_in_mention) = tf.while_loop(cond=lambda time, *_: time < time_steps,\n",
    "                                                            body=_count_only_step,\n",
    "                                                            loop_vars=(time, \n",
    "                                                                       seqs_ta, \n",
    "                                                                       batch_range,\n",
    "                                                                       mention_counts, \n",
    "                                                                       already_in_mention))\n",
    "    # add 1 to counts where we never detected the end\n",
    "    already_in_mention.set_shape((None,))\n",
    "    mention_counts = _sparse_update(already_in_mention,\n",
    "                                    batch_range, batch_range,\n",
    "                                    mention_counts, mention_counts+1)\n",
    "#     already_in_mention.set_shape((None,))\n",
    "#     update_indices = tf.boolean_mask(batch_range, already_in_mention)\n",
    "#     update_values = tf.boolean_mask(mention_counts+1, already_in_mention)\n",
    "#     mention_counts = tf.dynamic_stitch([batch_range, update_indices],\n",
    "#                                        [mention_counts, update_values])\n",
    "    \n",
    "    # now create the tensors we will extract mention data into\n",
    "    max_num_mentions = tf.reduce_max(mention_counts)\n",
    "    \n",
    "    # create a linearized version of the mention statistics we'll gather\n",
    "    # it'll be padded with -1's (can't use 0 as its a valid index)\n",
    "    mention_starts = -1*tf.ones(shape=(batch_size * max_num_mentions,), dtype=tf.int32)\n",
    "    mention_ends = -1*tf.ones(shape=(batch_size * max_num_mentions,), dtype=tf.int32)\n",
    "    \n",
    "    # we also need a full linear range and a liear index into the mention_stats\n",
    "    # tensors so we can dynamically overwrite the values\n",
    "    linear_range = tf.range(batch_size * max_num_mentions)\n",
    "    linear_index = max_num_mentions * tf.range(batch_size)\n",
    "    \n",
    "    # reset the bookkeeping tensors\n",
    "    time = tf.constant(0, dtype=tf.int32)\n",
    "    mention_counts = tf.zeros(dtype=tf.int32, shape=(batch_size,))\n",
    "    already_in_mention = tf.cast(mention_counts, tf.bool)\n",
    "    \n",
    "    # extract the mentions\n",
    "    (time, _, _, _, _, _,\n",
    "     mention_starts, \n",
    "     mention_ends,\n",
    "     mention_counts, \n",
    "     already_in_mention) = tf.while_loop(cond=lambda time, *_: time < time_steps,\n",
    "                                         body=_extraction_step,\n",
    "                                         loop_vars= (time, \n",
    "                                                     seqs_ta,\n",
    "                                                     outside_token,\n",
    "                                                     linear_range,\n",
    "                                                     linear_index,\n",
    "                                                     batch_range,\n",
    "                                                     mention_starts, \n",
    "                                                     mention_ends,\n",
    "                                                     mention_counts, \n",
    "                                                     already_in_mention))\n",
    "    # if we ended on a mention, we need to compute final endpoints\n",
    "    already_in_mention.set_shape((None,))\n",
    "    boundary = time * tf.ones_like(mention_counts, dtype=tf.int32) \n",
    "    offsets = mention_counts + linear_index\n",
    "    mention_ends = _sparse_update(already_in_mention,\n",
    "                                  linear_range, offsets,\n",
    "                                  mention_ends, boundary)\n",
    "#     update_indices = tf.boolean_mask(offsets, already_in_mention)\n",
    "#     update_values = tf.boolean_mask(boundary, already_in_mention)\n",
    "#     mention_ends = tf.dynamic_stitch([linear_range, update_indices],\n",
    "#                                      [mention_ends, update_values])\n",
    "    mention_counts = _sparse_update(already_in_mention,\n",
    "                                    batch_range, batch_range,\n",
    "                                    mention_counts, mention_counts+1)\n",
    "#     update_indices = tf.boolean_mask(batch_range, already_in_mention)\n",
    "#     update_values = tf.boolean_mask(mention_counts+1, already_in_mention)\n",
    "#     mention_counts = tf.dynamic_stitch([batch_range, update_indices],\n",
    "#                                        [mention_counts, update_values])\n",
    "    \n",
    "    # finally concat and reshape extraction stats\n",
    "    mention_starts = tf.reshape(mention_starts, (batch_size, max_num_mentions, 1))\n",
    "    mention_ends = tf.reshape(mention_ends, (batch_size, max_num_mentions, 1))\n",
    "    mentions = tf.concat(2, [mention_starts, mention_ends])\n",
    "    return mentions\n",
    "        \n",
    "\n",
    "tf.reset_default_graph()\n",
    "seqs = tf.Variable(fake_tagged_seqs, dtype=tf.int32)\n",
    "outside_token = tf.constant(0, dtype=tf.int32, name='Outside_Mention_Token')\n",
    "\n",
    "batch_size = tf.shape(seqs)[0]\n",
    "max_num_mentions = tf.constant(5)\n",
    "\n",
    "r = tf.range(0, batch_size) * max_num_mentions\n",
    "\n",
    "a = tf.Variable([1,2,3,4], validate_shape=False, trainable=False)\n",
    "z = tf.constant([True, False, False, True])\n",
    "r = tf.range(4)\n",
    "scatter_idxs = tf.boolean_mask(r, z)\n",
    "scatter_vals = tf.Variable([0,0])\n",
    "\n",
    "b = tf.dynamic_stitch([r, scatter_idxs], [a, scatter_vals])\n",
    "\n",
    "# c = tf.select(z, a, b)\n",
    "# c = tf.scatter_update(b, tf.Variable([1,2]), tf.Variable([5,3]))\n",
    "\n",
    "# a = tf.Variable([0,1])\n",
    "z = tf.constant(2)\n",
    "z.set_shape(None)\n",
    "# b = tf.tile(a, [z])\n",
    "\n",
    "c = tf.constant(0)\n",
    "d = c + 1\n",
    "\"\"\"\n",
    "New way to do the mention extraction:\n",
    "1. Run through once, only updating mention counts\n",
    "   to dynamically compute the max number of mentions and lengths\n",
    "2. Create a linearly indexed zero filled tensor with total shape [batch_size x max_num_mentions]\n",
    "   for each piece of metadata\n",
    "3. Selectively update the linear index tensor with mention extractions\n",
    "4. Finally reshape and stitch tensors together\n",
    "\"\"\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print \"Init\"\n",
    "    mentions = extract_mentions(seqs, outside_token)\n",
    "    \n",
    "#     writer = tf.train.SummaryWriter(\".\", sess.graph)\n",
    "    tf.initialize_all_variables().run()\n",
    "#     writer.flush()\n",
    "#     writer.close()\n",
    "    print \"Done\"\n",
    "#     print c.eval()\n",
    "#     print d.eval()\n",
    "    print \"Running\"\n",
    "    m = mentions.eval()\n",
    "    print \"Done\"\n",
    "    print fake_tagged_seqs\n",
    "    print m[:,:,0]\n",
    "    print m[:,:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funtion to extract the entire graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init\n",
      "Done\n",
      "Running\n",
      "Done\n",
      "Input tags\n",
      "[[0 1 2 0 1 2 1 0]\n",
      " [1 2 0 1 0 1 0 1]]\n",
      "Extracted Mentions\n",
      "[0 1]\n",
      "[3 4]\n",
      "[[[ 1  3]\n",
      "  [ 4  6]\n",
      "  [ 6  7]\n",
      "  [-1 -1]]\n",
      "\n",
      " [[ 0  2]\n",
      "  [ 3  4]\n",
      "  [ 5  6]\n",
      "  [ 7  8]]]\n"
     ]
    }
   ],
   "source": [
    "def extract_mentions(seqs):#, features):\n",
    "    \"\"\" Iterate over a batch of sequences, extracting the mentions encoded in them.\n",
    "    \n",
    "    Args:\n",
    "      seqs: Tensor with shape [batch_size, max_timesteps]\n",
    "      \n",
    "    Returns:\n",
    "      mentions: Tensor with shape [batch_size, max_extracted_mentions, 3].\n",
    "        This tensor is padded to the max number of extracted mentions.\n",
    "        The final dimension `3` encodes mention metadata where:\n",
    "          0: mention left boundary index `i`\n",
    "          1: mention right boundary index `j` (inclusive)\n",
    "          2: mention group\n",
    "      mentions_mask: Tensor with shape [batch_size, max_extracted_mentions].\n",
    "        This tensor encodes the `pad` locations of the mentions tensor.\n",
    "        \n",
    "    Example (pseudocode):\n",
    "      # fake sequences [ O B I O B I I O ]\n",
    "      #                [ B I O O O B O B ]\n",
    "      fake_tagged_seqs = np.array([[0,1,2,0,1,2,2,0],\n",
    "                             [1,2,0,1,0,1,0,1]])\n",
    "                             \n",
    "      mentions = extract_mentions(seqs, outside_token) \n",
    "      print mentions[:,:,0] # starting boundaries\n",
    "      >>> [[ 1  4 -1 -1]\n",
    "           [ 0  3  5  7]]\n",
    "      print mentions[:,:,1] # end boundaries (inclusive)\n",
    "      >>> [[ 2  6 -1 -1]\n",
    "           [ 1  3  5  7]]\n",
    "            \n",
    "    \"\"\" \n",
    "    def _sparse_update(update_mask, stitch_range, update_range, old_values, new_values):\n",
    "        \"\"\" Return as sparsely updated tensor according to the mask.\n",
    "        \n",
    "        This allows for scattered updates to a `Tensor` (not just a `Variable`)\n",
    "        by using dynamic stitch to overwrite values\"\"\"\n",
    "        update_indices = tf.boolean_mask(update_range, update_mask)\n",
    "        update_values = tf.boolean_mask(new_values, update_mask)\n",
    "        return tf.dynamic_stitch([stitch_range, update_indices],\n",
    "                                 [old_values, update_values])\n",
    "    \n",
    "    begin_tokens = tf.constant([[1]])\n",
    "#     outside_tokens = tf.constant([[0]])\n",
    "    outside_token = tf.constant(0)\n",
    "    def _start_new_mention(tags):\n",
    "        start_new_mention = tf.reduce_any(tf.equal(tags, begin_tokens), \n",
    "                                      reduction_indices=[0])\n",
    "        start_new_mention.set_shape((None,))\n",
    "        return start_new_mention\n",
    "    \n",
    "    def _in_mention(tags):\n",
    "        in_mention = tf.not_equal(tags, outside_token)\n",
    "        return in_mention\n",
    "    \n",
    "    def _end_current_mention(start_new_mention, in_mention, already_in_mention):\n",
    "        start_or_out = tf.logical_or(start_new_mention, tf.logical_not(in_mention))\n",
    "        end_current_mention = tf.logical_and(start_or_out, already_in_mention)\n",
    "        end_current_mention.set_shape((None,))\n",
    "        return end_current_mention\n",
    "        \n",
    "    # first figure out the maximum number of mentions\n",
    "    def _count_only_step(time, mention_counts, already_in_mention):\n",
    "        \"\"\" Update mentions_count using the mention detection update rules. \n",
    "        \n",
    "        This is done by marking if we are starting at a mention\n",
    "        and then adding to the count to sequences in the batch \n",
    "        where we detect the end of a mention.\n",
    "        \n",
    "        This is done by stitching in the updates to overwrite the current\n",
    "        values.  \n",
    "        \n",
    "        NOTE: Overwriting dynammic stitch may seem weird\n",
    "          but it's due to some scatter/while_loop idiosyncrasies of tf\n",
    "          (this finally works after my 4th implementation attempt)\n",
    "        \"\"\"\n",
    "        tags = seqs_ta.read(time)\n",
    "        in_mention = _in_mention(tags)\n",
    "        start_new_mention = _start_new_mention(tags)\n",
    "        end_current_mention = _end_current_mention(start_new_mention, in_mention, already_in_mention)\n",
    "        mention_counts = _sparse_update(end_current_mention,\n",
    "                                        batch_range, batch_range,\n",
    "                                        mention_counts, mention_counts+1)\n",
    "        already_in_mention = in_mention\n",
    "        return time+1, mention_counts, already_in_mention\n",
    "    \n",
    "    # fill in empty bookkeeping tensors that encode the mentions\n",
    "    def _extraction_step(time, \n",
    "                         mention_starts,\n",
    "                         mention_ends,\n",
    "#                          mention_features,\n",
    "                         mention_counts, \n",
    "                         mention_sizes,\n",
    "                         already_in_mention):\n",
    "        \"\"\" Extract mention boundaries at this timestep.\n",
    "        \n",
    "        Args:\n",
    "          time: the current timestep in the batch of sequences\n",
    "          seqs_ta: the batch of sequences\n",
    "          mention_starts: the Tensor holding the start boundaries \n",
    "            of the extracted mentions so far\n",
    "          mention_ends: the Tensor holding the end boundaries \n",
    "            of the extracted mentions so far\n",
    "          mention_counts: the current number of mentions found\n",
    "            for a single sequence in the batch.  This is used to \n",
    "            dynamically scatter extracted mentions into the `mentions`\n",
    "            TensorArray so that it can be abstracted away from the \n",
    "            underlying sequence.\n",
    "          in_mentions: whether or not the sequence is in a mention or not.\n",
    "            As we scan, we extract mentions by looking for contiguous groups\n",
    "            of non-'Outside' tags.  \n",
    "            This way we can extract multi-token mentions into single elements.\n",
    "        \"\"\"        \n",
    "        # get the sequence tags at the current timestep\n",
    "        tags = seqs_ta.read(time)\n",
    "        \n",
    "        # decide if they are in mention or not\n",
    "        in_mention = _in_mention(tags)\n",
    "        \n",
    "        ### IF they are a mention but weren't before, start a new mention\n",
    "        # do this by applying scattered updates (via dynamic_stitch) \n",
    "        # to the masked, linearly indexed locations of new mentions, \n",
    "        # where the updated values are the current timestep\n",
    "        # eg, the location in the sequence where this mention is being started\n",
    "        boundary = time * tf.ones_like(tags, dtype=tf.int32) \n",
    "        start_new_mention = _start_new_mention(tags)\n",
    "        end_current_mention = _end_current_mention(start_new_mention, in_mention, already_in_mention)\n",
    "        \n",
    "        ### IF they aren't but were before, end the mention at t\n",
    "        mention_ends = _sparse_update(end_current_mention,\n",
    "                                      linear_range, mention_counts + linear_index,\n",
    "                                      mention_ends, boundary)\n",
    "        \n",
    "        mention_counts = _sparse_update(end_current_mention,\n",
    "                                        batch_range, batch_range,\n",
    "                                        mention_counts, mention_counts+1)\n",
    "        \n",
    "        mention_starts = _sparse_update(start_new_mention,\n",
    "                                        linear_range, mention_counts + linear_index,\n",
    "                                        mention_starts, boundary)\n",
    "\n",
    "        # update mention counts where we've ended an extraction (same as `_count_step()`)\n",
    "        mention_sizes = _sparse_update(end_current_mention,\n",
    "                                       batch_range, batch_range,\n",
    "                                       mention_sizes, tf.zeros_like(mention_sizes))\n",
    "        mention_sizes = _sparse_update(in_mention,\n",
    "                                       batch_range, batch_range,\n",
    "                                       mention_sizes, mention_sizes+1)\n",
    "        already_in_mention = in_mention\n",
    "        \n",
    "        return (time + 1, \n",
    "#                 seqs_ta,\n",
    "#                 outside_token,\n",
    "#                 linear_range,\n",
    "#                 linear_index,\n",
    "#                 batch_range,\n",
    "                mention_starts, \n",
    "                mention_ends,\n",
    "#                 mention_features,\n",
    "                mention_counts, \n",
    "                mention_sizes,\n",
    "                already_in_mention)\n",
    "    \n",
    "    # convert the sequences\n",
    "    shape = tf.shape(seqs)\n",
    "    batch_size = shape[0]\n",
    "    time_steps = shape[1]\n",
    "#     feature_size = shape[2]\n",
    "    \n",
    "    # `TensorArray`'s read in time-major, so transpose\n",
    "    seqs_ta = tf.TensorArray(dtype=seqs.dtype, size=time_steps, clear_after_read=False)\n",
    "    seqs_ta = seqs_ta.unpack(tf.transpose(seqs, [1,0]))\n",
    "#     features_ta = tf.TensorArray(dtype=features.dtype, size=time_steps)\n",
    "#     features_ta = features_ta.unpack(tf.transpose(features, [1,0,2]))\n",
    "    \n",
    "    # bookkeeping tensors\n",
    "    time = tf.constant(0, dtype=tf.int32)\n",
    "    batch_range = tf.range(batch_size)\n",
    "    mention_counts = tf.zeros(dtype=tf.int32, shape=(batch_size,))\n",
    "    already_in_mention = tf.cast(mention_counts, tf.bool)\n",
    "        \n",
    "    # find the maximum number of mentions in batch\n",
    "    (_, mention_counts, already_in_mention) = tf.while_loop(cond=lambda time, *_: time < time_steps,\n",
    "                                                            body=_count_only_step,\n",
    "                                                            loop_vars=(time,\n",
    "                                                                       mention_counts, \n",
    "                                                                       already_in_mention))\n",
    "    # add 1 to counts where we never detected the end\n",
    "    already_in_mention.set_shape((None,))\n",
    "    mention_counts = _sparse_update(already_in_mention,\n",
    "                                    batch_range, batch_range,\n",
    "                                    mention_counts, mention_counts+1)\n",
    "    \n",
    "    # now create the tensors we will extract mention data into\n",
    "    max_num_mentions = tf.reduce_max(mention_counts)\n",
    "    max_num_relations = max_num_mentions*(max_num_mentions-1)/2\n",
    "    \n",
    "    # create a linearized version of the mention statistics we'll gather\n",
    "    # it'll be padded with -1's (can't use 0 as its a valid index)\n",
    "    mention_starts = -1*tf.ones(shape=(batch_size * max_num_mentions,), dtype=tf.int32)\n",
    "    mention_ends = -1*tf.ones(shape=(batch_size * max_num_mentions,), dtype=tf.int32)\n",
    "#     mention_features = -1*tf.ones(shape=(batch_size * max_num_mentions, feature_size), \n",
    "#                                   dtype=features.dtype)\n",
    "    \n",
    "    # we also need a full linear range and a liear index into the mention_stats\n",
    "    # tensors so we can dynamically overwrite the values\n",
    "    linear_range = tf.range(batch_size * max_num_mentions)\n",
    "    linear_index = max_num_mentions * tf.range(batch_size)\n",
    "    \n",
    "    # reset the bookkeeping tensors\n",
    "    time = tf.constant(0, dtype=tf.int32)\n",
    "    mention_counts = tf.zeros(dtype=tf.int32, shape=(batch_size,))\n",
    "    mention_sizes = tf.zeros(dtype=tf.int32, shape=(batch_size,))\n",
    "    already_in_mention = tf.cast(mention_counts, tf.bool)\n",
    "    \n",
    "    # extract the mentions\n",
    "    (time,\n",
    "     mention_starts, \n",
    "     mention_ends,\n",
    "#      mention_features,\n",
    "     mention_counts, \n",
    "     mention_sizes,\n",
    "     already_in_mention) = tf.while_loop(cond=lambda time, *_: time < time_steps,\n",
    "                                         body=_extraction_step,\n",
    "                                         loop_vars= (time, \n",
    "                                                     mention_starts, \n",
    "                                                     mention_ends,\n",
    "#                                                      mention_features,\n",
    "                                                     mention_counts, \n",
    "                                                     mention_sizes,\n",
    "                                                     already_in_mention))\n",
    "    # if we ended on a mention, we need to compute final endpoints\n",
    "    already_in_mention.set_shape((None,))\n",
    "    boundary = time * tf.ones_like(mention_counts, dtype=tf.int32) \n",
    "    offsets = mention_counts + linear_index\n",
    "    mention_ends = _sparse_update(already_in_mention,\n",
    "                                  linear_range, offsets,\n",
    "                                  mention_ends, boundary)\n",
    "    mention_counts = _sparse_update(already_in_mention,\n",
    "                                    batch_range, batch_range,\n",
    "                                    mention_counts, mention_counts+1)\n",
    "#     mention_sizes = _sparse_update(already_in_mention,\n",
    "#                                    batch_range, batch_range,\n",
    "#                                    mention_sizes, mention_sizes+1)\n",
    "    \n",
    "    # finally concat and reshape extraction stats\n",
    "    mention_starts = tf.reshape(mention_starts, (batch_size, max_num_mentions, 1))\n",
    "    mention_ends = tf.reshape(mention_ends, (batch_size, max_num_mentions, 1))\n",
    "    mentions = tf.concat(2, [mention_starts, mention_ends])\n",
    "    return mentions, mention_sizes, mention_counts#, max_num_mentions, max_num_relations\n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "New way to do the mention extraction:\n",
    "1. Run through once, only updating mention counts\n",
    "   to dynamically compute the max number of mentions and lengths\n",
    "2. Create a linearly indexed zero filled tensor with total shape [batch_size x max_num_mentions]\n",
    "   for each piece of metadata\n",
    "3. Selectively update the linear index tensor with mention extractions\n",
    "4. Finally reshape and stitch tensors together\n",
    "\"\"\"\n",
    "# create fake sequences over a 'batch'\n",
    "# sequences are \n",
    "# [ O B I O B I B O ]\n",
    "# [ B I O B O B O B ]\n",
    "tf.reset_default_graph()\n",
    "fake_tagged_seqs = np.array([[0,1,2,0,1,2,1,0],\n",
    "                             [1,2,0,1,0,1,0,1]])\n",
    "seqs = tf.Variable(fake_tagged_seqs, dtype=tf.int32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print \"Init\"\n",
    "    mentions = extract_mentions(seqs)\n",
    "    tf.initialize_all_variables().run()\n",
    "    print \"Done\"\n",
    "#     print c.eval()\n",
    "#     print d.eval()\n",
    "    print \"Running\"\n",
    "    m, s, c = mentions\n",
    "    print \"Done\"\n",
    "#     print n.eval(), r.eval()\n",
    "    print \"Input tags\"\n",
    "    print fake_tagged_seqs\n",
    "    print \"Extracted Mentions\"\n",
    "    print s.eval()\n",
    "    print c.eval()\n",
    "    print m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False  True]]\n",
      "[False False  True]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "begin_tokens = tf.constant([[1]])\n",
    "tok = tf.constant([0, 2, 1])\n",
    "eq = tf.equal(tok, begin_tokens)\n",
    "eq2 = tf.reduce_any(eq, reduction_indices=[0])\n",
    "with tf.Session():\n",
    "    tf.initialize_all_variables().run()\n",
    "    print eq.eval()\n",
    "    print eq2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.scatt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir ../summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "# start = tf.Variable([0, 1])\n",
    "# r = tf.range(start)\n",
    "# with tf.Session():\n",
    "#     tf.initialize_all_variables().run()\n",
    "#     print r.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_mentions(seqs, seq_features):\n",
    "    \"\"\" Iterate over a batch of sequences, extracting the mentions encoded in them.\n",
    "    \n",
    "    Args:\n",
    "      seqs: Tensor with shape [batch_size, max_timesteps]\n",
    "      \n",
    "    Returns:\n",
    "      mentions: Tensor with shape [batch_size, max_extracted_mentions, 3].\n",
    "        This tensor is padded to the max number of extracted mentions.\n",
    "        The final dimension `3` encodes mention metadata where:\n",
    "          0: mention left boundary index `i`\n",
    "          1: mention right boundary index `j` (inclusive)\n",
    "          2: mention group\n",
    "      mentions_mask: Tensor with shape [batch_size, max_extracted_mentions].\n",
    "        This tensor encodes the `pad` locations of the mentions tensor.\n",
    "        \n",
    "    Example (pseudocode):\n",
    "      # fake sequences [ O B I O B I I O ]\n",
    "      #                [ B I O O O B O B ]\n",
    "      fake_tagged_seqs = np.array([[0,1,2,0,1,2,2,0],\n",
    "                             [1,2,0,1,0,1,0,1]])\n",
    "                             \n",
    "      mentions = extract_mentions(seqs, outside_token) \n",
    "      print mentions[:,:,0] # starting boundaries\n",
    "      >>> [[ 1  4 -1 -1]\n",
    "           [ 0  3  5  7]]\n",
    "      print mentions[:,:,1] # end boundaries (inclusive)\n",
    "      >>> [[ 2  6 -1 -1]\n",
    "           [ 1  3  5  7]]\n",
    "            \n",
    "    \"\"\" \n",
    "    def _sparse_update(update_mask, stitch_range, update_range, old_values, new_values):\n",
    "        \"\"\" Return as sparsely updated tensor according to the mask.\n",
    "        \n",
    "        This allows for scattered updates to a `Tensor` (not just a `Variable`)\n",
    "        by using dynamic stitch to overwrite values\"\"\"\n",
    "        update_indices = tf.boolean_mask(update_range, update_mask)\n",
    "        update_values = tf.boolean_mask(new_values, update_mask)\n",
    "        return tf.dynamic_stitch([stitch_range, update_indices],\n",
    "                                 [old_values, update_values])\n",
    "    \n",
    "    begin_tokens = tf.constant([[1]])\n",
    "#     outside_tokens = tf.constant([[0]])\n",
    "    outside_token = tf.constant(0)\n",
    "    def _start_new_mention(tags):\n",
    "        start_new_mention = tf.reduce_any(tf.equal(tags, begin_tokens), \n",
    "                                      reduction_indices=[0])\n",
    "        start_new_mention.set_shape((None,))\n",
    "        return start_new_mention\n",
    "    \n",
    "    def _in_mention(tags):\n",
    "        in_mention = tf.not_equal(tags, outside_token)\n",
    "        return in_mention\n",
    "    \n",
    "    def _end_current_mention(start_new_mention, in_mention, already_in_mention):\n",
    "        start_or_out = tf.logical_or(start_new_mention, tf.logical_not(in_mention))\n",
    "        end_current_mention = tf.logical_and(start_or_out, already_in_mention)\n",
    "        end_current_mention.set_shape((None,))\n",
    "        return end_current_mention\n",
    "        \n",
    "    # first figure out the maximum number of mentions\n",
    "    def _count_only_step(time, mention_counts, already_in_mention):\n",
    "        \"\"\" Update mentions_count using the mention detection update rules. \n",
    "        \n",
    "        This is done by marking if we are starting at a mention\n",
    "        and then adding to the count to sequences in the batch \n",
    "        where we detect the end of a mention.\n",
    "        \n",
    "        This is done by stitching in the updates to overwrite the current\n",
    "        values.  \n",
    "        \n",
    "        NOTE: Overwriting dynammic stitch may seem weird\n",
    "          but it's due to some scatter/while_loop idiosyncrasies of tf\n",
    "          (this finally works after my 4th implementation attempt)\n",
    "        \"\"\"\n",
    "        tags = seqs_ta.read(time)\n",
    "        in_mention = _in_mention(tags)\n",
    "        start_new_mention = _start_new_mention(tags)\n",
    "        end_current_mention = _end_current_mention(start_new_mention, in_mention, already_in_mention)\n",
    "        mention_counts = _sparse_update(end_current_mention,\n",
    "                                        batch_range, batch_range,\n",
    "                                        mention_counts, mention_counts+1)\n",
    "        already_in_mention = in_mention\n",
    "        return time+1, mention_counts, already_in_mention\n",
    "    \n",
    "    # fill in empty bookkeeping tensors that encode the mentions\n",
    "    def _extraction_step(time, \n",
    "                         mention_starts,\n",
    "                         mention_ends,\n",
    "                         mention_features,\n",
    "                         mention_counts, \n",
    "                         mention_sizes,\n",
    "                         sliding_feature,\n",
    "                         already_in_mention):\n",
    "        \"\"\" Extract mention boundaries at this timestep.\n",
    "        \n",
    "        Args:\n",
    "          time: the current timestep in the batch of sequences\n",
    "          seqs_ta: the batch of sequences\n",
    "          mention_starts: the Tensor holding the start boundaries \n",
    "            of the extracted mentions so far\n",
    "          mention_ends: the Tensor holding the end boundaries \n",
    "            of the extracted mentions so far\n",
    "          mention_counts: the current number of mentions found\n",
    "            for a single sequence in the batch.  This is used to \n",
    "            dynamically scatter extracted mentions into the `mentions`\n",
    "            TensorArray so that it can be abstracted away from the \n",
    "            underlying sequence.\n",
    "          in_mentions: whether or not the sequence is in a mention or not.\n",
    "            As we scan, we extract mentions by looking for contiguous groups\n",
    "            of non-'Outside' tags.  \n",
    "            This way we can extract multi-token mentions into single elements.\n",
    "        \"\"\"        \n",
    "        # get the sequence tags at the current timestep\n",
    "        tags = seqs_ta.read(time)\n",
    "        features = tf.tile(features_ta.read(time), [max_num_mentions, 1])\n",
    "        \n",
    "        # decide if they are in mention or not\n",
    "        in_mention = _in_mention(tags)\n",
    "        \n",
    "        boundary = time * tf.ones_like(tags, dtype=tf.int32) \n",
    "        \n",
    "        # whether to start new mention and/or end the previous\n",
    "        start_new_mention = _start_new_mention(tags)\n",
    "        end_current_mention = _end_current_mention(start_new_mention, in_mention, already_in_mention)\n",
    "        \n",
    "        \n",
    "        mention_ends = _sparse_update(end_current_mention,\n",
    "                                      linear_range, mention_counts + linear_index,\n",
    "                                      mention_ends, boundary)\n",
    "        \n",
    "        mention_counts = _sparse_update(end_current_mention,\n",
    "                                        batch_range, batch_range,\n",
    "                                        mention_counts, mention_counts+1)\n",
    "        \n",
    "        mention_starts = _sparse_update(start_new_mention,\n",
    "                                        linear_range, mention_counts + linear_index,\n",
    "                                        mention_starts, boundary)\n",
    "        \n",
    "        repeated_index = tf.tile(tf.reshape(mention_counts+linear_index, (-1,1)), [1,2])\n",
    "        repeated_batch_range = tf.tile(tf.reshape(batch_range, (-1,1)), [1,2])\n",
    "        mention_features = _sparse_update(in_mention,\n",
    "                                          repeated_batch_range, repeated_index,\n",
    "                                          mention_features, sliding_feature + features)\n",
    "        mention_features.set_shape((None, None))\n",
    "        \n",
    "        sliding_feature = _sparse_update(end_current_mention,\n",
    "                                          batch_range, batch_range,\n",
    "                                          sliding_feature, tf.zeros_like(sliding_feature))\n",
    "        \n",
    "        # update mention counts where we've ended an extraction (same as `_count_step()`)\n",
    "        mention_sizes = _sparse_update(end_current_mention,\n",
    "                                       batch_range, batch_range,\n",
    "                                       mention_sizes, tf.zeros_like(mention_sizes))\n",
    "        mention_sizes = _sparse_update(in_mention,\n",
    "                                       batch_range, batch_range,\n",
    "                                       mention_sizes, mention_sizes+1)\n",
    "        \n",
    "        already_in_mention = in_mention\n",
    "        \n",
    "        return (time + 1, \n",
    "#                 seqs_ta,\n",
    "#                 outside_token,\n",
    "#                 linear_range,\n",
    "#                 linear_index,\n",
    "#                 batch_range,\n",
    "                mention_starts, \n",
    "                mention_ends,\n",
    "                mention_features,\n",
    "                mention_counts, \n",
    "                mention_sizes,\n",
    "                sliding_feature,\n",
    "                already_in_mention)\n",
    "    \n",
    "    # convert the sequences\n",
    "    shape = tf.shape(seq_features)\n",
    "    batch_size = shape[0]\n",
    "    time_steps = shape[1]\n",
    "    feature_size = shape[2]\n",
    "    \n",
    "    # `TensorArray`'s read in time-major, so transpose\n",
    "    seqs_ta = tf.TensorArray(dtype=seqs.dtype, size=time_steps, clear_after_read=False)\n",
    "    seqs_ta = seqs_ta.unpack(tf.transpose(seqs, [1,0]))\n",
    "    features_ta = tf.TensorArray(dtype=seq_features.dtype, size=time_steps)\n",
    "    features_ta = features_ta.unpack(tf.transpose(seq_features, [1,0,2]))\n",
    "    \n",
    "    # bookkeeping tensors\n",
    "    time = tf.constant(0, dtype=tf.int32)\n",
    "    batch_range = tf.range(batch_size)\n",
    "    mention_counts = tf.zeros(dtype=tf.int32, shape=(batch_size,))\n",
    "    already_in_mention = tf.cast(mention_counts, tf.bool)\n",
    "        \n",
    "    # find the maximum number of mentions in batch\n",
    "    (_, mention_counts, already_in_mention) = tf.while_loop(cond=lambda time, *_: time < time_steps,\n",
    "                                                            body=_count_only_step,\n",
    "                                                            loop_vars=(time,\n",
    "                                                                       mention_counts, \n",
    "                                                                       already_in_mention))\n",
    "    # add 1 to counts where we never detected the end\n",
    "    already_in_mention.set_shape((None,))\n",
    "    mention_counts = _sparse_update(already_in_mention,\n",
    "                                    batch_range, batch_range,\n",
    "                                    mention_counts, mention_counts+1)\n",
    "    \n",
    "    # now create the tensors we will extract mention data into\n",
    "    max_num_mentions = tf.reduce_max(mention_counts)\n",
    "    max_num_relations = max_num_mentions*(max_num_mentions-1)/2\n",
    "    \n",
    "    # create a linearized version of the mention statistics we'll gather\n",
    "    # it'll be padded with -1's (can't use 0 as its a valid index)\n",
    "    mention_starts = -1*tf.ones(shape=(batch_size * max_num_mentions,), dtype=tf.int32)\n",
    "    mention_ends = -1*tf.ones(shape=(batch_size * max_num_mentions,), dtype=tf.int32)\n",
    "    mention_features = tf.zeros(shape=(batch_size * max_num_mentions, feature_size),\n",
    "                                dtype=seq_features.dtype)\n",
    "#     mention_features = -1*tf.ones(shape=(batch_size * max_num_mentions, feature_size), \n",
    "#                                   dtype=features.dtype)\n",
    "    \n",
    "    # we also need a full linear range and a liear index into the mention_stats\n",
    "    # tensors so we can dynamically overwrite the values\n",
    "    linear_range = tf.range(batch_size * max_num_mentions)\n",
    "    linear_index = max_num_mentions * tf.range(batch_size)\n",
    "    \n",
    "    # reset the bookkeeping tensors\n",
    "    time = tf.constant(0, dtype=tf.int32)\n",
    "    mention_counts = tf.zeros(dtype=tf.int32, shape=(batch_size,))\n",
    "    mention_sizes = tf.zeros(dtype=tf.int32, shape=(batch_size,))\n",
    "    sliding_feature = tf.zeros(dtype=seq_features.dtype, shape=(batch_size,))\n",
    "    already_in_mention = tf.cast(mention_counts, tf.bool)\n",
    "    \n",
    "    # extract the mentions\n",
    "    (time,\n",
    "     mention_starts, \n",
    "     mention_ends,\n",
    "     mention_features,\n",
    "     mention_counts, \n",
    "     mention_sizes,\n",
    "     sliding_feature,\n",
    "     already_in_mention) = tf.while_loop(cond=lambda time, *_: time < time_steps,\n",
    "                                         body=_extraction_step,\n",
    "                                         loop_vars= (time, \n",
    "                                                     mention_starts, \n",
    "                                                     mention_ends,\n",
    "                                                     mention_features,\n",
    "                                                     mention_counts, \n",
    "                                                     mention_sizes,\n",
    "                                                     sliding_feature,\n",
    "                                                     already_in_mention))\n",
    "    # if we ended on a mention, we need to compute final endpoints\n",
    "    already_in_mention.set_shape((None,))\n",
    "    boundary = time * tf.ones_like(mention_counts, dtype=tf.int32) \n",
    "    offsets = mention_counts + linear_index\n",
    "    mention_ends = _sparse_update(already_in_mention,\n",
    "                                  linear_range, offsets,\n",
    "                                  mention_ends, boundary)\n",
    "    mention_counts = _sparse_update(already_in_mention,\n",
    "                                    batch_range, batch_range,\n",
    "                                    mention_counts, mention_counts+1)\n",
    "#     mention_sizes = _sparse_update(already_in_mention,\n",
    "#                                    batch_range, batch_range,\n",
    "#                                    mention_sizes, mention_sizes+1)\n",
    "    \n",
    "    # finally concat and reshape extraction stats\n",
    "    mention_starts = tf.reshape(mention_starts, (batch_size, max_num_mentions, 1))\n",
    "    mention_ends = tf.reshape(mention_ends, (batch_size, max_num_mentions, 1))\n",
    "    mentions = tf.concat(2, [mention_starts, mention_ends])\n",
    "    return mentions, mention_features, mention_sizes, mention_counts#, max_num_mentions, max_num_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes (?,) and (?, ?) are not compatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-eee8ace4b108>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m tags = tf.Variable(np.array([[0,1,2],\n\u001b[1;32m     22\u001b[0m                              [1,0,1]]), dtype=tf.int32, trainable=False)\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmention_spans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmention_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_mentions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedded_seqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-6c3250b3dc98>\u001b[0m in \u001b[0;36mextract_mentions\u001b[0;34m(seqs, seq_features)\u001b[0m\n\u001b[1;32m    245\u001b[0m                                                      \u001b[0mmention_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                                                      \u001b[0msliding_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                                                      already_in_mention))\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;31m# if we ended on a mention, we need to compute final endpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0malready_in_mention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.pyc\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)\u001b[0m\n\u001b[1;32m   2516\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhileContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2517\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2518\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuildLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_invariants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2519\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.pyc\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2354\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2355\u001b[0m       original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2356\u001b[0;31m           pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2357\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.pyc\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2304\u001b[0m         \u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginal_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2305\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[0;32m-> 2306\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2307\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2308\u001b[0m       \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-6c3250b3dc98>\u001b[0m in \u001b[0;36m_extraction_step\u001b[0;34m(time, mention_starts, mention_ends, mention_features, mention_counts, mention_sizes, sliding_feature, already_in_mention)\u001b[0m\n\u001b[1;32m    143\u001b[0m                                           \u001b[0mrepeated_batch_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeated_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                                           mention_features, sliding_feature + features)\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mmention_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         sliding_feature = _sparse_update(end_current_mention,\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shape\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mthis\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \"\"\"\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36mmerge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    577\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         raise ValueError(\"Shapes %s and %s are not compatible\" %\n\u001b[0;32m--> 579\u001b[0;31m                          (self, other))\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (?,) and (?, ?) are not compatible"
     ]
    }
   ],
   "source": [
    "# [ O B I ]\n",
    "# [ B O B ]\n",
    "\n",
    "# rnn outputs\n",
    "tf.reset_default_graph()\n",
    "seqs = tf.Variable(np.array([[0,1,1],\n",
    "                             [1,0,1]]) , dtype=tf.int32, trainable=False)\n",
    "ys = tf.Variable(np.array([[0,1],\n",
    "                           [1,0]]), trainable=False)\n",
    "embed = tf.Variable(np.array([[2., 2.],\n",
    "                              [3., 3.]]))\n",
    "\n",
    "embedded_seqs = tf.nn.embedding_lookup(embed, seqs)\n",
    "print embedded_seqs.get_shape()\n",
    "# cell = tf.nn.rnn_cell.BasicRNNCell(5)\n",
    "# outputs, _ = tf.nn.dynamic_rnn(cell, embedded_seqs, dtype=tf.float64)\n",
    "\n",
    "# print outputs.get_shape()\n",
    "\n",
    "# extracted mentions\n",
    "tags = tf.Variable(np.array([[0,1,2],\n",
    "                             [1,0,1]]), dtype=tf.int32, trainable=False)\n",
    "mention_spans, mention_features, _, _ = extract_mentions(tags, embedded_seqs)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print mention_spans.eval()\n",
    "    print mention_features.eval()\n",
    "#     print sizes.eval()\n",
    "#     print counts.eval()\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_indices(tags):\n",
    "    shape = tf.shape(tags)\n",
    "    batch_size = shape[0]\n",
    "    time_steps = shape[1]\n",
    "    \n",
    "    tags_ta = tf.TensorArray(dtype=tags.dtype, size=time_steps, clear_after_read=True)\n",
    "    tags_ta = seqs_ta.unpack(tf.transpose(tags, [1,0]))\n",
    "    index_ta = tf.TensorArray(dtype=tags.dtype, size=time_steps, clear_after_read=True)\n",
    "    \n",
    "    begin_tokens = tf.constant([[1]])\n",
    "#     outside_tokens = tf.constant([[0]])\n",
    "    outside_token = tf.constant(0)\n",
    "    def _start_new_mention(tags):\n",
    "        start_new_mention = tf.reduce_any(tf.equal(tags, begin_tokens), \n",
    "                                      reduction_indices=[0])\n",
    "        start_new_mention.set_shape((None,))\n",
    "        return start_new_mention\n",
    "    \n",
    "    def _in_mention(tags):\n",
    "        in_mention = tf.not_equal(tags, outside_token)\n",
    "        return in_mention\n",
    "    \n",
    "    def _end_current_mention(start_new_mention, in_mention, already_in_mention):\n",
    "        start_or_out = tf.logical_or(start_new_mention, tf.logical_not(in_mention))\n",
    "        end_current_mention = tf.logical_and(start_or_out, already_in_mention)\n",
    "        end_current_mention.set_shape((None,))\n",
    "        return end_current_mention\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# [ O B I ]\n",
    "# [ B O B ]\n",
    "\n",
    "# rnn outputs\n",
    "tf.reset_default_graph()\n",
    "seqs = tf.Variable(np.array([[0,1,1],\n",
    "                             [1,0,1]]) , dtype=tf.int32, trainable=False)\n",
    "ys = tf.Variable(np.array([[0,1],\n",
    "                           [1,0]]), trainable=False)\n",
    "embed = tf.Variable(np.array([[2., 2.],\n",
    "                              [3., 3.]]))\n",
    "\n",
    "embedded_seqs = tf.nn.embedding_lookup(embed, seqs)\n",
    "print embedded_seqs.get_shape()\n",
    "\n",
    "# extracted mentions\n",
    "tags = tf.Variable(np.array([[0,1,2],\n",
    "                             [1,0,1]]), dtype=tf.int32, trainable=False)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print mention_spans.eval()\n",
    "    print mention_features.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
