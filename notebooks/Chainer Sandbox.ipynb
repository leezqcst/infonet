{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import json\n",
    "from io import open\n",
    "import time\n",
    "import os.path\n",
    "import six\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sb\n",
    "sb.set_color_codes()\n",
    "plt.rcParams['figure.figsize'] = (6,4)\n",
    "\n",
    "import chainer as ch\n",
    "import chainer.training.extensions # for some reason this isn't automatically imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = json.loads(open('../data/ace_05_head_yaat.json', 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "class Vocab():\n",
    "    \"\"\" A convenience vocabulary wrapper \n",
    "    \n",
    "    TODO: Add in sampling table functionality\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 tokens=None, \n",
    "                 min_count=5,\n",
    "                 pad_token='<PAD>', \n",
    "                 unk_token='<UNK>'):\n",
    "        self.min_count=min_count\n",
    "        self.pad_token = pad_token\n",
    "        self.unk_token = unk_token\n",
    "        \n",
    "        self.use(tokens)\n",
    "#         self.make_sampling_table()\n",
    "\n",
    "    @property\n",
    "    def n(self):\n",
    "        \"\"\" The total number of tokens seen by the vocabulary.\n",
    "        \n",
    "        This **does not** include tokens which have not been seen `min_count` times\n",
    "        \"\"\"\n",
    "        return self._n\n",
    "\n",
    "    @property\n",
    "    def v(self):\n",
    "        \"\"\" The total number of unique tokens in the vocabulary.\n",
    "        \n",
    "        This **does not** include tokens which have not been seen `min_count` times\n",
    "        \"\"\"\n",
    "        return self._v\n",
    "\n",
    "    @property\n",
    "    def pad(self):\n",
    "        \"\"\" Return the PAD token \"\"\"\n",
    "        return self.pad_token\n",
    "\n",
    "    @property\n",
    "    def ipad(self):\n",
    "        \"\"\" Return the index of the PAD token \"\"\"\n",
    "        return self.idx(self.pad_token)\n",
    "    \n",
    "    @property\n",
    "    def unk(self):\n",
    "        \"\"\" Return the UNK token \"\"\"\n",
    "        return self.unk_token\n",
    "\n",
    "    @property\n",
    "    def iunk(self):\n",
    "        \"\"\" Return the index of the UNK token \"\"\"\n",
    "        return self.idx(self.unk_token)\n",
    "\n",
    "    def idx(self, token):\n",
    "        \"\"\" Return the index of a token or the index of UNK if not in vocab.\n",
    "        \n",
    "        Additionally this will return UNK if the token is in the vocab \n",
    "        but has yet to be seen `min_count` times\n",
    "        \"\"\"\n",
    "        if token == self.pad_token:\n",
    "            return self._vocab2idx[token]\n",
    "        elif token in self.vocabset:\n",
    "            if self.count_index[token] >= self.min_count:\n",
    "                return self._vocab2idx[token]\n",
    "            else:\n",
    "                return self._vocab2idx[self.unk_token]\n",
    "        else:\n",
    "            return self._vocab2idx[self.unk_token]\n",
    "\n",
    "    def token(self, idx):\n",
    "        \"\"\" Return the token corresponding to the input index `idx`.\n",
    "        \n",
    "        If the index is not in the vocabulary, or it is the index\n",
    "        of a token that has not been seen `min_count` times,\n",
    "        the UNK token is returned instead\n",
    "        \"\"\"\n",
    "        if idx in self.idxset:\n",
    "            token = self._idx2vocab[idx]\n",
    "            if self.count_index[token] >= self.min_count:\n",
    "                return token\n",
    "            else:\n",
    "                return self.unk_token\n",
    "        else:\n",
    "            return self.unk_token\n",
    "\n",
    "    def use(self, tokens):\n",
    "        \"\"\" Create the vocabulary, using these tokens.\n",
    "        \n",
    "        This method will reset the vocab with these tokens.\n",
    "        \n",
    "        `tokens` is expected to be a flat list.\n",
    "        \"\"\"\n",
    "        self.count_index = Counter()\n",
    "        self._vocab2idx = {self.pad_token:0,\n",
    "                           self.unk_token:1}\n",
    "        self._idx2vocab = {0:self.pad_token,\n",
    "                           1:self.unk_token}\n",
    "        if tokens:\n",
    "            self.add(tokens)\n",
    "\n",
    "    def add(self, tokens):\n",
    "        \"\"\" Add these tokens to the vocabulary.\n",
    "        \n",
    "        This can be used iteratively, adding, say, one sentence at a time.\n",
    "        \n",
    "        NOTE: Expects `tokens` to be a flat list.\n",
    "        \"\"\"\n",
    "        # increment counts of tokens seen here\n",
    "        for token in tokens:\n",
    "            self.count_index[token] += 1\n",
    "        \n",
    "        # add tokens to the vocabulary if they are new\n",
    "        token_set = set(tokens)\n",
    "        for token in token_set:\n",
    "            if token not in self._vocab2idx:\n",
    "                new_idx = len(self._vocab2idx)\n",
    "                self._vocab2idx[token] = new_idx\n",
    "                self._idx2vocab[new_idx] = token\n",
    "        \n",
    "        # now precompute commonly used properties of the vocab (ignoring infrequent tokens)\n",
    "        self.vocabset = set([ token for (token, count) in self.count_index.most_common()\n",
    "                              if count >= self.min_count ]) \n",
    "        self.vocabset |= set([self.pad_token, self.unk_token])\n",
    "        self.idxset = set([ self._vocab2idx[token] for token in self.vocabset ])\n",
    "        self._n = sum( count for count in self.count_index.values() if count >= self.min_count )\n",
    "        self._v = sum( 1 for count in self.count_index.values() if count >= self.min_count ) + 2 # <PAD> and <UNK>\n",
    "        \n",
    "    def drop_infrequent(self):\n",
    "        \"\"\" Drop all words from the vocabulary that have not been seen `min_count` times\n",
    "        and recompute the vocabulary indices.\n",
    "        \n",
    "        This is useful for when the vocab has a long tail of infrequent words\n",
    "        that we no longer wish to account for.\n",
    "        \n",
    "        NOTE: This changes indices of tokens in the vocab!\n",
    "        \"\"\"\n",
    "        # remove all infrequent tokens from the count index\n",
    "        to_remove = set(self.count_index.keys()) - self.vocabset\n",
    "        for token in to_remove:\n",
    "            self.count_index.pop(token)\n",
    "            \n",
    "        # now reset the vocab dicts and reindex the tokens\n",
    "        self._vocab2idx = {self.pad_token:0,\n",
    "                           self.unk_token:1}\n",
    "        self._idx2vocab = {0:self.pad_token,\n",
    "                           1:self.unk_token}\n",
    "        for token in self.count_index.keys():\n",
    "            new_idx = len(self._vocab2idx)\n",
    "            self._vocab2idx[token] = new_idx\n",
    "            self._idx2vocab[new_idx] = token\n",
    "            \n",
    "        # precompute commonly used properties of the vocab\n",
    "        self.vocabset = set(self._vocab2idx.keys())\n",
    "        self.idxset = set(self._idx2vocab.keys())\n",
    "        self._n = sum( count for count in self.count_index.values() )\n",
    "        self._v = len(self._vocab2idx)\n",
    "\n",
    "    def count(self, token):\n",
    "        \"\"\" Get the count of a token.  \n",
    "        \n",
    "        This includes tokens with countes below `min_count`,\n",
    "        which have been seen but are not included in the vocab.\n",
    "        \"\"\"\n",
    "        return self.count_index[token]\n",
    "\n",
    "#     def make_sampling_table(self, power_scalar=.75):\n",
    "#         # from 0 to V-1, get the frequency\n",
    "#         self.vocab_distribution = np.array([ (self.count_index[self._idx2vocab[idx]]/float(self._n))**power_scalar\n",
    "#                                     for idx in range(len(self.idxset))])\n",
    "#         self.vocab_distribution /= np.sum(self.vocab_distribution).astype(np.float)\n",
    "\n",
    "#     def sample(self, sample_shape):\n",
    "#         # sample a tensor of indices\n",
    "#         # by walking up the CDF\n",
    "#         # setting each position to the index\n",
    "#         # of the word which is the closest\n",
    "#         # word with that CDF\n",
    "#         sums = np.zeros(sample_shape)\n",
    "#         rands = npr.uniform(size=sample_shape)\n",
    "#         idxs = np.zeros(sample_shape)\n",
    "#         for i in range(len(self.vocab_distribution)):\n",
    "#             sums += self.vocab_distribution[i]\n",
    "#             idxs[sums <= rands] = i\n",
    "#         return idxs.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Entity_BIO_map(mention_labels, annotation):\n",
    "    \"\"\" Uses BIO scheme (untyped) for entities only \"\"\"\n",
    "    if annotation['node-type'] == 'entity':\n",
    "        left, right = tuple(annotation['ann-span'])\n",
    "        mention_labels[left] = 'B'\n",
    "        for i in range(1, right-left+1):\n",
    "            mention_labels[left+i] = 'I'\n",
    "    return mention_labels\n",
    "\n",
    "def Entity_typed_BIO_map(mention_labels, annotation):\n",
    "    \"\"\" Uses BIO scheme (typed) for entities only \"\"\"\n",
    "    if annotation['node-type'] == 'entity':\n",
    "        mention_type = annotation['type']\n",
    "        left, right = tuple(annotation['ann-span'])\n",
    "        mention_labels[left] = 'B-'+mention_type\n",
    "        for i in range(1, right-left+1):\n",
    "            mention_labels[left+i] = 'I-'+mention_type\n",
    "    return mention_labels\n",
    "\n",
    "def Entity_BILOU_map(mention_labels, annotation):\n",
    "    \"\"\" Uses BILOU scheme (untyped) for entities only \"\"\"\n",
    "    if annotation['node-type'] == 'entity':\n",
    "        left, right = tuple(annotation['ann-span'])\n",
    "        if left == right:\n",
    "            mention_labels[left] = 'U'\n",
    "        else:\n",
    "            mention_labels[left] = 'B'\n",
    "            for i in range(1, right-left):\n",
    "                mention_labels[left+i] = 'I'\n",
    "            mention_labels[right] = 'L'\n",
    "    return mention_labels\n",
    "\n",
    "def Entity_typed_BILOU_map(mention_labels, annotation):\n",
    "    \"\"\" Uses BILOU scheme (typed) for entities only \"\"\"\n",
    "    if annotation['node-type'] == 'entity':\n",
    "        mention_type = annotation['type']\n",
    "        left, right = tuple(annotation['ann-span'])\n",
    "        if left == right:\n",
    "            mention_labels[left] = 'U-'+mention_type\n",
    "        else:\n",
    "            mention_labels[left] = 'B-'+mention_type\n",
    "            for i in range(1, right-left):\n",
    "                mention_labels[left+i] = 'I-'+mention_type\n",
    "            mention_labels[right] = 'L-'+mention_type\n",
    "    return mention_labels\n",
    "\n",
    "def compute_flat_mention_labels(doc, scheme_func=Entity_BIO_map):\n",
    "    \"\"\" Takes a YAAT style document and computes token-level mention label list.\n",
    "    \n",
    "    This function only considers the outermost spans (as per ACE evaluation)\n",
    "    by editing the mentions of shortest span-length to longest.\n",
    "    Thus wider mentions will override narrower nested mentions.\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    \n",
    "    tokens: ['part', 'of' , 'mention', '.', 'not', 'part']\n",
    "    with annotation: {'ann-type':'node',\n",
    "                      'node-type':'entity',\n",
    "                      'ann-span':[0,2]}\n",
    "    with scheme: BIO\n",
    "    \n",
    "    yields:\n",
    "    mention_labels = ['B', 'I', 'I', 'O', 'O', 'O']\n",
    "    \"\"\"\n",
    "    mention_labels = ['O' for token in doc['tokens']]\n",
    "    mentions = [ annotation for annotation in doc['annotations'] if annotation['ann-type'] == 'node' ]\n",
    "    for annotation in sorted(mentions, key=lambda x:x['ann-span'][1]-x['ann-span'][0]):\n",
    "        mention_labels = scheme_func(mention_labels, annotation)\n",
    "    return mention_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324491 total tokens and 4826 types with mincount > 5\n"
     ]
    }
   ],
   "source": [
    "token_vocab = Vocab(min_count=5)\n",
    "for doc in data.values():\n",
    "    token_vocab.add(doc['tokens'])\n",
    "print '{} total tokens and {} types with mincount > 5'.format(token_vocab.n, token_vocab.v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of O\n",
      "al B\n",
      "qaeda I\n",
      ". O\n",
      "they O\n",
      "may O\n",
      "have O\n",
      "been O\n",
      "timed O\n",
      "to O\n"
     ]
    }
   ],
   "source": [
    "doc['boundary_labels'] = compute_flat_mention_labels(doc, Entity_BIO_map)\n",
    "for token, label in zip(doc['tokens'], doc['boundary_labels'])[100:110]:\n",
    "    print token, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boundary_vocab = Vocab(min_count=0)\n",
    "for doc in data.values():\n",
    "    doc['boundary_labels'] = compute_flat_mention_labels(doc, Entity_BIO_map)\n",
    "    boundary_vocab.add(doc['boundary_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321 train, 53 validation, and 161 test documents\n"
     ]
    }
   ],
   "source": [
    "xy = [(doc['tokens'], doc['boundary_labels']) for doc in data.values()]\n",
    "npr.shuffle(xy)\n",
    "\n",
    "valid_split = int(len(xy)*.6)\n",
    "test_split = int(len(xy)*.7)\n",
    "xy_train, xy_valid, xy_test = xy[:valid_split], xy[valid_split:test_split], xy[test_split:]\n",
    "\n",
    "x_train = [d[0] for d in xy_train]\n",
    "y_train = [d[1] for d in xy_train]\n",
    "x_valid = [d[0] for d in xy_valid]\n",
    "y_valid = [d[1] for d in xy_valid]\n",
    "x_test = [d[0] for d in xy_test]\n",
    "y_test = [d[1] for d in xy_test]\n",
    "\n",
    "print '{} train, {} validation, and {} test documents'.format(len(x_train), len(x_valid), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # create an additional training set that is split on sentences\n",
    "# def split_sentences(doc_x, doc_y):\n",
    "#     xs, ys = [], []\n",
    "#     sent_x, sent_y = [], []\n",
    "#     for x, y in zip(doc_x, doc_y):\n",
    "#         if x == '.':\n",
    "#             sent_x.append(x)\n",
    "#             sent_y.append(y)\n",
    "#             xs.append(sent_x)\n",
    "#             ys.append(sent_y)\n",
    "#             sent_x = []\n",
    "#             sent_y = []\n",
    "#         else:\n",
    "#             sent_x.append(x)\n",
    "#             sent_y.append(y)\n",
    "#     return xs, ys\n",
    "\n",
    "# def split_all_docs(xs, ys):\n",
    "#     all_xs, all_ys = [], []\n",
    "#     for x,y in zip(xs, ys):\n",
    "#         sent_xs, sent_ys = split_sentences(x, y)\n",
    "#         all_xs.extend(sent_xs)\n",
    "#         all_ys.extend(sent_ys)\n",
    "#     return all_xs, all_ys\n",
    "\n",
    "# x_sent_train, y_sent_train = split_all_docs(x_train, y_train)\n",
    "# x_sent_test, y_sent_test = split_all_docs(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# before we do conversions, we need to drop unfrequent words from the vocab and reindex it\n",
    "token_vocab.drop_infrequent()\n",
    "boundary_vocab.drop_infrequent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_sequence(sequence, conversion_func):\n",
    "    return [ conversion_func(s) for s in sequence ]\n",
    "\n",
    "def convert_sequences(sequences, conversion_func):\n",
    "    return [ convert_sequence(sequence, conversion_func) for sequence in sequences ]\n",
    "\n",
    "ix_train = convert_sequences(x_train, token_vocab.idx)\n",
    "ix_valid = convert_sequences(x_valid, token_vocab.idx)\n",
    "ix_test = convert_sequences(x_test, token_vocab.idx)\n",
    "iy_train = convert_sequences(y_train, boundary_vocab.idx)\n",
    "iy_valid = convert_sequences(y_valid, boundary_vocab.idx)\n",
    "iy_test = convert_sequences(y_test, boundary_vocab.idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bucketed iterator for the variable length sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BucketedIterator(ch.dataset.iterator.Iterator):\n",
    "    def _anchored_permutation(self, order):\n",
    "        \"\"\" Randomized permutation except last element is alway the largest.\n",
    "        \n",
    "        Used for bucketed rnn batches where the last batch may \n",
    "        (and if so must) be smaller than the rest.\n",
    "        \"\"\"\n",
    "        order = npr.permutation(order)\n",
    "#         m = np.max(order)\n",
    "#         order[order==m] = order[-1]\n",
    "#         order[-1] = m\n",
    "        return order\n",
    "        \n",
    "    def __init__(self, dataset, batch_size, repeat=True, shuffle=True):\n",
    "        self.dataset = dataset\n",
    "        self.n = n = len(self.dataset)\n",
    "        self.batch_size = batch_size\n",
    "        self._repeat = repeat\n",
    "\n",
    "        # first decide if dataset is one set of sequences or a zipped set of seequences\n",
    "        if type(self.dataset[0][0]) not in (tuple, list, dict):\n",
    "            # one dataset\n",
    "            self.dataset.sort(key=lambda x:len(x), reverse=True)\n",
    "        else:\n",
    "            # zipped or dict dataset\n",
    "            self.dataset.sort(key=lambda x:len(x[0]), reverse=True)\n",
    "        # then sort them by length of leading (or only) sequence so they are length bucketed\n",
    "        # and sorted by length within minibatches (needed for chainer RNNs)\n",
    "        self.n_batches = n//batch_size if (n % batch_size == 0) else n//batch_size + 1\n",
    "        self.minibatches = [ tuple(self.dataset[i*batch_size:(i+1)*batch_size])\n",
    "                              for i in range(self.n_batches) ]\n",
    "\n",
    "        if shuffle:\n",
    "            self._order = self._anchored_permutation(len(self.minibatches))\n",
    "        else:\n",
    "            self._order = None\n",
    "\n",
    "        self.current_position = 0\n",
    "        self.epoch = 0\n",
    "        self.is_new_epoch = False\n",
    "\n",
    "    def __next__(self):\n",
    "        if not self._repeat and self.epoch > 0:\n",
    "            raise StopIteration\n",
    "\n",
    "        if self._order is not None:\n",
    "            i = self._order[self.current_position]\n",
    "        else:\n",
    "            i = self.current_position\n",
    "        minibatch = self.minibatches[i]\n",
    "        \n",
    "        # last minibatch in epoch\n",
    "        if self.current_position == self.n_batches-1:\n",
    "            self.epoch += 1\n",
    "            self.is_new_epoch = True\n",
    "            self.current_position = 0\n",
    "            if self._order is not None:\n",
    "                self._order = self._anchored_permutation(self._order)\n",
    "        else:\n",
    "            self.is_new_epoch = False\n",
    "            self.current_position += 1\n",
    "        return minibatch\n",
    "    \n",
    "    @property\n",
    "    def epoch_detail(self):\n",
    "        return self.epoch + self.current_position / len(self.dataset)\n",
    "\n",
    "    def serialize(self, serializer):\n",
    "        self.current_position = serializer('current_position',\n",
    "                                           self.current_position)\n",
    "        self.epoch = serializer('epoch', self.epoch)\n",
    "        self.is_new_epoch = serializer('is_new_epoch', self.is_new_epoch)\n",
    "        if self._order is not None:\n",
    "            serializer('_order', self._order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Tagger(ch.Chain):\n",
    "    def __init__(self, embed, lstm_size, out_size):\n",
    "        super(Tagger, self).__init__(\n",
    "            embed = embed,\n",
    "            lstm = ch.links.LSTM(embed.W.shape[1], lstm_size),\n",
    "            out = ch.links.Linear(lstm_size, out_size)\n",
    "        )\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.lstm.reset_state()\n",
    "    \n",
    "    def __call__(self, x_list):\n",
    "        embeds = [ self.embed(x) for x in x_list ]\n",
    "#         print  \"{} steps,\".format(len(x_list)),\n",
    "        start = time.time()\n",
    "        lstms = [ self.lstm(x) for x in embeds ]\n",
    "        s = time.time()-start\n",
    "#         print \"{} secs, {} steps/sec\".format(s, float(len(lstms))/s)\n",
    "        outs = [ self.out(h) for h in lstms ]\n",
    "        return outs\n",
    "    \n",
    "class SequenceLoss(ch.Chain):\n",
    "    def __init__(self, sequence_predictor, \n",
    "                 loss_func=ch.functions.softmax_cross_entropy):\n",
    "        super(SequenceLoss, self).__init__(\n",
    "            sequence_predictor = sequence_predictor\n",
    "        )\n",
    "        self.loss_func = loss_func\n",
    "        \n",
    "    def __call__(self, x_list, y_list):\n",
    "        loss = 0\n",
    "        yhat_list = self.sequence_predictor(x_list)\n",
    "        for yhat, y in zip(yhat_list, y_list):\n",
    "            loss += self.loss_func(yhat, y)\n",
    "        return loss\n",
    "    \n",
    "# class SequencePredict(ch.Chain):\n",
    "#     def __init__(self, predictor):\n",
    "#         super(SequencePredict, self).__init__(\n",
    "#             predictor=predictor\n",
    "#         )\n",
    "    \n",
    "#     def __call__(self, x_list, return_proba=False):\n",
    "#         logits_list = self.predictor(x_list)\n",
    "#         if return_proba:\n",
    "#             probs = [ ch.functions.softmax(logit) for logit in logits_list ]\n",
    "#             return probs\n",
    "#         else:\n",
    "#             preds = [ ch.functions.argmax(logit, axis=1) for logit in logits_list ]\n",
    "#             return preds\n",
    "        \n",
    "def sequence_converter(in_list, device=None):\n",
    "    # note that device is omitted\n",
    "    return ch.functions.transpose_sequence([ ch.Variable(np.array(x, dtype=np.int32))\n",
    "                                             for x in in_list ])\n",
    "def volatile_sequence_converter(in_list, device=None):\n",
    "    # note that device is omitted\n",
    "    return ch.functions.transpose_sequence([ ch.Variable(np.array(x, dtype=np.int32),\n",
    "                                                         volatile=\"AUTO\")\n",
    "                                             for x in in_list ])\n",
    "    \n",
    "class SequenceUpdater(ch.training.StandardUpdater):\n",
    "    def __init__(self, *args, **kwds):\n",
    "        super(SequenceUpdater, self).__init__(*args, **kwds)\n",
    "        self.converter = sequence_converter\n",
    "        \n",
    "    def update_core(self):\n",
    "        batch = self._iterators['main'].next()        \n",
    "\n",
    "        optimizer = self._optimizers['main']\n",
    "        loss_func = self.loss_func or optimizer.target\n",
    "\n",
    "        if isinstance(batch, tuple):\n",
    "            in_vars = tuple([self.converter(x_list) for x_list in zip(*batch)])\n",
    "            optimizer.update(loss_func, *in_vars)\n",
    "        elif isinstance(batch, dict):\n",
    "            in_vars = {key: self.converter(x_list)\n",
    "                       for key, x_list in six.iteritems(batch)}\n",
    "            optimizer.update(loss_func, **in_vars)\n",
    "        else:\n",
    "            in_var = self.converter(batch)\n",
    "            optimizer.update(loss_func, in_var)\n",
    "            \n",
    "import chainer.reporter as reporter_module\n",
    "class SequenceEvaluator(ch.training.extensions.Evaluator):\n",
    "    def __init__(self, *args, **kwds):\n",
    "        super(SequenceEvaluator, self).__init__(*args, **kwds)\n",
    "        self.converter = volatile_sequence_converter\n",
    "        \n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluates the model and returns a result dictionary.\n",
    "\n",
    "        This method runs the evaluation loop over the validation dataset. It\n",
    "        accumulates the reported values to :class:`~chainer.DictSummary` and\n",
    "        returns a dictionary whose values are means computed by the summary.\n",
    "\n",
    "        Users can override this method to customize the evaluation routine.\n",
    "\n",
    "        Returns:\n",
    "            dict: Result dictionary. This dictionary is further reported via\n",
    "                :func:`~chainer.report` without specifying any observer.\n",
    "\n",
    "        \"\"\"\n",
    "        iterator = self._iterators['main']\n",
    "        target = self._targets['main']\n",
    "        eval_func = self.eval_func or target\n",
    "\n",
    "        if self.eval_hook:\n",
    "            self.eval_hook(self)\n",
    "        it = copy.copy(iterator)\n",
    "        summary = reporter_module.DictSummary()\n",
    "\n",
    "        for batch in it:\n",
    "            observation = {}\n",
    "            with reporter_module.report_scope(observation):\n",
    "                if isinstance(batch, tuple):\n",
    "                    in_vars = tuple([self.converter(x_list) for x_list in zip(*batch)])\n",
    "                    eval_func(*in_vars)\n",
    "                elif isinstance(batch, dict):\n",
    "                    in_vars = {key: self.converter(x_list)\n",
    "                               for key, x_list in six.iteritems(batch)}\n",
    "                    eval_func(**in_vars)\n",
    "                else:\n",
    "                    in_var = self.converter(batch)\n",
    "                    eval_func(in_var)\n",
    "            summary.add(observation)\n",
    "\n",
    "        return summary.compute_mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_batch_loss(loss, epoch_i, batch_i, n_batches):\n",
    "    batch_percent = float(batch_i)/n_batches\n",
    "    progress = \"Epoch {0} : [{1}{2}] {3:2.2f}%, Loss = {4:2.6f}\".format(epoch_i,\n",
    "                                                           int(np.floor(batch_percent*10))*'=',\n",
    "                                                           int(np.ceil((1-batch_percent)*10))*'-',\n",
    "                                                           batch_percent*100,\n",
    "                                                           float(loss))\n",
    "#     if batch_i > 2:\n",
    "#         print '\\r',progress,\n",
    "#     else:\n",
    "#         print progress,\n",
    "    print '\\r',progress,\n",
    "\n",
    "def print_epoch_loss(epoch_i, avg_loss, valid_loss, time):\n",
    "    print '\\rEpoch {0} : Avg Loss = {1:2.4f}, Validation Loss = {2:2.4f}, {3} sec'.format(\n",
    "        epoch_i, float(avg_loss), float(valid_loss), np.ceil(int(time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Avg Loss = 1493.4323, Validation Loss = 1499.7939, 19.0 sec\n",
      "Epoch 2 : [=---------] 16.67%, Loss = 220.174210 (1)"
     ]
    }
   ],
   "source": [
    "# data\n",
    "train_iter = BucketedIterator(zip(ix_train, iy_train), 64, repeat=True)\n",
    "valid_iter = BucketedIterator(zip(ix_valid, iy_valid), 64, repeat=True)\n",
    "\n",
    "# hyperparams\n",
    "embedding_size = 50\n",
    "learning_rate = .01\n",
    "\n",
    "# model\n",
    "embed = ch.functions.EmbedID(token_vocab.v, embedding_size)\n",
    "tagger = Tagger(embed, embedding_size, boundary_vocab.v)\n",
    "model_loss = SequenceLoss(tagger)\n",
    "optimizer = ch.optimizers.Adam(learning_rate)\n",
    "# optimizer.use_cleargrads()\n",
    "optimizer.setup(model_loss)\n",
    "\n",
    "# training\n",
    "n_epoch = 20\n",
    "epoch_losses = [[]]\n",
    "valid_losses = []\n",
    "forward_times = [[]]\n",
    "backward_times = [[]]\n",
    "seq_lengths = [[]]\n",
    "for batch in train_iter:\n",
    "    # prepare data and model\n",
    "    x_list, y_list = zip(*batch)\n",
    "    x_list = sequence_converter(x_list)\n",
    "    y_list = sequence_converter(y_list)\n",
    "#     print \"\\rEpoch: {}/{}, Iteration: {}/{}\".format(\n",
    "#         train_iter.epoch+1, n_epoch, train_iter.current_position+1, train_iter.n_batches),\n",
    "#     print \"Longest Sequence: {}\".format(len(x_list))\n",
    "    model_loss.cleargrads()\n",
    "    tagger.reset_state()\n",
    "    seq_lengths[-1].append(len(x_list))\n",
    "    # run model\n",
    "    start = time.time()\n",
    "    loss = model_loss(x_list, y_list)\n",
    "    forward_times[-1].append(time.time()-start)\n",
    "    loss_val = loss.data\n",
    "#     print \"Loss: {}\".format(loss_val),\n",
    "#     print train_iter.current_position+1\n",
    "    print_batch_loss(loss_val, \n",
    "                     train_iter.epoch+1, \n",
    "                     train_iter.current_position, \n",
    "                     train_iter.n_batches)\n",
    "    epoch_losses[-1].append(loss_val)\n",
    "    # backprop\n",
    "    start = time.time()\n",
    "    loss.backward()\n",
    "    optimizer.update()\n",
    "    backward_times[-1].append(time.time()-start)\n",
    "\n",
    "    if train_iter.is_new_epoch:\n",
    "        valid_loss = 0\n",
    "        for valid_batch in valid_iter:\n",
    "            x_list, y_list = zip(*valid_batch)\n",
    "            x_list = sequence_converter(x_list)\n",
    "            y_list = sequence_converter(y_list)\n",
    "            tagger.reset_state()\n",
    "            valid_loss += model_loss(x_list, y_list).data\n",
    "            if valid_iter.is_new_epoch:\n",
    "                break\n",
    "#         print \"Valid Loss: {}\".format(valid_loss)\n",
    "        print_epoch_loss(train_iter.epoch, \n",
    "                         np.mean(epoch_losses[-1]), \n",
    "                         valid_loss, \n",
    "                         time=np.sum(forward_times[-1]+backward_times[-1]))\n",
    "        valid_losses.append(valid_loss)\n",
    "        epoch_losses.append([])\n",
    "        seq_lengths.append([])\n",
    "        forward_times.append([])\n",
    "        backward_times.append([])\n",
    "        if train_iter.epoch == n_epoch:\n",
    "            print \"Done\"\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.figure.Figure at 0x13aba47d0>,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x1379070d0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGJCAYAAACQKdlyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBBkhhBBCpC0JMkIIIYRIW/8fEEkuddHdH9oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13aba47d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curve(epoch_losses, valid_losses,\n",
    "                        logx=False, \n",
    "                        logy=False,\n",
    "                        title='Training Learning Curve',\n",
    "                        xlabel='Epoch',\n",
    "                        ylabel='Loss',\n",
    "                        figsize=(6,4),\n",
    "                        savename=None):\n",
    "    fig, ax = plt.subplots(1, figsize=figsize)\n",
    "    train_means = np.array([ np.mean(epoch_loss) for epoch_loss in epoch_losses ])\n",
    "    train_stds = np.array([ np.std(epoch_loss) for epoch_loss in epoch_losses ])\n",
    "    t = xrange(len(epoch_losses))\n",
    "    ax.plot(t, train_means, 'bo-', lw=2,label='Average Per Epoch Training Loss', markersize=1)\n",
    "    ax.fill_between(t, train_means+train_stds, train_means-train_stds, facecolor='b', alpha=0.15)\n",
    "    ax.plot(range(len(valid_losses)), valid_losses, 'go--', lw=2, label='Per Epoch Validation Loss', markersize=1)\n",
    "    ax.set_title(title)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    if logx:\n",
    "        ax.set_xscale('log')\n",
    "    if logy:\n",
    "        ax.set_yscale('log')\n",
    "    if savename:\n",
    "        fig.savefig(savename)\n",
    "    return fig, ax\n",
    "\n",
    "plot_learning_curve(epoch_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print type(zip(ix_test, iy_test)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_list, y_list = zip(*BucketedIterator(zip(ix_test, iy_test), 1000).next())\n",
    "tagger.reset_state()\n",
    "logits_list = tagger(sequence_converter(x_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_logits(x_list):\n",
    "    x_iter = BucketedIterator(x_list, len(x_list))\n",
    "    order = x_iter._order\n",
    "    x_list = x_iter.next()\n",
    "    tagger.reset_state()\n",
    "    logits_list = [ logits.data for logits in tagger(sequence_converter(x_list)) ]\n",
    "    return logits_list, order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(x_list, y_list, return_proba=False):\n",
    "    # make a single batch out of the data\n",
    "    x_iter = BucketedIterator(zip(x_list, y_list), len(x_list))\n",
    "    x_list, y_list = zip(*x_iter.next())\n",
    "        \n",
    "    # run the model\n",
    "    tagger.reset_state()\n",
    "    logits_list = [ logits.data for logits in tagger(sequence_converter(x_list)) ]\n",
    "    \n",
    "    if return_proba:\n",
    "        probs = [ ch.functions.softmax(logit) for logit in logits_list ]\n",
    "        probs = [ prob.data for prob in ch.functions.transpose_sequence(probs) ]\n",
    "        return probs, x_list, y_list\n",
    "    else:\n",
    "        preds = [ ch.functions.argmax(logit, axis=1) for logit in logits_list ]\n",
    "        preds = [ pred.data for pred in ch.functions.transpose_sequence(preds) ]\n",
    "        return preds, x_list, y_list\n",
    "    \n",
    "preds, x_list, y_list = predict(ix_train, iy_train)\n",
    "preds = convert_sequences(preds, boundary_vocab.token)\n",
    "xs = convert_sequences(x_list, token_vocab.token)\n",
    "ys = convert_sequences(y_list, boundary_vocab.token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161 2673\n",
      "3979 3979\n",
      "< O O\n",
      "DOC O O\n",
      "> O O\n",
      "< O O\n",
      "DOCID O O\n",
      "> O O\n",
      "<UNK> O O\n",
      "< O O\n",
      "/DOCID O O\n",
      "> O O\n",
      "< O O\n",
      "DOCTYPE O O\n",
      "SOURCE=\"broadcast O O\n",
      "news O O\n",
      "\" O O\n",
      "> O O\n",
      "NEWS O O\n",
      "STORY O O\n",
      "< O O\n",
      "/DOCTYPE O O\n",
      "> O O\n",
      "< O O\n",
      "DATETIME O O\n",
      "> O O\n",
      "2003 O O\n",
      "- O O\n",
      "04 O O\n",
      "- O O\n",
      "09 O O\n",
      "<UNK> O O\n",
      "< O O\n",
      "/DATETIME O O\n",
      "> O O\n",
      "< O O\n",
      "BODY O O\n",
      "> O O\n",
      "< O O\n",
      "TEXT O O\n",
      "> O O\n",
      "< O O\n",
      "TURN O O\n",
      "> O O\n",
      "a O O\n",
      "federal O O\n",
      "appeals O O\n",
      "court B B\n",
      "will O O\n",
      "decide O O\n",
      "how O O\n",
      "long O O\n",
      "dirty O O\n",
      "bomb B B\n",
      "suspect O B\n",
      "<UNK> O B\n",
      "<UNK> O I\n",
      "can O O\n",
      "be O O\n",
      "<UNK> O O\n",
      "and O O\n",
      "whether O O\n",
      "he B B\n",
      "can O O\n",
      "meet O O\n",
      "with O O\n",
      "attorneys O B\n",
      ". O O\n",
      "the O O\n",
      "u.s B B\n",
      ". O O\n",
      "attorney B B\n",
      "says O O\n",
      "<UNK> O B\n",
      "is O O\n",
      "an O O\n",
      "enemy O O\n",
      "<UNK> O B\n",
      "and O O\n",
      "not O O\n",
      "<UNK> O O\n",
      "to O O\n",
      "<UNK> O O\n",
      ". O O\n",
      "he B B\n",
      "is O O\n",
      "accused O O\n",
      "of O O\n",
      "<UNK> O O\n",
      "to O O\n",
      "<UNK> O O\n",
      "a O O\n",
      "dirty O O\n",
      "bomb B B\n",
      "in O O\n",
      "this O O\n",
      "country O B\n",
      ". O O\n",
      "< O O\n",
      "/TURN O O\n",
      "> O O\n",
      "< O O\n",
      "/TEXT O O\n",
      "> O O\n",
      "< O O\n",
      "/BODY O O\n",
      "> O O\n",
      "< O O\n",
      "ENDTIME O O\n",
      "> O O\n",
      "2003 O O\n",
      "- O O\n",
      "04 O O\n",
      "- O O\n",
      "09 O O\n",
      "<UNK> O O\n",
      "< O O\n",
      "/ENDTIME O O\n",
      "> O O\n",
      "< O O\n",
      "/DOC O O\n",
      "> O O\n"
     ]
    }
   ],
   "source": [
    "print len(ix_test), len(ix_test[0])\n",
    "print len(preds[0]), len(ys[0])\n",
    "for a,b,c in zip(xs[-1], preds[-1], ys[-1]):\n",
    "    print a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mode(L):\n",
    "    \"\"\" Compute the mode of a list \"\"\"\n",
    "    types = {}\n",
    "    for e in L:\n",
    "        if e in types:\n",
    "            types[e] += 1\n",
    "        else:\n",
    "            types[e] = 1\n",
    "    return sorted(types.items(), reverse=True, key=lambda x:x[1])[0][0]\n",
    "\n",
    "def extract_mentions(seq, typed=True):\n",
    "    \"\"\" We extract mentions approximately according to the BIO or BILOU schemes\n",
    "    with some relaxations.\n",
    "    \n",
    "    We start mentions when we see anything but an 'O'. \n",
    "    We end them when we see an 'O'.\n",
    "    \n",
    "    When computing the type of the mention\n",
    "    we simply take the mode of the types of it's constituent tokens.\n",
    "    \"\"\"\n",
    "    mentions = []\n",
    "    in_mention = False\n",
    "    mention_start = mention_end = 0\n",
    "    for i, s in enumerate(seq):\n",
    "        if not in_mention and s.startswith(('B', 'I', 'L', 'U')):\n",
    "            mention_start = i\n",
    "            in_mention = True\n",
    "        elif in_mention and s == 'O':\n",
    "            if typed:\n",
    "                mention_type = mode([ s.split('-')[-1] for s in seq[mention_start:i] ])\n",
    "            else:\n",
    "                mention_type = 'E'\n",
    "            mentions.append((mention_start, i-1, mention_type))\n",
    "            in_mention=False\n",
    "    if in_mention: # we end on a mention\n",
    "        if typed:\n",
    "            mention_type = mode([ s.split('-')[-1] for s in seq[mention_start:i] ])\n",
    "        else:\n",
    "            mention_type = 'E'\n",
    "        mentions.append((mention_start, i, mention_type))\n",
    "    return mentions\n",
    "    \n",
    "def extract_all_mentions(seqs, typed=True):\n",
    "    return [extract_mentions(seq, typed=typed) for seq in seqs]\n",
    "\n",
    "def mention_precision_recall(true_mentions, pred_mentions):\n",
    "    \"\"\" This function returns the counts of true positives, false positives, and false negatives\n",
    "    which are necessary for calculating precision and recall.\n",
    "    A mention boundary is considered correct if both ends are correct. \n",
    "    \"\"\"\n",
    "    true_mentions = set(true_mentions)\n",
    "    pred_mentions = set(pred_mentions)\n",
    "    tp = len(true_mentions & pred_mentions)\n",
    "    fn = len(true_mentions - pred_mentions)\n",
    "    fp = len(pred_mentions - true_mentions)\n",
    "    return tp, fp, fn\n",
    "\n",
    "def mention_boundary_stats(true_ys, pred_ys, typed=True):\n",
    "    all_true_mentions = extract_all_mentions(true_ys, typed=typed)\n",
    "    all_pred_mentions = extract_all_mentions(pred_ys, typed=typed)\n",
    "    stats = {'tp':0,\n",
    "             'fp':0,\n",
    "             'fn':0}\n",
    "    for true_mentions, pred_mentions in zip(all_true_mentions, all_pred_mentions):\n",
    "        tp, fp, fn = mention_precision_recall(true_mentions, pred_mentions)\n",
    "        stats['tp'] += tp\n",
    "        stats['fp'] += fp\n",
    "        stats['fn'] += fn\n",
    "    stats['precision'] = tp / float(tp + fp)\n",
    "    stats['recall'] = tp / float(tp + fn)\n",
    "    stats['f1'] = 2*stats['precision']*stats['recall']/(stats['precision']+stats['recall'])\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: 0.8571, R: 0.5455, F1: 0.6667\n"
     ]
    }
   ],
   "source": [
    "f1_stats = mention_boundary_stats(ys, preds, typed=True)\n",
    "print \"P: {s[precision]:2.4f}, R: {s[recall]:2.4f}, F1: {s[f1]:2.4f}\".format(s=f1_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chainer Trainer Abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[J     total [..................................................]  0.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "         5 iter, 0 epoch / 10 epochs\n",
      "       inf iters/sec. Estimated time to finish: 0:00:00.\n",
      "\u001b[4A\u001b[J"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-94152e79b8cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# trainer.extend(PrintReport())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/training/trainer.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                             \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/training/extensions/evaluator.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mreporter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mreporter_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-9e7ff06d04a3>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0min_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0meval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0min_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     in_vars = {key: self.converter(x_list)\n",
      "\u001b[0;32m<ipython-input-50-9e7ff06d04a3>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x_list, y_list)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0myhat_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-9e7ff06d04a3>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x_list)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#         print  \"{} steps,\".format(len(x_list)),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mlstms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membeds\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#         print \"{} secs, {} steps/sec\".format(s, float(len(lstms))/s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/links/connection/lstm.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mlstm_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mh_rest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/links/connection/linear.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/functions/connection/linear.pyc\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(x, W, b)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mLinearFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mLinearFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/function.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Forward prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitervalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/functions/connection/linear.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# embed = ch.functions.EmbedID(token_vocab.v, 100)\n",
    "# tagger = Tagger(embed, 100, boundary_vocab.v)\n",
    "# model_loss = SequenceLoss(tagger)\n",
    "# optimizer = ch.optimizers.Adam()\n",
    "# optimizer.use_cleargrads()\n",
    "# optimizer.setup(model_loss)\n",
    "\n",
    "# train_iter = BucketedIterator(zip(ix_train, iy_train), 64, repeat=True)\n",
    "# valid_iter = BucketedIterator(zip(ix_valid, iy_valid), 64, repeat=True)\n",
    "# updater = SequenceUpdater(train_iter, optimizer)\n",
    "# trainer = ch.training.Trainer(updater, (10, 'epoch'), out='result')\n",
    "# trainer.extend(ch.training.extensions.ProgressBar(update_interval=5))\n",
    "# trainer.extend(SequenceEvaluator(valid_iter, model_loss))\n",
    "# # trainer.extend(PrintReport())\n",
    "\n",
    "# trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
