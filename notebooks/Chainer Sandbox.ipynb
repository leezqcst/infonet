{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: This notebook was for dev purposes only.  Not guaranteed to run anymore (and run order is somewhat nonlinear). All relevant code as been moved to the infonet package or in an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import json\n",
    "import io\n",
    "import time\n",
    "import os.path\n",
    "import six\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sb\n",
    "sb.set_color_codes()\n",
    "plt.rcParams['figure.figsize'] = (6,4)\n",
    "\n",
    "import chainer as ch\n",
    "import chainer.training.extensions # for some reason this isn't automatically imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = json.loads(io.open('../data/ace_05_head_yaat.json', 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "class Vocab():\n",
    "    \"\"\" A convenience vocabulary wrapper \n",
    "    \n",
    "    TODO: Add in sampling table functionality\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 tokens=None, \n",
    "                 min_count=5,\n",
    "                 pad_token='<PAD>', \n",
    "                 unk_token='<UNK>'):\n",
    "        self.min_count=min_count\n",
    "        self.pad_token = pad_token\n",
    "        self.unk_token = unk_token\n",
    "        \n",
    "        self.use(tokens)\n",
    "#         self.make_sampling_table()\n",
    "\n",
    "    @property\n",
    "    def n(self):\n",
    "        \"\"\" The total number of tokens seen by the vocabulary.\n",
    "        \n",
    "        This **does not** include tokens which have not been seen `min_count` times\n",
    "        \"\"\"\n",
    "        return self._n\n",
    "\n",
    "    @property\n",
    "    def v(self):\n",
    "        \"\"\" The total number of unique tokens in the vocabulary.\n",
    "        \n",
    "        This **does not** include tokens which have not been seen `min_count` times\n",
    "        \"\"\"\n",
    "        return self._v\n",
    "\n",
    "    @property\n",
    "    def pad(self):\n",
    "        \"\"\" Return the PAD token \"\"\"\n",
    "        return self.pad_token\n",
    "\n",
    "    @property\n",
    "    def ipad(self):\n",
    "        \"\"\" Return the index of the PAD token \"\"\"\n",
    "        return self.idx(self.pad_token)\n",
    "    \n",
    "    @property\n",
    "    def unk(self):\n",
    "        \"\"\" Return the UNK token \"\"\"\n",
    "        return self.unk_token\n",
    "\n",
    "    @property\n",
    "    def iunk(self):\n",
    "        \"\"\" Return the index of the UNK token \"\"\"\n",
    "        return self.idx(self.unk_token)\n",
    "\n",
    "    def idx(self, token):\n",
    "        \"\"\" Return the index of a token or the index of UNK if not in vocab.\n",
    "        \n",
    "        Additionally this will return UNK if the token is in the vocab \n",
    "        but has yet to be seen `min_count` times\n",
    "        \"\"\"\n",
    "        if token == self.pad_token:\n",
    "            return self._vocab2idx[token]\n",
    "        elif token in self.vocabset:\n",
    "            if self.count_index[token] >= self.min_count:\n",
    "                return self._vocab2idx[token]\n",
    "            else:\n",
    "                return self._vocab2idx[self.unk_token]\n",
    "        else:\n",
    "            return self._vocab2idx[self.unk_token]\n",
    "\n",
    "    def token(self, idx):\n",
    "        \"\"\" Return the token corresponding to the input index `idx`.\n",
    "        \n",
    "        If the index is not in the vocabulary, or it is the index\n",
    "        of a token that has not been seen `min_count` times,\n",
    "        the UNK token is returned instead\n",
    "        \"\"\"\n",
    "        if idx in self.idxset:\n",
    "            token = self._idx2vocab[idx]\n",
    "            if self.count_index[token] >= self.min_count:\n",
    "                return token\n",
    "            else:\n",
    "                return self.unk_token\n",
    "        else:\n",
    "            return self.unk_token\n",
    "\n",
    "    def use(self, tokens):\n",
    "        \"\"\" Create the vocabulary, using these tokens.\n",
    "        \n",
    "        This method will reset the vocab with these tokens.\n",
    "        \n",
    "        `tokens` is expected to be a flat list.\n",
    "        \"\"\"\n",
    "        self.count_index = Counter()\n",
    "        self._vocab2idx = {self.pad_token:0,\n",
    "                           self.unk_token:1}\n",
    "        self._idx2vocab = {0:self.pad_token,\n",
    "                           1:self.unk_token}\n",
    "        if tokens:\n",
    "            self.add(tokens)\n",
    "\n",
    "    def add(self, tokens):\n",
    "        \"\"\" Add these tokens to the vocabulary.\n",
    "        \n",
    "        This can be used iteratively, adding, say, one sentence at a time.\n",
    "        \n",
    "        NOTE: Expects `tokens` to be a flat list.\n",
    "        \"\"\"\n",
    "        # increment counts of tokens seen here\n",
    "        for token in tokens:\n",
    "            self.count_index[token] += 1\n",
    "        \n",
    "        # add tokens to the vocabulary if they are new\n",
    "        token_set = set(tokens)\n",
    "        for token in token_set:\n",
    "            if token not in self._vocab2idx:\n",
    "                new_idx = len(self._vocab2idx)\n",
    "                self._vocab2idx[token] = new_idx\n",
    "                self._idx2vocab[new_idx] = token\n",
    "        \n",
    "        # now precompute commonly used properties of the vocab (ignoring infrequent tokens)\n",
    "        self.vocabset = set([ token for (token, count) in self.count_index.most_common()\n",
    "                              if count >= self.min_count ]) \n",
    "        self.vocabset |= set([self.pad_token, self.unk_token])\n",
    "        self.idxset = set([ self._vocab2idx[token] for token in self.vocabset ])\n",
    "        self._n = sum( count for count in self.count_index.values() if count >= self.min_count )\n",
    "        self._v = sum( 1 for count in self.count_index.values() if count >= self.min_count ) + 2 # <PAD> and <UNK>\n",
    "        \n",
    "    def drop_infrequent(self):\n",
    "        \"\"\" Drop all words from the vocabulary that have not been seen `min_count` times\n",
    "        and recompute the vocabulary indices.\n",
    "        \n",
    "        This is useful for when the vocab has a long tail of infrequent words\n",
    "        that we no longer wish to account for.\n",
    "        \n",
    "        NOTE: This changes indices of tokens in the vocab!\n",
    "        \"\"\"\n",
    "        # remove all infrequent tokens from the count index\n",
    "        to_remove = set(self.count_index.keys()) - self.vocabset\n",
    "        for token in to_remove:\n",
    "            self.count_index.pop(token)\n",
    "            \n",
    "        # now reset the vocab dicts and reindex the tokens\n",
    "        self._vocab2idx = {self.pad_token:0,\n",
    "                           self.unk_token:1}\n",
    "        self._idx2vocab = {0:self.pad_token,\n",
    "                           1:self.unk_token}\n",
    "        for token in self.count_index.keys():\n",
    "            new_idx = len(self._vocab2idx)\n",
    "            self._vocab2idx[token] = new_idx\n",
    "            self._idx2vocab[new_idx] = token\n",
    "            \n",
    "        # precompute commonly used properties of the vocab\n",
    "        self.vocabset = set(self._vocab2idx.keys())\n",
    "        self.idxset = set(self._idx2vocab.keys())\n",
    "        self._n = sum( count for count in self.count_index.values() )\n",
    "        self._v = len(self._vocab2idx)\n",
    "\n",
    "    def count(self, token):\n",
    "        \"\"\" Get the count of a token.  \n",
    "        \n",
    "        This includes tokens with countes below `min_count`,\n",
    "        which have been seen but are not included in the vocab.\n",
    "        \"\"\"\n",
    "        return self.count_index[token]\n",
    "\n",
    "#     def make_sampling_table(self, power_scalar=.75):\n",
    "#         # from 0 to V-1, get the frequency\n",
    "#         self.vocab_distribution = np.array([ (self.count_index[self._idx2vocab[idx]]/float(self._n))**power_scalar\n",
    "#                                     for idx in range(len(self.idxset))])\n",
    "#         self.vocab_distribution /= np.sum(self.vocab_distribution).astype(np.float)\n",
    "\n",
    "#     def sample(self, sample_shape):\n",
    "#         # sample a tensor of indices\n",
    "#         # by walking up the CDF\n",
    "#         # setting each position to the index\n",
    "#         # of the word which is the closest\n",
    "#         # word with that CDF\n",
    "#         sums = np.zeros(sample_shape)\n",
    "#         rands = npr.uniform(size=sample_shape)\n",
    "#         idxs = np.zeros(sample_shape)\n",
    "#         for i in range(len(self.vocab_distribution)):\n",
    "#             sums += self.vocab_distribution[i]\n",
    "#             idxs[sums <= rands] = i\n",
    "#         return idxs.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Entity_BIO_map(mention_labels, annotation):\n",
    "    \"\"\" Uses BIO scheme (untyped) for entities only \"\"\"\n",
    "    if annotation['node-type'] == 'entity':\n",
    "        left, right = tuple(annotation['ann-span'])\n",
    "        mention_labels[left] = 'B'\n",
    "        for i in range(1, right-left+1):\n",
    "            mention_labels[left+i] = 'I'\n",
    "    return mention_labels\n",
    "\n",
    "def Entity_typed_BIO_map(mention_labels, annotation):\n",
    "    \"\"\" Uses BIO scheme (typed) for entities only \"\"\"\n",
    "    if annotation['node-type'] == 'entity':\n",
    "        mention_type = annotation['type']\n",
    "        left, right = tuple(annotation['ann-span'])\n",
    "        mention_labels[left] = 'B-'+mention_type\n",
    "        for i in range(1, right-left+1):\n",
    "            mention_labels[left+i] = 'I-'+mention_type\n",
    "    return mention_labels\n",
    "\n",
    "def Entity_BILOU_map(mention_labels, annotation):\n",
    "    \"\"\" Uses BILOU scheme (untyped) for entities only \"\"\"\n",
    "    if annotation['node-type'] == 'entity':\n",
    "        left, right = tuple(annotation['ann-span'])\n",
    "        if left == right:\n",
    "            mention_labels[left] = 'U'\n",
    "        else:\n",
    "            mention_labels[left] = 'B'\n",
    "            for i in range(1, right-left):\n",
    "                mention_labels[left+i] = 'I'\n",
    "            mention_labels[right] = 'L'\n",
    "    return mention_labels\n",
    "\n",
    "def Entity_typed_BILOU_map(mention_labels, annotation):\n",
    "    \"\"\" Uses BILOU scheme (typed) for entities only \"\"\"\n",
    "    if annotation['node-type'] == 'entity':\n",
    "        mention_type = annotation['type']\n",
    "        left, right = tuple(annotation['ann-span'])\n",
    "        if left == right:\n",
    "            mention_labels[left] = 'U-'+mention_type\n",
    "        else:\n",
    "            mention_labels[left] = 'B-'+mention_type\n",
    "            for i in range(1, right-left):\n",
    "                mention_labels[left+i] = 'I-'+mention_type\n",
    "            mention_labels[right] = 'L-'+mention_type\n",
    "    return mention_labels\n",
    "\n",
    "def compute_flat_mention_labels(doc, scheme_func=Entity_BIO_map):\n",
    "    \"\"\" Takes a YAAT style document and computes token-level mention label list.\n",
    "    \n",
    "    This function only considers the outermost spans (as per ACE evaluation)\n",
    "    by editing the mentions of shortest span-length to longest.\n",
    "    Thus wider mentions will override narrower nested mentions.\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    \n",
    "    tokens: ['part', 'of' , 'mention', '.', 'not', 'part']\n",
    "    with annotation: {'ann-type':'node',\n",
    "                      'node-type':'entity',\n",
    "                      'ann-span':[0,2]}\n",
    "    with scheme: BIO\n",
    "    \n",
    "    yields:\n",
    "    mention_labels = ['B', 'I', 'I', 'O', 'O', 'O']\n",
    "    \"\"\"\n",
    "    mention_labels = ['O' for token in doc['tokens']]\n",
    "    mentions = [ annotation for annotation in doc['annotations'] if annotation['ann-type'] == 'node' ]\n",
    "    for annotation in sorted(mentions, key=lambda x:x['ann-span'][1]-x['ann-span'][0]):\n",
    "        mention_labels = scheme_func(mention_labels, annotation)\n",
    "    return mention_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324491 total tokens and 4826 types with mincount > 5\n"
     ]
    }
   ],
   "source": [
    "token_vocab = Vocab(min_count=5)\n",
    "for doc in data.values():\n",
    "    token_vocab.add(doc['tokens'])\n",
    "print '{} total tokens and {} types with mincount > 5'.format(token_vocab.n, token_vocab.v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of O\n",
      "al B\n",
      "qaeda I\n",
      ". O\n",
      "they O\n",
      "may O\n",
      "have O\n",
      "been O\n",
      "timed O\n",
      "to O\n"
     ]
    }
   ],
   "source": [
    "doc['boundary_labels'] = compute_flat_mention_labels(doc, Entity_BIO_map)\n",
    "for token, label in zip(doc['tokens'], doc['boundary_labels'])[100:110]:\n",
    "    print token, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boundary_vocab = Vocab(min_count=0)\n",
    "for doc in data.values():\n",
    "    doc['boundary_labels'] = compute_flat_mention_labels(doc, Entity_BIO_map)\n",
    "    boundary_vocab.add(doc['boundary_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321 train, 53 validation, and 161 test documents\n"
     ]
    }
   ],
   "source": [
    "xy = [(doc['tokens'], doc['boundary_labels']) for doc in data.values()]\n",
    "npr.shuffle(xy)\n",
    "\n",
    "valid_split = int(len(xy)*.6)\n",
    "test_split = int(len(xy)*.8)\n",
    "xy_train, xy_valid, xy_test = xy[:valid_split], xy[valid_split:test_split], xy[test_split:]\n",
    "\n",
    "x_train = [d[0] for d in xy_train]\n",
    "y_train = [d[1] for d in xy_train]\n",
    "x_valid = [d[0] for d in xy_valid]\n",
    "y_valid = [d[1] for d in xy_valid]\n",
    "x_test = [d[0] for d in xy_test]\n",
    "y_test = [d[1] for d in xy_test]\n",
    "\n",
    "print '{} train, {} validation, and {} test documents'.format(len(x_train), len(x_valid), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # create an additional training set that is split on sentences\n",
    "# def split_sentences(doc_x, doc_y):\n",
    "#     xs, ys = [], []\n",
    "#     sent_x, sent_y = [], []\n",
    "#     for x, y in zip(doc_x, doc_y):\n",
    "#         if x == '.':\n",
    "#             sent_x.append(x)\n",
    "#             sent_y.append(y)\n",
    "#             xs.append(sent_x)\n",
    "#             ys.append(sent_y)\n",
    "#             sent_x = []\n",
    "#             sent_y = []\n",
    "#         else:\n",
    "#             sent_x.append(x)\n",
    "#             sent_y.append(y)\n",
    "#     return xs, ys\n",
    "\n",
    "# def split_all_docs(xs, ys):\n",
    "#     all_xs, all_ys = [], []\n",
    "#     for x,y in zip(xs, ys):\n",
    "#         sent_xs, sent_ys = split_sentences(x, y)\n",
    "#         all_xs.extend(sent_xs)\n",
    "#         all_ys.extend(sent_ys)\n",
    "#     return all_xs, all_ys\n",
    "\n",
    "# x_sent_train, y_sent_train = split_all_docs(x_train, y_train)\n",
    "# x_sent_test, y_sent_test = split_all_docs(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# before we do conversions, we need to drop unfrequent words from the vocab and reindex it\n",
    "token_vocab.drop_infrequent()\n",
    "boundary_vocab.drop_infrequent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_sequence(sequence, conversion_func):\n",
    "    return [ conversion_func(s) for s in sequence ]\n",
    "\n",
    "def convert_sequences(sequences, conversion_func):\n",
    "    return [ convert_sequence(sequence, conversion_func) for sequence in sequences ]\n",
    "\n",
    "ix_train = convert_sequences(x_train, token_vocab.idx)\n",
    "ix_valid = convert_sequences(x_valid, token_vocab.idx)\n",
    "ix_test = convert_sequences(x_test, token_vocab.idx)\n",
    "iy_train = convert_sequences(y_train, boundary_vocab.idx)\n",
    "iy_valid = convert_sequences(y_valid, boundary_vocab.idx)\n",
    "iy_test = convert_sequences(y_test, boundary_vocab.idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bucketed iterator for the variable length sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BucketedIterator(ch.dataset.iterator.Iterator):\n",
    "    def _anchored_permutation(self, order):\n",
    "        \"\"\" Randomized permutation except last element is alway the largest.\n",
    "        \n",
    "        Used for bucketed rnn batches where the last batch may \n",
    "        (and if so must) be smaller than the rest.\n",
    "        \"\"\"\n",
    "        order = npr.permutation(order)\n",
    "#         m = np.max(order)\n",
    "#         order[order==m] = order[-1]\n",
    "#         order[-1] = m\n",
    "        return order\n",
    "        \n",
    "    def __init__(self, dataset, batch_size, repeat=True, shuffle=True):\n",
    "        self.dataset = dataset\n",
    "        self.n = n = len(self.dataset)\n",
    "        self.batch_size = batch_size\n",
    "        self._repeat = repeat\n",
    "\n",
    "        # first decide if dataset is one set of sequences or a zipped set of seequences\n",
    "        if type(self.dataset[0][0]) not in (tuple, list, dict):\n",
    "            # one dataset\n",
    "            self.dataset.sort(key=lambda x:len(x), reverse=True)\n",
    "        else:\n",
    "            # zipped or dict dataset\n",
    "            self.dataset.sort(key=lambda x:len(x[0]), reverse=True)\n",
    "        # then sort them by length of leading (or only) sequence so they are length bucketed\n",
    "        # and sorted by length within minibatches (needed for chainer RNNs)\n",
    "        self.n_batches = n//batch_size if (n % batch_size == 0) else n//batch_size + 1\n",
    "        self.minibatches = [ tuple(self.dataset[i*batch_size:(i+1)*batch_size])\n",
    "                              for i in range(self.n_batches) ]\n",
    "\n",
    "        if shuffle:\n",
    "            self._order = self._anchored_permutation(len(self.minibatches))\n",
    "        else:\n",
    "            self._order = None\n",
    "\n",
    "        self.current_position = 0\n",
    "        self.epoch = 0\n",
    "        self.is_new_epoch = False\n",
    "\n",
    "    def __next__(self):\n",
    "        if not self._repeat and self.epoch > 0:\n",
    "            raise StopIteration\n",
    "\n",
    "        if self._order is not None:\n",
    "            i = self._order[self.current_position]\n",
    "        else:\n",
    "            i = self.current_position\n",
    "        minibatch = self.minibatches[i]\n",
    "        \n",
    "        # last minibatch in epoch\n",
    "        if self.current_position == self.n_batches-1:\n",
    "            self.epoch += 1\n",
    "            self.is_new_epoch = True\n",
    "            self.current_position = 0\n",
    "            if self._order is not None:\n",
    "                self._order = self._anchored_permutation(self._order)\n",
    "        else:\n",
    "            self.is_new_epoch = False\n",
    "            self.current_position += 1\n",
    "        return minibatch\n",
    "    \n",
    "    @property\n",
    "    def epoch_detail(self):\n",
    "        return self.epoch + self.current_position / len(self.dataset)\n",
    "\n",
    "    def serialize(self, serializer):\n",
    "        self.current_position = serializer('current_position',\n",
    "                                           self.current_position)\n",
    "        self.epoch = serializer('epoch', self.epoch)\n",
    "        self.is_new_epoch = serializer('is_new_epoch', self.is_new_epoch)\n",
    "        if self._order is not None:\n",
    "            serializer('_order', self._order)\n",
    "            \n",
    "class SequenceIterator(ch.dataset.iterator.Iterator):\n",
    "    def __init__(self, dataset, batch_size, repeat=True, shuffle=True):\n",
    "        self.dataset = dataset\n",
    "        self.n = n = len(self.dataset)\n",
    "        self.batch_size = batch_size\n",
    "        self._repeat = repeat\n",
    "        self.shuffle = shuffle\n",
    "        self.n_batches = n//batch_size if (n % batch_size == 0) else n//batch_size + 1\n",
    "\n",
    "        if shuffle:\n",
    "            npr.shuffle(self.dataset)\n",
    "\n",
    "        self.current_position = 0\n",
    "        self.epoch = 0\n",
    "        self.is_new_epoch = False\n",
    "\n",
    "    def __next__(self):\n",
    "        if not self._repeat and self.epoch > 0:\n",
    "            raise StopIteration\n",
    "\n",
    "        i = self.current_position\n",
    "        minibatch = self.dataset[i*self.batch_size:(i+1)*self.batch_size]\n",
    "        # minibatches must be sorted by descending sequence len\n",
    "        # sort key changes if dataset is one set of sequences or a zipped set of seequences\n",
    "        if type(self.dataset[0][0]) not in (tuple, list, dict):\n",
    "            # one dataset\n",
    "            minibatch.sort(key=lambda x:len(x), reverse=True)\n",
    "        else:\n",
    "            # zipped or dict dataset\n",
    "            minibatch.sort(key=lambda x:len(x[0]), reverse=True)\n",
    "        \n",
    "        # last minibatch in epoch\n",
    "        if self.current_position == self.n_batches-1:\n",
    "            self.epoch += 1\n",
    "            self.is_new_epoch = True\n",
    "            self.current_position = 0\n",
    "            if self.shuffle:\n",
    "                npr.shuffle(self.dataset)\n",
    "        else:\n",
    "            self.is_new_epoch = False\n",
    "            self.current_position += 1\n",
    "\n",
    "        return minibatch\n",
    "    \n",
    "    @property\n",
    "    def epoch_detail(self):\n",
    "        return self.epoch + self.current_position / len(self.dataset)\n",
    "\n",
    "    def serialize(self, serializer):\n",
    "        self.current_position = serializer('current_position',\n",
    "                                           self.current_position)\n",
    "        self.epoch = serializer('epoch', self.epoch)\n",
    "        self.is_new_epoch = serializer('is_new_epoch', self.is_new_epoch)\n",
    "        if self._order is not None:\n",
    "            serializer('_order', self._order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class Tagger(ch.Chain):\n",
    "    def __init__(self, embed, lstm_size, out_size):\n",
    "        super(Tagger, self).__init__(\n",
    "            embed = embed,\n",
    "            lstm = ch.links.LSTM(embed.W.shape[1], lstm_size),\n",
    "            out = ch.links.Linear(lstm_size, out_size)\n",
    "        )\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.lstm.reset_state()\n",
    "    \n",
    "    def __call__(self, x_list):\n",
    "        embeds = [ self.embed(x) for x in x_list ]\n",
    "        lstms = [ self.lstm(x) for x in embeds ]\n",
    "        outs = [ self.out(h) for h in lstms ]\n",
    "        return outs, lstms\n",
    "    \n",
    "class TaggerLoss(ch.Chain):\n",
    "    def __init__(self, tagger, \n",
    "                 loss_func=ch.functions.softmax_cross_entropy):\n",
    "        super(TaggerLoss, self).__init__(\n",
    "            tagger = tagger\n",
    "        )\n",
    "        self.loss_func = loss_func\n",
    "        \n",
    "    def __call__(self, x_list, y_list):\n",
    "        loss = 0\n",
    "        yhat_list,_ = self.tagger(x_list)\n",
    "        for yhat, y in zip(yhat_list, y_list):\n",
    "            loss += self.loss_func(yhat, y)\n",
    "        return loss\n",
    "    \n",
    "class Extractor(ch.Chain):\n",
    "    def __init__(self, \n",
    "                 feature_size,\n",
    "                 n_mention_class,\n",
    "                 n_relation_class,\n",
    "                 in_tags=(1,2), \n",
    "                 out_tags=(0,),\n",
    "                 max_rel_dist=10000):\n",
    "        super(Extractor, self).__init__(\n",
    "            f_m=ch.links.Linear(feature_size, n_mention_class),\n",
    "            f_r=ch.links.Linear(2*feature_size, n_relation_class)\n",
    "        )\n",
    "#         self.f_m.W.data = npr.randint((feature_size, n_mention_class))\n",
    "        self.in_tags = in_tags\n",
    "        self.out_tags = out_tags\n",
    "        self.max_rel_dist = max_rel_dist\n",
    "        \n",
    "    def _extract_graph(self, tagger_preds, tagger_features):\n",
    "        # convert from time-major to batch-major\n",
    "        tagger_preds = ch.functions.transpose_sequence(tagger_preds)\n",
    "        tagger_features = ch.functions.transpose_sequence(tagger_features)\n",
    "#         print len(tagger_preds)\n",
    "        \n",
    "        # extract the mentions and relations for each doc\n",
    "        all_boundaries = extract_all_mentions(tagger_preds, \n",
    "                                              in_tags=self.in_tags, \n",
    "                                              out_tags=self.out_tags)\n",
    "#         print 'N', [len(b) for b in all_boundaries]\n",
    "        all_mentions = []\n",
    "        all_relation_idxs = []\n",
    "        all_left_mentions = []\n",
    "        all_right_mentions = []\n",
    "        for s, (boundaries, seq, features) in enumerate(zip(all_boundaries, tagger_preds, tagger_features)):\n",
    "            mentions = []\n",
    "            relation_idxs = []\n",
    "            left_mentions = []\n",
    "            right_mentions = []\n",
    "            for i, b in enumerate(boundaries):\n",
    "                mention = ch.functions.sum(features[b[0]:b[1]], axis=0)\n",
    "                mentions.append(mention)\n",
    "                # make a relation of to all previous mentions (M choose 2)\n",
    "                for j in range(i):\n",
    "                    if abs(boundaries[j][0] - b[0]) < self.max_rel_dist:\n",
    "                        print '\\rDoc: {} R({},{})'.format(s, j, i),\n",
    "                        relation_idxs.append([j,i])\n",
    "                        left_mentions.append(mentions[j])\n",
    "                        right_mentions.append(mentions[i])\n",
    "            print 'Stacking...',\n",
    "            if mentions:\n",
    "                mentions = ch.functions.vstack(mentions)\n",
    "                print 'm=',mentions.shape,\n",
    "            all_mentions.append(mentions)\n",
    "            if left_mentions:\n",
    "                left_mentions = ch.functions.vstack(left_mentions)\n",
    "                print 'l=',left_mentions.shape,\n",
    "            all_left_mentions.append(left_mentions)\n",
    "            if right_mentions:\n",
    "                right_mentions = ch.functions.vstack(right_mentions)\n",
    "                print 'r=',right_mentions.shape,\n",
    "            all_right_mentions.append(right_mentions)\n",
    "            all_relation_idxs.append(relation_idxs)\n",
    "            print 'Done'\n",
    "        return all_mentions, all_left_mentions, all_right_mentions, all_relation_idxs\n",
    "    \n",
    "    def __call__(self, tagger_logits, tagger_features):\n",
    "        tagger_preds = [ ch.functions.argmax(logit, axis=1) for logit in tagger_logits ]\n",
    "        start = time.time()\n",
    "        mentions, l_mentions, r_mentions, rel_idxs = self._extract_graph(    \n",
    "            tagger_preds, \n",
    "            tagger_features)\n",
    "        # concat left and right mentions into one relation vector\n",
    "        relations = [ ch.functions.concat(m, axis=1) if type(m[0]) is ch.Variable else m[0]\n",
    "                             for m in zip(l_mentions, r_mentions) ]\n",
    "        # score mentions and relations\n",
    "#         print mentions[0].shape\n",
    "        m_logits = [ self.f_m(m) if type(m) is ch.Variable else []\n",
    "                     for m in mentions ]\n",
    "        r_logits = [ self.f_r(r) if type(r) is ch.Variable else []\n",
    "                     for r in relations ]\n",
    "        return m_logits, r_logits, rel_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_mentions(seq, \n",
    "                     in_tags=('B', 'I', 'L', 'U'), \n",
    "                     out_tags=('O'), \n",
    "                     typemap=False):\n",
    "    \"\"\" We extract mentions approximately according to the BIO or BILOU schemes\n",
    "    with some relaxations.\n",
    "    \n",
    "    We start mentions when we see anything but an 'O'. \n",
    "    We end them when we see an 'O'.\n",
    "    \n",
    "    When computing the type of the mention\n",
    "    we simply take the mode of the types of it's constituent tokens.\n",
    "    \"\"\"\n",
    "    if type(seq[0]) == ch.Variable:\n",
    "        seq = [ s.data for s in seq ]\n",
    "        \n",
    "    mentions = []\n",
    "    in_mention = False\n",
    "    mention_start = mention_end = 0\n",
    "    for i, s in enumerate(seq):\n",
    "        if not in_mention and s in in_tags:\n",
    "            mention_start = i\n",
    "            in_mention = True\n",
    "        elif in_mention and s in out_tags:\n",
    "            if typemap:\n",
    "                mention_type = mode([ typemap[s] for s in seq[mention_start:i] ])\n",
    "            else:\n",
    "                mention_type = None\n",
    "            mentions.append((mention_start, i, mention_type))\n",
    "            in_mention=False\n",
    "    if in_mention: # we end on a mention\n",
    "        if typemap:\n",
    "            mention_type = mode([ typemap[s] for s in seq[mention_start:i] ])\n",
    "        else:\n",
    "            mention_type = None\n",
    "        mentions.append((mention_start, i+1, mention_type))\n",
    "    return mentions\n",
    "    \n",
    "def extract_all_mentions(seqs, **kwds):\n",
    "    return [extract_mentions(seq, **kwds) for seq in seqs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x = ch.Variable(np.array([2,0,1]))\n",
    "# reorder = np.argsort(x.data)\n",
    "# print reorder\n",
    "# x.data = x.data[reorder]\n",
    "# print x.data\n",
    "# x = x[:1]\n",
    "# print x.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_batch_loss(loss, epoch_i, batch_i, n_batches):\n",
    "    batch_percent = float(batch_i)/n_batches\n",
    "    progress = \"Epoch {0} : [{1}{2}] {3:2.2f}%, Loss = {4:2.6f}\".format(epoch_i,\n",
    "                                                           int(np.floor(batch_percent*10))*'=',\n",
    "                                                           int(np.ceil((1-batch_percent)*10))*'-',\n",
    "                                                           batch_percent*100,\n",
    "                                                           float(loss))\n",
    "    print '\\r',progress,\n",
    "\n",
    "def print_epoch_loss(epoch_i, avg_loss, valid_loss, time):\n",
    "    print '\\rEpoch {0} : Avg Loss = {1:2.4f}, Validation Loss = {2:2.4f}, {3} sec'.format(\n",
    "        epoch_i, float(avg_loss), float(valid_loss), np.ceil(int(time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<PAD>', 1: '<UNK>', 2: 'I', 3: 'B', 4: 'O'}"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_vocab._idx2vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sequence_converter(x_list):\n",
    "    return [ np.array(x, dtype=np.int32) for x in x_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data\n",
    "print \"setting up...\",\n",
    "train_iter = SequenceIterator(zip(ix_train, iy_train), 256, repeat=True)\n",
    "valid_iter = SequenceIterator(zip(ix_valid, iy_valid), 256, repeat=True)\n",
    "\n",
    "# hyperparams\n",
    "embedding_size = 50\n",
    "learning_rate = .01\n",
    "\n",
    "# model\n",
    "# embed = ch.functions.EmbedID(token_vocab.v, embedding_size)\n",
    "# tagger = Tagger(embed, embedding_size, boundary_vocab.v)\n",
    "extractor = Extractor(embedding_size, 5, 6,\n",
    "                      in_tags=(2,3),\n",
    "                      out_tags=(0,4), \n",
    "                      max_rel_dist=100)\n",
    "# model_loss = TaggerLoss(tagger)\n",
    "optimizer = ch.optimizers.Adam(learning_rate)\n",
    "# optimizer.use_cleargrads()\n",
    "optimizer.setup(model_loss)\n",
    "print \"Done\"\n",
    "# training\n",
    "n_epoch = 50\n",
    "best_valid_loss = 1e50\n",
    "epoch_losses = [[]]\n",
    "valid_losses = []\n",
    "forward_times = [[]]\n",
    "backward_times = [[]]\n",
    "seq_lengths = [[]]\n",
    "fit_start = time.time()\n",
    "for batch in train_iter:\n",
    "    # prepare data and model\n",
    "    x_list, y_list = zip(*batch)\n",
    "    x_list = sequence_converter(x_list)\n",
    "    y_list = sequence_converter(y_list)\n",
    "    model_loss.cleargrads()\n",
    "    tagger.reset_state()\n",
    "    seq_lengths[-1].append(len(x_list))\n",
    "    # run model\n",
    "    start = time.time()\n",
    "    loss = model_loss(x_list, y_list)\n",
    "    forward_times[-1].append(time.time()-start)\n",
    "    loss_val = loss.data\n",
    "    \n",
    "\n",
    "#         print 'e', e\n",
    "#     print \"Loss: {}\".format(loss_val),\n",
    "#     print train_iter.current_position+1\n",
    "    print_batch_loss(loss_val, \n",
    "                     train_iter.epoch+1, \n",
    "                     train_iter.current_position, \n",
    "                     train_iter.n_batches)\n",
    "    epoch_losses[-1].append(loss_val)\n",
    "    # backprop\n",
    "    start = time.time()\n",
    "    loss.backward()\n",
    "    optimizer.update()\n",
    "    backward_times[-1].append(time.time()-start)\n",
    "    \n",
    "    # extractor model\n",
    "    if train_iter.epoch > 0:\n",
    "        logits, hs = tagger(x_list)\n",
    "        start = time.time()\n",
    "        e = extractor(logits, hs)\n",
    "        print '{} sec, {} nodes, {} edges'.format(time.time()-start, \n",
    "                                                  np.sum(a.shape[0] for a in e[0]),\n",
    "                                                  np.sum(a.shape[0] for a in e[1]))\n",
    "\n",
    "    if train_iter.is_new_epoch:\n",
    "        valid_loss = 0\n",
    "        for valid_batch in valid_iter:\n",
    "            x_list, y_list = zip(*valid_batch)\n",
    "            x_list = sequence_converter(x_list)\n",
    "            y_list = sequence_converter(y_list)\n",
    "            tagger.reset_state()\n",
    "            valid_loss += model_loss(x_list, y_list).data\n",
    "            if valid_iter.is_new_epoch:\n",
    "                break\n",
    "#         print \"Valid Loss: {}\".format(valid_loss)\n",
    "        print_epoch_loss(train_iter.epoch, \n",
    "                         np.mean(epoch_losses[-1]), \n",
    "                         valid_loss, \n",
    "                         time=np.sum(forward_times[-1]+backward_times[-1]))\n",
    "        valid_losses.append(valid_loss)\n",
    "        epoch_losses.append([])\n",
    "        seq_lengths.append([])\n",
    "        forward_times.append([])\n",
    "        backward_times.append([])\n",
    "        # save best\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            ch.serializers.save_npz('tagger.model', tagger)\n",
    "        if train_iter.epoch == n_epoch:\n",
    "            print \"Training finished. {} epochs in {} seconds\".format(n_epoch, time.time()-fit_start)\n",
    "            print 'Restoring best model...',\n",
    "            ch.serializers.load_npz('tagger.model', tagger)\n",
    "            print 'Done'\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ch.serializers.load_npz('tagger.model', tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.figure.Figure at 0x1224cc050>,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x124de8150>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGJCAYAAAC3h1iaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1224cc050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curve(epoch_losses, valid_losses,\n",
    "                        logx=False, \n",
    "                        logy=False,\n",
    "                        title='Training Learning Curve',\n",
    "                        xlabel='Epoch',\n",
    "                        ylabel='Loss',\n",
    "                        figsize=(6,4),\n",
    "                        savename=None):\n",
    "    fig, ax = plt.subplots(1, figsize=figsize)\n",
    "    train_means = np.array([ np.mean(epoch_loss) for epoch_loss in epoch_losses ])\n",
    "    train_stds = np.array([ np.std(epoch_loss) for epoch_loss in epoch_losses ])\n",
    "    t = xrange(len(epoch_losses))\n",
    "    ax.plot(t, train_means, 'bo-', lw=2,label='Average Per Epoch Training Loss', markersize=1)\n",
    "    ax.fill_between(t, train_means+train_stds, train_means-train_stds, facecolor='b', alpha=0.15)\n",
    "    ax.plot(range(len(valid_losses)), valid_losses, 'go--', lw=2, label='Per Epoch Validation Loss', markersize=1)\n",
    "    ax.set_title(title)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    if logx:\n",
    "        ax.set_xscale('log')\n",
    "    if logy:\n",
    "        ax.set_yscale('log')\n",
    "    if savename:\n",
    "        fig.savefig(savename)\n",
    "    return fig, ax\n",
    "\n",
    "plot_learning_curve(epoch_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(x_list, y_list, return_proba=False):\n",
    "    # make a single batch out of the data\n",
    "    x_iter = BucketedIterator(zip(x_list, y_list), len(x_list))\n",
    "    x_list, y_list = zip(*x_iter.next())\n",
    "        \n",
    "    # run the model\n",
    "    tagger.reset_state()\n",
    "    logits_list, _ = tagger(sequence_converter(x_list)) \n",
    "    logits_list = [ logits.data for logits in logits_list ]\n",
    "    \n",
    "    if return_proba:\n",
    "        probs = [ ch.functions.softmax(logit) for logit in logits_list ]\n",
    "        probs = [ prob.data for prob in ch.functions.transpose_sequence(probs) ]\n",
    "        return probs, x_list, y_list\n",
    "    else:\n",
    "        preds = [ ch.functions.argmax(logit, axis=1) for logit in logits_list ]\n",
    "        preds = [ pred.data for pred in ch.functions.transpose_sequence(preds) ]\n",
    "        return preds, x_list, y_list\n",
    "    \n",
    "def model_graph(x_list, out_fname):\n",
    "    x_iter = BucketedIterator(x_list, len(x_list))\n",
    "    x_list = x_iter.next()\n",
    "        \n",
    "    # run the model\n",
    "    tagger.reset_state()\n",
    "    logits_list = tagger(sequence_converter(x_list))\n",
    "    g = ch.computational_graph.build_computational_graph(logits_list)\n",
    "    with open(out_fname, 'w') as o:\n",
    "        o.write(g.dump())\n",
    "    print \"Done.  Render {}\".format(out_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print len(ix_test), len(ix_test[0])\n",
    "# print len(preds[0]), len(ys[0])\n",
    "# for a,b,c in zip(xs[-1], preds[-1], ys[-1]):\n",
    "#     print a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mode(L):\n",
    "    \"\"\" Compute the mode of a list \"\"\"\n",
    "    types = {}\n",
    "    for e in L:\n",
    "        if e in types:\n",
    "            types[e] += 1\n",
    "        else:\n",
    "            types[e] = 1\n",
    "    return sorted(types.items(), reverse=True, key=lambda x:x[1])[0][0]\n",
    "\n",
    "def extract_mentions(seq, typed=True):\n",
    "    \"\"\" We extract mentions approximately according to the BIO or BILOU schemes\n",
    "    with some relaxations.\n",
    "    \n",
    "    We start mentions when we see anything but an 'O'. \n",
    "    We end them when we see an 'O'.\n",
    "    \n",
    "    When computing the type of the mention\n",
    "    we simply take the mode of the types of it's constituent tokens.\n",
    "    \"\"\"\n",
    "    mentions = []\n",
    "    in_mention = False\n",
    "    mention_start = mention_end = 0\n",
    "    for i, s in enumerate(seq):\n",
    "        if not in_mention and s.startswith(('B', 'I', 'L', 'U')):\n",
    "            mention_start = i\n",
    "            in_mention = True\n",
    "        elif in_mention and s == 'O':\n",
    "            if typed:\n",
    "                mention_type = mode([ s.split('-')[-1] for s in seq[mention_start:i] ])\n",
    "            else:\n",
    "                mention_type = 'E'\n",
    "            mentions.append((mention_start, i-1, mention_type))\n",
    "            in_mention=False\n",
    "    if in_mention: # we end on a mention\n",
    "        if typed:\n",
    "            mention_type = mode([ s.split('-')[-1] for s in seq[mention_start:i] ])\n",
    "        else:\n",
    "            mention_type = 'E'\n",
    "        mentions.append((mention_start, i, mention_type))\n",
    "    return mentions\n",
    "    \n",
    "def extract_all_mentions(seqs, typed=True):\n",
    "    return [extract_mentions(seq, typed=typed) for seq in seqs]\n",
    "\n",
    "def mention_precision_recall(true_mentions, pred_mentions):\n",
    "    \"\"\" This function returns the counts of true positives, false positives, and false negatives\n",
    "    which are necessary for calculating precision and recall.\n",
    "    A mention boundary is considered correct if both ends are correct. \n",
    "    \"\"\"\n",
    "    true_mentions = set(true_mentions)\n",
    "    pred_mentions = set(pred_mentions)\n",
    "    tp = len(true_mentions & pred_mentions)\n",
    "    fn = len(true_mentions - pred_mentions)\n",
    "    fp = len(pred_mentions - true_mentions)\n",
    "    return tp, fp, fn\n",
    "\n",
    "def mention_boundary_stats(true_ys, pred_ys, typed=True):\n",
    "    all_true_mentions = extract_all_mentions(true_ys, typed=typed)\n",
    "    all_pred_mentions = extract_all_mentions(pred_ys, typed=typed)\n",
    "    stats = {'tp':0,\n",
    "             'fp':0,\n",
    "             'fn':0}\n",
    "    for true_mentions, pred_mentions in zip(all_true_mentions, all_pred_mentions):\n",
    "        tp, fp, fn = mention_precision_recall(true_mentions, pred_mentions)\n",
    "        stats['tp'] += tp\n",
    "        stats['fp'] += fp\n",
    "        stats['fn'] += fn\n",
    "    stats['precision'] = tp / float(tp + fp +1e-15)\n",
    "    stats['recall'] = tp / float(tp + fn +1e-15)\n",
    "    stats['f1'] = 2*stats['precision']*stats['recall']/(stats['precision']+stats['recall']+1e-15)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< B O\n",
      "DOC I O\n",
      "> B O\n",
      "< B O\n",
      "DOCID O O\n",
      "> O O\n",
      "<UNK> O O\n",
      "< B O\n",
      "/DOCID I O\n",
      "> B O\n",
      "< B O\n",
      "DOCTYPE B O\n",
      "SOURCE=\"broadcast <UNK> O\n",
      "news I O\n",
      "\" I O\n",
      "> B O\n",
      "NEWS <UNK> O\n",
      "STORY <UNK> O\n",
      "< B O\n",
      "/DOCTYPE B O\n",
      "> B O\n",
      "< B O\n",
      "DATETIME B O\n",
      "> B O\n",
      "2003 B O\n",
      "- <UNK> O\n",
      "04 I O\n",
      "- <UNK> O\n",
      "09 <UNK> O\n",
      "<UNK> O O\n",
      "< B O\n",
      "/DATETIME O O\n",
      "> B O\n",
      "< B O\n",
      "BODY O O\n",
      "> B O\n",
      "< B O\n",
      "TEXT I O\n",
      "> B O\n",
      "< B O\n",
      "TURN O O\n",
      "> B O\n",
      "a <UNK> O\n",
      "federal <UNK> O\n",
      "appeals <UNK> O\n",
      "court <UNK> B\n",
      "will O O\n",
      "decide I O\n",
      "how I O\n",
      "long <UNK> O\n",
      "dirty <UNK> O\n",
      "bomb <UNK> B\n",
      "suspect I B\n",
      "<UNK> O B\n",
      "<UNK> O I\n",
      "can I O\n",
      "be <PAD> O\n",
      "<UNK> O O\n",
      "and O O\n",
      "whether I O\n",
      "he <PAD> B\n",
      "can B O\n",
      "meet B O\n",
      "with B O\n",
      "attorneys B B\n",
      ". B O\n",
      "the B O\n",
      "u.s B B\n",
      ". O O\n",
      "attorney I B\n",
      "says O O\n",
      "<UNK> O B\n",
      "is O O\n",
      "an <PAD> O\n",
      "enemy <UNK> O\n",
      "<UNK> O B\n",
      "and O O\n",
      "not O O\n",
      "<UNK> O O\n",
      "to O O\n",
      "<UNK> O O\n",
      ". I O\n",
      "he <PAD> B\n",
      "is <PAD> O\n",
      "accused <UNK> O\n",
      "of B O\n",
      "<UNK> <PAD> O\n",
      "to I O\n",
      "<UNK> <PAD> O\n",
      "a <UNK> O\n",
      "dirty <UNK> O\n",
      "bomb <UNK> B\n",
      "in B O\n",
      "this <PAD> O\n",
      "country O B\n",
      ". O O\n",
      "< B O\n",
      "/TURN B O\n",
      "> B O\n",
      "< B O\n",
      "/TEXT <UNK> O\n",
      "> B O\n",
      "< B O\n",
      "/BODY O O\n",
      "> O O\n",
      "< B O\n",
      "ENDTIME B O\n",
      "> B O\n",
      "2003 B O\n",
      "- O O\n",
      "04 I O\n",
      "- <UNK> O\n",
      "09 <UNK> O\n",
      "<UNK> O O\n",
      "< B O\n",
      "/ENDTIME I O\n",
      "> B O\n",
      "< B O\n",
      "/DOC <PAD> O\n",
      "> B O\n"
     ]
    }
   ],
   "source": [
    "for a,b,c in zip(xs[-1], preds[-1], ys[-1]):\n",
    "    print a,b,c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chainer Trainer Abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[J     total [..................................................]  0.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "         5 iter, 0 epoch / 10 epochs\n",
      "       inf iters/sec. Estimated time to finish: 0:00:00.\n",
      "\u001b[4A\u001b[J"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-94152e79b8cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# trainer.extend(PrintReport())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/training/trainer.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                             \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/training/extensions/evaluator.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mreporter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mreporter_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-9e7ff06d04a3>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0min_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0meval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0min_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     in_vars = {key: self.converter(x_list)\n",
      "\u001b[0;32m<ipython-input-50-9e7ff06d04a3>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x_list, y_list)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0myhat_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-9e7ff06d04a3>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x_list)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#         print  \"{} steps,\".format(len(x_list)),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mlstms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membeds\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#         print \"{} secs, {} steps/sec\".format(s, float(len(lstms))/s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/links/connection/lstm.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mlstm_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mh_rest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/links/connection/linear.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/functions/connection/linear.pyc\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(x, W, b)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mLinearFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mLinearFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/function.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Forward prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitervalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thomaseffland/.virtualenvs/research/lib/python2.7/site-packages/chainer/functions/connection/linear.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# embed = ch.functions.EmbedID(token_vocab.v, 100)\n",
    "# tagger = Tagger(embed, 100, boundary_vocab.v)\n",
    "# model_loss = SequenceLoss(tagger)\n",
    "# optimizer = ch.optimizers.Adam()\n",
    "# optimizer.use_cleargrads()\n",
    "# optimizer.setup(model_loss)\n",
    "\n",
    "# train_iter = BucketedIterator(zip(ix_train, iy_train), 64, repeat=True)\n",
    "# valid_iter = BucketedIterator(zip(ix_valid, iy_valid), 64, repeat=True)\n",
    "# updater = SequenceUpdater(train_iter, optimizer)\n",
    "# trainer = ch.training.Trainer(updater, (10, 'epoch'), out='result')\n",
    "# trainer.extend(ch.training.extensions.ProgressBar(update_interval=5))\n",
    "# trainer.extend(SequenceEvaluator(valid_iter, model_loss))\n",
    "# # trainer.extend(PrintReport())\n",
    "\n",
    "# trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print npr.shuffle([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1453079729188098211"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'abc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-206-bcff80e9d78d>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-206-bcff80e9d78d>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    return ch.functions.transpose_sequence([ ch.Variable(np.array(x, dtype=np.int32))\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "def sequence_converter(in_list, device=None):\n",
    "    # note that device is omitted\n",
    "    return ch.functions.transpose_sequence([ ch.Variable(np.array(x, dtype=np.int32))\n",
    "                                             for x in in_list ])\n",
    "def volatile_sequence_converter(in_list, device=None):\n",
    "    # note that device is omitted\n",
    "    return ch.functions.transpose_sequence([ ch.Variable(np.array(x, dtype=np.int32),\n",
    "                                                         volatile=\"AUTO\")\n",
    "                                             for x in in_list ])\n",
    "    \n",
    "class SequenceUpdater(ch.training.StandardUpdater):\n",
    "    def __init__(self, *args, **kwds):\n",
    "        super(SequenceUpdater, self).__init__(*args, **kwds)\n",
    "        self.converter = sequence_converter\n",
    "        \n",
    "    def update_core(self):\n",
    "        batch = self._iterators['main'].next()        \n",
    "\n",
    "        optimizer = self._optimizers['main']\n",
    "        loss_func = self.loss_func or optimizer.target\n",
    "\n",
    "        if isinstance(batch, tuple):\n",
    "            in_vars = tuple([self.converter(x_list) for x_list in zip(*batch)])\n",
    "            optimizer.update(loss_func, *in_vars)\n",
    "        elif isinstance(batch, dict):\n",
    "            in_vars = {key: self.converter(x_list)\n",
    "                       for key, x_list in six.iteritems(batch)}\n",
    "            optimizer.update(loss_func, **in_vars)\n",
    "        else:\n",
    "            in_var = self.converter(batch)\n",
    "            optimizer.update(loss_func, in_var)\n",
    "            \n",
    "import chainer.reporter as reporter_module\n",
    "class SequenceEvaluator(ch.training.extensions.Evaluator):\n",
    "    def __init__(self, *args, **kwds):\n",
    "        super(SequenceEvaluator, self).__init__(*args, **kwds)\n",
    "        self.converter = volatile_sequence_converter\n",
    "        \n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluates the model and returns a result dictionary.\n",
    "\n",
    "        This method runs the evaluation loop over the validation dataset. It\n",
    "        accumulates the reported values to :class:`~chainer.DictSummary` and\n",
    "        returns a dictionary whose values are means computed by the summary.\n",
    "\n",
    "        Users can override this method to customize the evaluation routine.\n",
    "\n",
    "        Returns:\n",
    "            dict: Result dictionary. This dictionary is further reported via\n",
    "                :func:`~chainer.report` without specifying any observer.\n",
    "\n",
    "        \"\"\"\n",
    "        iterator = self._iterators['main']\n",
    "        target = self._targets['main']\n",
    "        eval_func = self.eval_func or target\n",
    "\n",
    "        if self.eval_hook:\n",
    "            self.eval_hook(self)\n",
    "        it = copy.copy(iterator)\n",
    "        summary = reporter_module.DictSummary()\n",
    "\n",
    "        for batch in it:\n",
    "            observation = {}\n",
    "            with reporter_module.report_scope(observation):\n",
    "                if isinstance(batch, tuple):\n",
    "                    in_vars = tuple([self.converter(x_list) for x_list in zip(*batch)])\n",
    "                    eval_func(*in_vars)\n",
    "                elif isinstance(batch, dict):\n",
    "                    in_vars = {key: self.converter(x_list)\n",
    "                               for key, x_list in six.iteritems(batch)}\n",
    "                    eval_func(**in_vars)\n",
    "                else:\n",
    "                    in_var = self.converter(batch)\n",
    "                    eval_func(in_var)\n",
    "            summary.add(observation)\n",
    "\n",
    "        return summary.compute_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import chainer as ch\n",
    "embed = ch.links.EmbedID(2,2)\n",
    "class Embed(ch.Chain):\n",
    "    def __init__(self, embed):\n",
    "        super(Embed, self).__init__(\n",
    "            embed_name = embed\n",
    "        )\n",
    "    def __call__(self, x):\n",
    "        return self.embed(x)\n",
    "    \n",
    "e1 = Embed(embed)\n",
    "e2 = Embed(embed.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1446f5988a84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'B'.startswith(('O', 'S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-41ea69ff204e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m'B'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "'B'.split('-')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([3,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
