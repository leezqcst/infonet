{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import json\n",
    "from io import open\n",
    "import time\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sb\n",
    "sb.set_color_codes()\n",
    "plt.rcParams['figure.figsize'] = (6,4)\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data and convert it to the NER task format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = json.loads(open('../data/ace_05_head_yaat.json', 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "class Vocab():\n",
    "    \"\"\" A convenience vocabulary wrapper \n",
    "    \n",
    "    TODO: Add in sampling table functionality\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 tokens=None, \n",
    "                 min_count=5,\n",
    "                 pad_token='<PAD>', \n",
    "                 unk_token='<UNK>'):\n",
    "        self.min_count=min_count\n",
    "        self.pad_token = pad_token\n",
    "        self.unk_token = unk_token\n",
    "        \n",
    "        self.use(tokens)\n",
    "#         self.make_sampling_table()\n",
    "\n",
    "    @property\n",
    "    def n(self):\n",
    "        \"\"\" The total number of tokens seen by the vocabulary.\n",
    "        \n",
    "        This **does not** include tokens which have not been seen `min_count` times\n",
    "        \"\"\"\n",
    "        return self._n\n",
    "\n",
    "    @property\n",
    "    def v(self):\n",
    "        \"\"\" The total number of unique tokens in the vocabulary.\n",
    "        \n",
    "        This **does not** include tokens which have not been seen `min_count` times\n",
    "        \"\"\"\n",
    "        return self._v\n",
    "\n",
    "    @property\n",
    "    def pad(self):\n",
    "        \"\"\" Return the PAD token \"\"\"\n",
    "        return self.pad_token\n",
    "\n",
    "    @property\n",
    "    def ipad(self):\n",
    "        \"\"\" Return the index of the PAD token \"\"\"\n",
    "        return self.idx(self.pad_token)\n",
    "    \n",
    "    @property\n",
    "    def unk(self):\n",
    "        \"\"\" Return the UNK token \"\"\"\n",
    "        return self.unk_token\n",
    "\n",
    "    @property\n",
    "    def iunk(self):\n",
    "        \"\"\" Return the index of the UNK token \"\"\"\n",
    "        return self.idx(self.unk_token)\n",
    "\n",
    "    def idx(self, token):\n",
    "        \"\"\" Return the index of a token or the index of UNK if not in vocab.\n",
    "        \n",
    "        Additionally this will return UNK if the token is in the vocab \n",
    "        but has yet to be seen `min_count` times\n",
    "        \"\"\"\n",
    "        if token == self.pad_token:\n",
    "            return self._vocab2idx[token]\n",
    "        elif token in self.vocabset:\n",
    "            if self.count_index[token] >= self.min_count:\n",
    "                return self._vocab2idx[token]\n",
    "            else:\n",
    "                return self._vocab2idx[self.unk_token]\n",
    "        else:\n",
    "            return self._vocab2idx[self.unk_token]\n",
    "\n",
    "    def token(self, idx):\n",
    "        \"\"\" Return the token corresponding to the input index `idx`.\n",
    "        \n",
    "        If the index is not in the vocabulary, or it is the index\n",
    "        of a token that has not been seen `min_count` times,\n",
    "        the UNK token is returned instead\n",
    "        \"\"\"\n",
    "        if idx in self.idxset:\n",
    "            token = self._idx2vocab[idx]\n",
    "            if self.count_index[token] >= self.min_count:\n",
    "                return token\n",
    "            else:\n",
    "                return self._idx2vocab[self.unk_token]\n",
    "        else:\n",
    "            return self._idx2vocab[self.unk_token]\n",
    "\n",
    "    def use(self, tokens):\n",
    "        \"\"\" Create the vocabulary, using these tokens.\n",
    "        \n",
    "        This method will reset the vocab with these tokens.\n",
    "        \n",
    "        `tokens` is expected to be a flat list.\n",
    "        \"\"\"\n",
    "        self.count_index = Counter()\n",
    "        self._vocab2idx = {self.pad_token:0,\n",
    "                           self.unk_token:1}\n",
    "        self._idx2vocab = {0:self.pad_token,\n",
    "                           1:self.unk_token}\n",
    "        if tokens:\n",
    "            self.add(tokens)\n",
    "\n",
    "    def add(self, tokens):\n",
    "        \"\"\" Add these tokens to the vocabulary.\n",
    "        \n",
    "        This can be used iteratively, adding, say, one sentence at a time.\n",
    "        \n",
    "        NOTE: Expects `tokens` to be a flat list.\n",
    "        \"\"\"\n",
    "        # increment counts of tokens seen here\n",
    "        for token in tokens:\n",
    "            self.count_index[token] += 1\n",
    "        \n",
    "        # add tokens to the vocabulary if they are new\n",
    "        token_set = set(tokens)\n",
    "        for token in token_set:\n",
    "            if token not in self._vocab2idx:\n",
    "                new_idx = len(self._vocab2idx)\n",
    "                self._vocab2idx[token] = new_idx\n",
    "                self._idx2vocab[new_idx] = token\n",
    "        \n",
    "        # now precompute commonly used properties of the vocab (ignoring infrequent tokens)\n",
    "        self.vocabset = set([ token for (token, count) in self.count_index.most_common()\n",
    "                              if count >= self.min_count ]) \n",
    "        self.vocabset |= set([self.pad_token, self.unk_token])\n",
    "        self.idxset = set([ self._vocab2idx[token] for token in self.vocabset ])\n",
    "        self._n = sum( count for count in self.count_index.values() if count >= self.min_count )\n",
    "        self._v = sum( 1 for count in self.count_index.values() if count >= self.min_count ) + 2 # <PAD> and <UNK>\n",
    "        \n",
    "    def drop_infrequent(self):\n",
    "        \"\"\" Drop all words from the vocabulary that have not been seen `min_count` times\n",
    "        and recompute the vocabulary indices.\n",
    "        \n",
    "        This is useful for when the vocab has a long tail of infrequent words\n",
    "        that we no longer wish to account for.\n",
    "        \n",
    "        NOTE: This changes indices of tokens in the vocab!\n",
    "        \"\"\"\n",
    "        # remove all infrequent tokens from the count index\n",
    "        to_remove = set(self.count_index.keys()) - self.vocabset\n",
    "        for token in to_remove:\n",
    "            self.count_index.pop(token)\n",
    "            \n",
    "        # now reset the vocab dicts and reindex the tokens\n",
    "        self._vocab2idx = {self.pad_token:0,\n",
    "                           self.unk_token:1}\n",
    "        self._idx2vocab = {0:self.pad_token,\n",
    "                           1:self.unk_token}\n",
    "        for token in self.count_index.keys():\n",
    "            new_idx = len(self._vocab2idx)\n",
    "            self._vocab2idx[token] = new_idx\n",
    "            self._idx2vocab[new_idx] = token\n",
    "            \n",
    "        # precompute commonly used properties of the vocab\n",
    "        self.vocabset = set(self._vocab2idx.keys())\n",
    "        self.idxset = set(self._idx2vocab.keys())\n",
    "        self._n = sum( count for count in self.count_index.values() )\n",
    "        self._v = len(self._vocab2idx)\n",
    "\n",
    "    def count(self, token):\n",
    "        \"\"\" Get the count of a token.  \n",
    "        \n",
    "        This includes tokens with countes below `min_count`,\n",
    "        which have been seen but are not included in the vocab.\n",
    "        \"\"\"\n",
    "        return self.count_index[token]\n",
    "\n",
    "#     def make_sampling_table(self, power_scalar=.75):\n",
    "#         # from 0 to V-1, get the frequency\n",
    "#         self.vocab_distribution = np.array([ (self.count_index[self._idx2vocab[idx]]/float(self._n))**power_scalar\n",
    "#                                     for idx in range(len(self.idxset))])\n",
    "#         self.vocab_distribution /= np.sum(self.vocab_distribution).astype(np.float)\n",
    "\n",
    "#     def sample(self, sample_shape):\n",
    "#         # sample a tensor of indices\n",
    "#         # by walking up the CDF\n",
    "#         # setting each position to the index\n",
    "#         # of the word which is the closest\n",
    "#         # word with that CDF\n",
    "#         sums = np.zeros(sample_shape)\n",
    "#         rands = npr.uniform(size=sample_shape)\n",
    "#         idxs = np.zeros(sample_shape)\n",
    "#         for i in range(len(self.vocab_distribution)):\n",
    "#             sums += self.vocab_distribution[i]\n",
    "#             idxs[sums <= rands] = i\n",
    "#         return idxs.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348986 total tokens and 20192 types\n",
      "324491 total tokens and 4826 types with mincount > 5\n"
     ]
    }
   ],
   "source": [
    "token_vocab = Vocab(min_count=0)\n",
    "for doc in data.values():\n",
    "    token_vocab.add(doc['tokens'])\n",
    "print '{} total tokens and {} types'.format(token_vocab.n, token_vocab.v)\n",
    "\n",
    "token_vocab = Vocab(min_count=5)\n",
    "for doc in data.values():\n",
    "    token_vocab.add(doc['tokens'])\n",
    "print '{} total tokens and {} types with mincount > 5'.format(token_vocab.n, token_vocab.v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'event-anchor', u'value', u'entity'])\n"
     ]
    }
   ],
   "source": [
    "mention_types = set([ annotation['node-type'] for doc in data.values() for annotation in doc['annotations']\n",
    "                      if annotation['ann-type'] == 'node'])\n",
    "print mention_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for doc in data.values()[:1]:\n",
    "#     for annotation in doc['annotations']:\n",
    "#         if annotation['ann-type'] == 'node':\n",
    "#             print annotation['ann-span']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Entity_BIO_map(mention_labels, annotation):\n",
    "    \"\"\" Uses BIO scheme (untyped) for entities only \"\"\"\n",
    "    if annotation['node-type'] == 'entity':\n",
    "        left, right = tuple(annotation['ann-span'])\n",
    "        mention_labels[left] = 'B'\n",
    "        for i in range(1, right-left+1):\n",
    "            mention_labels[left+i] = 'I'\n",
    "    return mention_labels\n",
    "\n",
    "def Entity_typed_BIO_map(mention_labels, annotation):\n",
    "    \"\"\" Uses BIO scheme (typed) for entities only \"\"\"\n",
    "    if annotation['node-type'] == 'entity':\n",
    "        mention_type = annotation['type']\n",
    "        left, right = tuple(annotation['ann-span'])\n",
    "        mention_labels[left] = 'B-'+mention_type\n",
    "        for i in range(1, right-left+1):\n",
    "            mention_labels[left+i] = 'I-'+mention_type\n",
    "    return mention_labels\n",
    "\n",
    "def Entity_BILOU_map(mention_labels, annotation):\n",
    "    \"\"\" Uses BILOU scheme (untyped) for entities only \"\"\"\n",
    "    if annotation['node-type'] == 'entity':\n",
    "        left, right = tuple(annotation['ann-span'])\n",
    "        if left == right:\n",
    "            mention_labels[left] = 'U'\n",
    "        else:\n",
    "            mention_labels[left] = 'B'\n",
    "            for i in range(1, right-left):\n",
    "                mention_labels[left+i] = 'I'\n",
    "            mention_labels[right] = 'L'\n",
    "    return mention_labels\n",
    "\n",
    "def Entity_typed_BILOU_map(mention_labels, annotation):\n",
    "    \"\"\" Uses BILOU scheme (typed) for entities only \"\"\"\n",
    "    if annotation['node-type'] == 'entity':\n",
    "        mention_type = annotation['type']\n",
    "        left, right = tuple(annotation['ann-span'])\n",
    "        if left == right:\n",
    "            mention_labels[left] = 'U-'+mention_type\n",
    "        else:\n",
    "            mention_labels[left] = 'B-'+mention_type\n",
    "            for i in range(1, right-left):\n",
    "                mention_labels[left+i] = 'I-'+mention_type\n",
    "            mention_labels[right] = 'L-'+mention_type\n",
    "    return mention_labels\n",
    "\n",
    "def compute_flat_mention_labels(doc, scheme_func=Entity_BIO_map):\n",
    "    \"\"\" Takes a YAAT style document and computes token-level mention label list.\n",
    "    \n",
    "    This function only considers the outermost spans (as per ACE evaluation)\n",
    "    by editing the mentions of shortest span-length to longest.\n",
    "    Thus wider mentions will override narrower nested mentions.\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    \n",
    "    tokens: ['part', 'of' , 'mention', '.', 'not', 'part']\n",
    "    with annotation: {'ann-type':'node',\n",
    "                      'node-type':'entity',\n",
    "                      'ann-span':[0,2]}\n",
    "    with scheme: BIO\n",
    "    \n",
    "    yields:\n",
    "    mention_labels = ['B', 'I', 'I', 'O', 'O', 'O']\n",
    "    \"\"\"\n",
    "    mention_labels = ['O' for token in doc['tokens']]\n",
    "    mentions = [ annotation for annotation in doc['annotations'] if annotation['ann-type'] == 'node' ]\n",
    "    for annotation in sorted(mentions, key=lambda x:x['ann-span'][1]-x['ann-span'][0]):\n",
    "        mention_labels = scheme_func(mention_labels, annotation)\n",
    "    return mention_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of O\n",
      "al B-ORG\n",
      "qaeda L-ORG\n",
      ". O\n",
      "they O\n",
      "may O\n",
      "have O\n",
      "been O\n",
      "timed O\n",
      "to O\n"
     ]
    }
   ],
   "source": [
    "doc['boundary_labels'] = compute_flat_mention_labels(doc, Entity_typed_BILOU_map)\n",
    "for token, label in zip(doc['tokens'], doc['boundary_labels'])[100:110]:\n",
    "    print token, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boundary_vocab = Vocab(min_count=0)\n",
    "for doc in data.values():\n",
    "    doc['boundary_labels'] = compute_flat_mention_labels(doc, Entity_BIO_map)\n",
    "    boundary_vocab.add(doc['boundary_labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374 train documents and 161 test documents\n"
     ]
    }
   ],
   "source": [
    "xy = [(doc['tokens'], doc['boundary_labels']) for doc in data.values()]\n",
    "npr.shuffle(xy)\n",
    "\n",
    "test_split = int(len(xy)*.7)\n",
    "xy_train, xy_test = xy[:test_split], xy[test_split:]\n",
    "\n",
    "x_train = [d[0] for d in xy_train]\n",
    "y_train = [d[1] for d in xy_train]\n",
    "x_test = [d[0] for d in xy_test]\n",
    "y_test = [d[1] for d in xy_test]\n",
    "\n",
    "print '{} train documents and {} test documents'.format(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an additional training set that is split on sentences\n",
    "def split_sentences(doc_x, doc_y):\n",
    "    xs, ys = [], []\n",
    "    sent_x, sent_y = [], []\n",
    "    for x, y in zip(doc_x, doc_y):\n",
    "        if x == '.':\n",
    "            sent_x.append(x)\n",
    "            sent_y.append(y)\n",
    "            xs.append(sent_x)\n",
    "            ys.append(sent_y)\n",
    "            sent_x = []\n",
    "            sent_y = []\n",
    "        else:\n",
    "            sent_x.append(x)\n",
    "            sent_y.append(y)\n",
    "    return xs, ys\n",
    "\n",
    "def split_all_docs(xs, ys):\n",
    "    all_xs, all_ys = [], []\n",
    "    for x,y in zip(xs, ys):\n",
    "        sent_xs, sent_ys = split_sentences(x, y)\n",
    "        all_xs.extend(sent_xs)\n",
    "        all_ys.extend(sent_ys)\n",
    "    return all_xs, all_ys\n",
    "\n",
    "x_sent_train, y_sent_train = split_all_docs(x_train, y_train)\n",
    "x_sent_test, y_sent_test = split_all_docs(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# before we do conversions, we need to drop unfrequent words from the vocab and reindex it\n",
    "token_vocab.drop_infrequent()\n",
    "boundary_vocab.drop_infrequent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BatchGenerator():\n",
    "    \"\"\" Generates batches of the data\"\"\"\n",
    "    def __init__(self, x, y, batch_size=64):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        if len(self.x) % self.batch_size:\n",
    "            # batch size doesn't divide the data\n",
    "            # so we will have a remainder (smaller) batch\n",
    "            self.n_batches = len(self.x) // self.batch_size + 1 \n",
    "        else:\n",
    "            self.n_batches = len(self.x) // self.batch_size\n",
    "        \n",
    "    def __iter__(self):\n",
    "        xy = zip(self.x, self.y)\n",
    "        npr.shuffle(xy)\n",
    "        \n",
    "        # chunk it into batches\n",
    "        batches = [ xy[i*self.batch_size:(i+1)*self.batch_size] \n",
    "                   for i in range(len(xy)//self.batch_size)]\n",
    "        \n",
    "        # iterate over the batches, unpacking into x,y\n",
    "        for batch in batches:\n",
    "            yield zip(*batch)\n",
    "            \n",
    "class BucketedBatchGenerator():\n",
    "    \"\"\" Generates batches of that have approximately homogenous sequence lengths w/in batch\"\"\"\n",
    "    def __init__(self, x, y, batch_size=64):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        if len(self.x) % self.batch_size:\n",
    "            # batch size doesn't divide the data\n",
    "            # so we will have a remainder (smaller) batch\n",
    "            self.n_batches = len(self.x) // self.batch_size + 1 \n",
    "        else:\n",
    "            self.n_batches = len(self.x) // self.batch_size\n",
    "        \n",
    "    def __iter__(self):\n",
    "        # sort data from shortest to longest\n",
    "        xy = sorted(zip(self.x, self.y), key=lambda x:len(x[0]))\n",
    "        # now chunk it into batches\n",
    "        batches = [ xy[i*self.batch_size:(i+1)*self.batch_size] \n",
    "                   for i in range(len(xy)//self.batch_size)]\n",
    "        # shuffle the batches\n",
    "        npr.shuffle(batches)\n",
    "        \n",
    "        # iterate over the batches, shuffling and unpacking into x,y\n",
    "        for batch in batches:\n",
    "            npr.shuffle(batch)\n",
    "            yield zip(*batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_mentions(seqs):#, features):\n",
    "    \"\"\" Iterate over a batch of sequences, extracting the mentions encoded in them.\n",
    "    \n",
    "    Args:\n",
    "      seqs: Tensor with shape [batch_size, max_timesteps]\n",
    "      \n",
    "    Returns:\n",
    "      mentions: Tensor with shape [batch_size, max_extracted_mentions, 3].\n",
    "        This tensor is padded to the max number of extracted mentions.\n",
    "        The final dimension `3` encodes mention metadata where:\n",
    "          0: mention left boundary index `i`\n",
    "          1: mention right boundary index `j` (inclusive)\n",
    "          2: mention group\n",
    "      mentions_mask: Tensor with shape [batch_size, max_extracted_mentions].\n",
    "        This tensor encodes the `pad` locations of the mentions tensor.\n",
    "        \n",
    "    Example (pseudocode):\n",
    "      # fake sequences [ O B I O B I I O ]\n",
    "      #                [ B I O O O B O B ]\n",
    "      fake_tagged_seqs = np.array([[0,1,2,0,1,2,2,0],\n",
    "                             [1,2,0,1,0,1,0,1]])\n",
    "                             \n",
    "      mentions = extract_mentions(seqs, outside_token) \n",
    "      print mentions[:,:,0] # starting boundaries\n",
    "      >>> [[ 1  4 -1 -1]\n",
    "           [ 0  3  5  7]]\n",
    "      print mentions[:,:,1] # end boundaries (inclusive)\n",
    "      >>> [[ 2  6 -1 -1]\n",
    "           [ 1  3  5  7]]\n",
    "            \n",
    "    \"\"\" \n",
    "    def _sparse_update(update_mask, stitch_range, update_range, old_values, new_values):\n",
    "        \"\"\" Return as sparsely updated tensor according to the mask.\n",
    "        \n",
    "        This allows for scattered updates to a `Tensor` (not just a `Variable`)\n",
    "        by using dynamic stitch to overwrite values\"\"\"\n",
    "        update_indices = tf.boolean_mask(update_range, update_mask)\n",
    "        update_values = tf.boolean_mask(new_values, update_mask)\n",
    "        return tf.dynamic_stitch([stitch_range, update_indices],\n",
    "                                 [old_values, update_values])\n",
    "    \n",
    "    begin_tokens = tf.constant([[1]])\n",
    "#     outside_tokens = tf.constant([[0]])\n",
    "    outside_token = tf.constant(0)\n",
    "    def _start_new_mention(tags):\n",
    "        start_new_mention = tf.reduce_any(tf.equal(tags, begin_tokens), \n",
    "                                      reduction_indices=[0])\n",
    "        start_new_mention.set_shape((None,))\n",
    "        return start_new_mention\n",
    "    \n",
    "    def _in_mention(tags):\n",
    "        in_mention = tf.not_equal(tags, outside_token)\n",
    "        return in_mention\n",
    "    \n",
    "    def _end_current_mention(start_new_mention, in_mention, already_in_mention):\n",
    "        start_or_out = tf.logical_or(start_new_mention, tf.logical_not(in_mention))\n",
    "        end_current_mention = tf.logical_and(start_or_out, already_in_mention)\n",
    "        end_current_mention.set_shape((None,))\n",
    "        return end_current_mention\n",
    "        \n",
    "    # first figure out the maximum number of mentions\n",
    "    def _count_only_step(time, mention_counts, already_in_mention):\n",
    "        \"\"\" Update mentions_count using the mention detection update rules. \n",
    "        \n",
    "        This is done by marking if we are starting at a mention\n",
    "        and then adding to the count to sequences in the batch \n",
    "        where we detect the end of a mention.\n",
    "        \n",
    "        This is done by stitching in the updates to overwrite the current\n",
    "        values.  \n",
    "        \n",
    "        NOTE: Overwriting dynammic stitch may seem weird\n",
    "          but it's due to some scatter/while_loop idiosyncrasies of tf\n",
    "          (this finally works after my 4th implementation attempt)\n",
    "        \"\"\"\n",
    "        tags = seqs_ta.read(time)\n",
    "        in_mention = _in_mention(tags)\n",
    "        start_new_mention = _start_new_mention(tags)\n",
    "        end_current_mention = _end_current_mention(start_new_mention, in_mention, already_in_mention)\n",
    "        mention_counts = _sparse_update(end_current_mention,\n",
    "                                        batch_range, batch_range,\n",
    "                                        mention_counts, mention_counts+1)\n",
    "        already_in_mention = in_mention\n",
    "        return time+1, mention_counts, already_in_mention\n",
    "    \n",
    "    # fill in empty bookkeeping tensors that encode the mentions\n",
    "    def _extraction_step(time, \n",
    "                         mention_starts,\n",
    "                         mention_ends,\n",
    "#                          mention_features,\n",
    "                         mention_counts, \n",
    "                         mention_sizes,\n",
    "                         already_in_mention):\n",
    "        \"\"\" Extract mention boundaries at this timestep.\n",
    "        \n",
    "        Args:\n",
    "          time: the current timestep in the batch of sequences\n",
    "          seqs_ta: the batch of sequences\n",
    "          mention_starts: the Tensor holding the start boundaries \n",
    "            of the extracted mentions so far\n",
    "          mention_ends: the Tensor holding the end boundaries \n",
    "            of the extracted mentions so far\n",
    "          mention_counts: the current number of mentions found\n",
    "            for a single sequence in the batch.  This is used to \n",
    "            dynamically scatter extracted mentions into the `mentions`\n",
    "            TensorArray so that it can be abstracted away from the \n",
    "            underlying sequence.\n",
    "          in_mentions: whether or not the sequence is in a mention or not.\n",
    "            As we scan, we extract mentions by looking for contiguous groups\n",
    "            of non-'Outside' tags.  \n",
    "            This way we can extract multi-token mentions into single elements.\n",
    "        \"\"\"        \n",
    "        # get the sequence tags at the current timestep\n",
    "        tags = seqs_ta.read(time)\n",
    "        \n",
    "        # decide if they are in mention or not\n",
    "        in_mention = _in_mention(tags)\n",
    "        \n",
    "        ### IF they are a mention but weren't before, start a new mention\n",
    "        # do this by applying scattered updates (via dynamic_stitch) \n",
    "        # to the masked, linearly indexed locations of new mentions, \n",
    "        # where the updated values are the current timestep\n",
    "        # eg, the location in the sequence where this mention is being started\n",
    "        boundary = time * tf.ones_like(tags, dtype=tf.int32) \n",
    "        start_new_mention = _start_new_mention(tags)\n",
    "        end_current_mention = _end_current_mention(start_new_mention, in_mention, already_in_mention)\n",
    "        \n",
    "        ### IF they aren't but were before, end the mention at t\n",
    "        mention_ends = _sparse_update(end_current_mention,\n",
    "                                      linear_range, mention_counts + linear_index,\n",
    "                                      mention_ends, boundary)\n",
    "        \n",
    "        mention_counts = _sparse_update(end_current_mention,\n",
    "                                        batch_range, batch_range,\n",
    "                                        mention_counts, mention_counts+1)\n",
    "        \n",
    "        mention_starts = _sparse_update(start_new_mention,\n",
    "                                        linear_range, mention_counts + linear_index,\n",
    "                                        mention_starts, boundary)\n",
    "\n",
    "        # update mention counts where we've ended an extraction (same as `_count_step()`)\n",
    "        mention_sizes = _sparse_update(end_current_mention,\n",
    "                                       batch_range, batch_range,\n",
    "                                       mention_sizes, tf.zeros_like(mention_sizes))\n",
    "        mention_sizes = _sparse_update(in_mention,\n",
    "                                       batch_range, batch_range,\n",
    "                                       mention_sizes, mention_sizes+1)\n",
    "        already_in_mention = in_mention\n",
    "        \n",
    "        return (time + 1, \n",
    "#                 seqs_ta,\n",
    "#                 outside_token,\n",
    "#                 linear_range,\n",
    "#                 linear_index,\n",
    "#                 batch_range,\n",
    "                mention_starts, \n",
    "                mention_ends,\n",
    "#                 mention_features,\n",
    "                mention_counts, \n",
    "                mention_sizes,\n",
    "                already_in_mention)\n",
    "    \n",
    "    # convert the sequences\n",
    "    shape = tf.shape(seqs)\n",
    "    batch_size = shape[0]\n",
    "    time_steps = shape[1]\n",
    "#     feature_size = shape[2]\n",
    "    \n",
    "    # `TensorArray`'s read in time-major, so transpose\n",
    "    seqs_ta = tf.TensorArray(dtype=seqs.dtype, size=time_steps, clear_after_read=False)\n",
    "    seqs_ta = seqs_ta.unpack(tf.transpose(seqs, [1,0]))\n",
    "#     features_ta = tf.TensorArray(dtype=features.dtype, size=time_steps)\n",
    "#     features_ta = features_ta.unpack(tf.transpose(features, [1,0,2]))\n",
    "    \n",
    "    # bookkeeping tensors\n",
    "    time = tf.constant(0, dtype=tf.int32)\n",
    "    batch_range = tf.range(batch_size)\n",
    "    mention_counts = tf.zeros(dtype=tf.int32, shape=(batch_size,))\n",
    "    already_in_mention = tf.cast(mention_counts, tf.bool)\n",
    "        \n",
    "    # find the maximum number of mentions in batch\n",
    "    (_, mention_counts, already_in_mention) = tf.while_loop(cond=lambda time, *_: time < time_steps,\n",
    "                                                            body=_count_only_step,\n",
    "                                                            loop_vars=(time,\n",
    "                                                                       mention_counts, \n",
    "                                                                       already_in_mention))\n",
    "    # add 1 to counts where we never detected the end\n",
    "    already_in_mention.set_shape((None,))\n",
    "    mention_counts = _sparse_update(already_in_mention,\n",
    "                                    batch_range, batch_range,\n",
    "                                    mention_counts, mention_counts+1)\n",
    "    \n",
    "    # now create the tensors we will extract mention data into\n",
    "    max_num_mentions = tf.reduce_max(mention_counts)\n",
    "    max_num_relations = max_num_mentions*(max_num_mentions-1)/2\n",
    "    \n",
    "    # create a linearized version of the mention statistics we'll gather\n",
    "    # it'll be padded with -1's (can't use 0 as its a valid index)\n",
    "    mention_starts = -1*tf.ones(shape=(batch_size * max_num_mentions,), dtype=tf.int32)\n",
    "    mention_ends = -1*tf.ones(shape=(batch_size * max_num_mentions,), dtype=tf.int32)\n",
    "#     mention_features = -1*tf.ones(shape=(batch_size * max_num_mentions, feature_size), \n",
    "#                                   dtype=features.dtype)\n",
    "    \n",
    "    # we also need a full linear range and a liear index into the mention_stats\n",
    "    # tensors so we can dynamically overwrite the values\n",
    "    linear_range = tf.range(batch_size * max_num_mentions)\n",
    "    linear_index = max_num_mentions * tf.range(batch_size)\n",
    "    \n",
    "    # reset the bookkeeping tensors\n",
    "    time = tf.constant(0, dtype=tf.int32)\n",
    "    mention_counts = tf.zeros(dtype=tf.int32, shape=(batch_size,))\n",
    "    mention_sizes = tf.zeros(dtype=tf.int32, shape=(batch_size,))\n",
    "    already_in_mention = tf.cast(mention_counts, tf.bool)\n",
    "    \n",
    "    # extract the mentions\n",
    "    (time,\n",
    "     mention_starts, \n",
    "     mention_ends,\n",
    "#      mention_features,\n",
    "     mention_counts, \n",
    "     mention_sizes,\n",
    "     already_in_mention) = tf.while_loop(cond=lambda time, *_: time < time_steps,\n",
    "                                         body=_extraction_step,\n",
    "                                         loop_vars= (time, \n",
    "                                                     mention_starts, \n",
    "                                                     mention_ends,\n",
    "#                                                      mention_features,\n",
    "                                                     mention_counts, \n",
    "                                                     mention_sizes,\n",
    "                                                     already_in_mention))\n",
    "    # if we ended on a mention, we need to compute final endpoints\n",
    "    already_in_mention.set_shape((None,))\n",
    "    boundary = time * tf.ones_like(mention_counts, dtype=tf.int32) \n",
    "    offsets = mention_counts + linear_index\n",
    "    mention_ends = _sparse_update(already_in_mention,\n",
    "                                  linear_range, offsets,\n",
    "                                  mention_ends, boundary)\n",
    "    mention_counts = _sparse_update(already_in_mention,\n",
    "                                    batch_range, batch_range,\n",
    "                                    mention_counts, mention_counts+1)\n",
    "    mention_sizes = _sparse_update(already_in_mention,\n",
    "                                   batch_range, batch_range,\n",
    "                                   mention_sizes, mention_sizes+1)\n",
    "    \n",
    "    # finally concat and reshape extraction stats\n",
    "    mention_starts = tf.reshape(mention_starts, (batch_size, max_num_mentions, 1))\n",
    "    mention_ends = tf.reshape(mention_ends, (batch_size, max_num_mentions, 1))\n",
    "    mentions = tf.concat(2, [mention_starts, mention_ends])\n",
    "    return mentions, mention_sizes, max_num_mentions, max_num_relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, session, model_name, options):\n",
    "        self.session = session\n",
    "        self.model_name = model_name\n",
    "        for key, value in options.items():\n",
    "            setattr(self, key, value)\n",
    "#         self.token_embed_size = options['token_embed_size']\n",
    "#         self.rnn_hidden_size = options['rnn_hidden_size']\n",
    "#         self.learning_rate = options['learning_rate']\n",
    "#         self.token_vocab = options['token_vocab']\n",
    "#         self.boundary_vocab = options['boundary_vocab']\n",
    "        \n",
    "        if 'checkpoint_dir' in options:\n",
    "            self.model_name = os.path.join(options['checkpoint_dir'], self.model_name)\n",
    "        \n",
    "        self.histories = {}\n",
    "    \n",
    "        print \"Building graph...\",\n",
    "        self.manipulate_options()\n",
    "        self.global_step_tensor = tf.Variable(0, trainable=False, name='global_step')\n",
    "        self.best_global_step_tensor = tf.Variable(0, trainable=False, name='best_global_step')\n",
    "        self.best_valid_loss_tensor = tf.Variable(1e50, trainable=False, name='best_valid_loss')\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "        self.build_forward()\n",
    "        self.build_loss()\n",
    "        self.build_optimizer()\n",
    "        \n",
    "        self.session.run(tf.initialize_all_variables())\n",
    "        print \"Done\"\n",
    "        \n",
    "    @property\n",
    "    def global_step(self):\n",
    "        return self.global_step_tensor.eval()\n",
    "    \n",
    "    @property\n",
    "    def best_global_step(self):\n",
    "        return self.best_global_step_tensor.eval()\n",
    "    \n",
    "    @best_global_step.setter\n",
    "    def best_valid_global_step(self, val):\n",
    "        self.session.run(self.best_global_step_tensor.assign(val))\n",
    "    \n",
    "    @property\n",
    "    def best_valid_loss(self):\n",
    "        return self.best_valid_loss_tensor.eval()\n",
    "    \n",
    "    @best_valid_loss.setter\n",
    "    def best_valid_loss(self, val):\n",
    "        self.session.run(self.best_valid_loss_tensor.assign(val))\n",
    "        \n",
    "    def manipulate_options(self):\n",
    "        \"\"\" For manipulating options before building the graph. \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def build_forward(self):\n",
    "        # inputs\n",
    "        self.token_seqs = tf.placeholder(dtype=tf.int32, \n",
    "                                         shape=[None, None])\n",
    "        self.seq_lens = tf.placeholder(dtype=tf.int32,\n",
    "                                      shape=[None])\n",
    "        self.batch_size = tf.shape(self.token_seqs)[0]\n",
    "        self.seq_len = tf.shape(self.token_seqs)[1]\n",
    "        \n",
    "        # initializers\n",
    "        rand_init = tf.random_normal_initializer(mean=0.0, \n",
    "                                                 stddev=1.0, \n",
    "                                                 seed=42, \n",
    "                                                 dtype=tf.float32)\n",
    "        ones_init = tf.constant_initializer(value=1.0, dtype=tf.float32)\n",
    "        \n",
    "        # embed the sequence tokens\n",
    "        embeddings = tf.get_variable(\"token_embeddings\",\n",
    "                                     shape=[self.token_vocab.v, self.token_embed_size],\n",
    "                                     initializer=rand_init)\n",
    "        embedded_seqs = tf.nn.embedding_lookup(embeddings, self.token_seqs)\n",
    "        \n",
    "        # process sequence with rnn\n",
    "        if self.bidirectional:\n",
    "            if self.cell_type == 'LSTM':\n",
    "                fw_cell = tf.nn.rnn_cell.LSTMCell(self.rnn_hidden_size)\n",
    "                bw_cell = tf.nn.rnn_cell.LSTMCell(self.rnn_hidden_size)\n",
    "            elif self.cell_type == 'RNN':\n",
    "                fw_cell = tf.nn.rnn_cell.RNNCell(self.rnn_hidden_size)\n",
    "                bw_cell = tf.nn.rnn_cell.RNNCell(self.rnn_hidden_size)\n",
    "            else:\n",
    "                fw_cell = tf.nn.rnn_cell.GRUCell(self.rnn_hidden_size)\n",
    "                bw_cell = tf.nn.rnn_cell.GRUCell(self.rnn_hidden_size)\n",
    "            fw_init_state = fw_cell.zero_state(self.batch_size, tf.float32)\n",
    "            bw_init_state = bw_cell.zero_state(self.batch_size, tf.float32)\n",
    "            outputs, output_states = tf.nn.bidirectional_dynamic_rnn(fw_cell, bw_cell,\n",
    "                                                                     embedded_seqs,\n",
    "                                                                     sequence_length=self.seq_lens,\n",
    "                                                                     initial_state_fw=fw_init_state,\n",
    "                                                                     initial_state_bw=bw_init_state)\n",
    "            outputs = tf.concat(2, outputs)\n",
    "        else:\n",
    "            if self.cell_type == 'LSTM':\n",
    "                cell = tf.nn.rnn_cell.LSTMCell(self.rnn_hidden_size)\n",
    "            elif self.cell_type == 'RNN':\n",
    "                cell = tf.nn.rnn_cell.RNNCell(self.rnn_hidden_size)\n",
    "            else:\n",
    "                cell = tf.nn.rnn_cell.GRUCell(self.rnn_hidden_size)\n",
    "            initial_state = cell.zero_state(self.batch_size, tf.float32)\n",
    "            outputs, state = tf.nn.dynamic_rnn(cell, embedded_seqs, \n",
    "                                               sequence_length=self.seq_lens, \n",
    "                                               initial_state=initial_state)\n",
    "        \n",
    "        # make predictions\n",
    "        if self.bidirectional:\n",
    "            rnn_out_size = 2 * self.rnn_hidden_size\n",
    "        else:\n",
    "            rnn_out_size = self.rnn_hidden_size\n",
    "        W_o = tf.get_variable(\"W_out\", \n",
    "                              shape=[rnn_out_size, self.boundary_vocab.v],\n",
    "                              initializer=rand_init)\n",
    "        b_o = tf.get_variable(\"b_out\", \n",
    "                              shape=[self.boundary_vocab.v],\n",
    "                              initializer=ones_init)\n",
    "        \n",
    "        outputs_flat_across_time = tf.reshape(outputs, [self.batch_size*self.seq_len, -1])\n",
    "        logits = tf.matmul(outputs_flat_across_time, W_o) + b_o\n",
    "        self.logits = tf.reshape(logits, [self.batch_size, self.seq_len, -1])\n",
    "        self.probs = tf.nn.softmax(self.logits)\n",
    "        self.preds = tf.argmax(self.logits, dimension=2)\n",
    "        \n",
    "    def build_loss(self):\n",
    "        def sparse_xent((logits, labels)):\n",
    "            \"\"\" Returns the cross entropy of a single timestep across the batch.\n",
    "            \n",
    "            Allows for us to use map to get the loss of a batch w/ unknown\n",
    "            sequence lengths and batch size (no need for static unrolling of loss)\n",
    "            \"\"\"\n",
    "            return tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels)\n",
    "        \n",
    "        self.seq_labels = tf.placeholder(dtype=tf.int32, \n",
    "                                         shape=[None, None])\n",
    "        self.seq_label_weights = tf.placeholder(dtype=tf.float32,\n",
    "                                                shape=[None, None])\n",
    "        # convert everything to time-major\n",
    "        logits = tf.transpose(self.logits, [1,0,2])\n",
    "        seq_labels = tf.transpose(self.seq_labels, [1,0])\n",
    "        seq_label_weights = tf.transpose(self.seq_label_weights, [1,0])\n",
    "        \n",
    "        # calculate the loss for each timestep for each sequence\n",
    "        raw_xent = tf.map_fn(sparse_xent, (logits, seq_labels), \n",
    "                             dtype=tf.float32)\n",
    "        weighted_xent = seq_label_weights * raw_xent\n",
    "        self.loss = tf.reduce_mean(tf.reduce_sum(weighted_xent, 0)) # don't average over seq length\n",
    "    \n",
    "    def build_optimizer(self):\n",
    "        self.lr = tf.placeholder(tf.float32, shape=[])\n",
    "        self.optimzer = tf.train.AdamOptimizer(self.lr)\n",
    "        self.train_op = self.optimzer.minimize(self.loss, global_step=self.global_step_tensor)\n",
    "    \n",
    "    def partial_fit(self, xs, ys, evaluate_only=False):\n",
    "        xs, weights, lengths = self.preprocess_batch(xs, self.token_vocab)\n",
    "        ys, _, _ = self.preprocess_batch(ys, self.boundary_vocab)\n",
    "        feed_dict = {\n",
    "            self.token_seqs: xs,\n",
    "            self.seq_labels: ys,\n",
    "            self.seq_lens: lengths,\n",
    "            self.seq_label_weights: weights,\n",
    "            self.lr: self.learning_rate\n",
    "        }\n",
    "        if evaluate_only:\n",
    "            loss = self.session.run(self.loss, feed_dict)\n",
    "        else:\n",
    "            loss, _ = self.session.run([self.loss, self.train_op], feed_dict)\n",
    "        return loss\n",
    "    \n",
    "    def predict(self, xs):\n",
    "        xs, _, lengths = self.preprocess_batch(xs, self.token_vocab)\n",
    "        feed_dict = {\n",
    "            self.token_seqs: xs,\n",
    "            self.seq_lens: lengths\n",
    "        }\n",
    "        preds = self.session.run(self.preds, feed_dict)\n",
    "        preds = self.postprocess_batch(preds, self.boundary_vocab, lengths=lengths)\n",
    "        return preds\n",
    "    \n",
    "    def predict_proba(self, xs):\n",
    "        xs, _, lengths = self.preprocess_batch(xs, self.token_vocab)\n",
    "        feed_dict = {\n",
    "            self.token_seqs: xs,\n",
    "            self.seq_lens: lengths\n",
    "        }\n",
    "        probs = self.session.run(self.probs, feed_dict)\n",
    "        return probs\n",
    "    \n",
    "    def fit(self, xs, ys, n_epoch, \n",
    "            batch_size=64, validation_split=.1,\n",
    "            early_stop=True, patience=5):\n",
    "        # first carve off validation set\n",
    "        # validation_split is considered a percent if a float < 1\n",
    "        # or a hard split size if an int >= 1\n",
    "        if validation_split < 1 and type(validation_split) is float:\n",
    "            validation_split = int(validation_split*len(xs))\n",
    "        else:\n",
    "            validation_split = int(validation_split)\n",
    "        xy = zip(xs, ys)\n",
    "        npr.shuffle(xy)\n",
    "        xs, ys = zip(*xy)\n",
    "        \n",
    "        valid_xs, train_xs = xs[:validation_split], xs[validation_split:]\n",
    "        valid_ys, train_ys = ys[:validation_split], ys[validation_split:]\n",
    "        \n",
    "        # show the status\n",
    "        print \"Fitting {} epochs of {} samples per with batch size {}\".format(\n",
    "               n_epoch, len(train_xs), batch_size)\n",
    "        print \"Validation Set size is {}. \\nEarly Stop = {} with patience: {}\".format(\n",
    "               len(valid_xs), early_stop, patience)\n",
    "        \n",
    "        # do the training\n",
    "        batch_generator = BucketedBatchGenerator(train_xs, train_ys, batch_size=batch_size)\n",
    "        fit_start = time.time()\n",
    "        n_valid_loss_up = 0\n",
    "        for epoch_i in range(n_epoch):\n",
    "            epoch_start = time.time()\n",
    "            epoch_losses = []\n",
    "            for batch_i, (x, y) in enumerate(batch_generator):\n",
    "                loss = self.partial_fit(x, y)\n",
    "                \n",
    "                # logging\n",
    "                self.print_batch_loss(loss, epoch_i+1, batch_i+1, batch_generator.n_batches)\n",
    "                epoch_losses.append(loss)\n",
    "                self.append_history('batch_losses', loss)\n",
    "            epoch_time = time.time() - epoch_start\n",
    "            \n",
    "            # evaluate the validation set\n",
    "            valid_loss = self.partial_fit(valid_xs, valid_ys, evaluate_only=True)\n",
    "            self.append_history('valid_losses', valid_loss)\n",
    "            self.append_history('epoch_losses', epoch_losses)\n",
    "            self.print_epoch_loss(epoch_i+1, np.mean(epoch_losses), valid_loss, epoch_time, len(train_xs))\n",
    "            \n",
    "            # early stopping\n",
    "            if valid_loss <= self.best_valid_loss:\n",
    "                self.best_valid_loss = valid_loss\n",
    "                self.best_global_step = self.global_step\n",
    "                self.checkpoint(display=False)\n",
    "                n_valid_loss_up = 0\n",
    "            else:\n",
    "                n_valid_loss_up += 1\n",
    "                if early_stop and n_valid_loss_up > patience:\n",
    "                    print \"\\nStopping Early...\",\n",
    "                    print \"Restoring model with best valid loss = {0:2.6f} at step: {1:d}\".format(\n",
    "                        self.best_valid_loss, self.best_global_step)\n",
    "                    self.restore()\n",
    "                    break\n",
    "            \n",
    "            \n",
    "        print \"\\nTotal train time {} sec for {} instances\".format(int(time.time()-fit_start), len(train_xs)*n_epoch)\n",
    "                \n",
    "    #####################            \n",
    "    # LOGGING FUNCTIONS #            \n",
    "    #####################            \n",
    "    def append_history(self, field_name, value):\n",
    "        \"\"\" Create or append values to a model \"history list\" by string name to keep track of important stats. \"\"\"\n",
    "        if not field_name in self.histories:\n",
    "                self.histories[field_name] = [value]\n",
    "        else:\n",
    "            self.histories[field_name].append(value)\n",
    "\n",
    "    def extend_history(self, field_name, list_of_values):\n",
    "        \"\"\" Same as `append_history` but expects an input list and extends the previous history instead of append. \"\"\"\n",
    "        if not field_name in self.histories:\n",
    "                self.histories[field_name] = list_of_values\n",
    "        else:\n",
    "            self.histories[field_name].extend(list_of_values)\n",
    "            \n",
    "    def checkpoint(self, model_name=None, display=True):\n",
    "        \"\"\" Checkpoint the model **graph** only \"\"\"\n",
    "        fname = model_name if model_name else self.model_name\n",
    "        model_file = '{}-{}.ckpt'.format(fname, self.global_step)\n",
    "        if display: print \"Saving model graph to file {} ...\".format(model_file),\n",
    "        self.saver.save(self.session, model_file)\n",
    "        self.model_file = model_file # keep track of our most recent save\n",
    "        if display: print \"Done\"\n",
    "        return model_file        \n",
    "    \n",
    "    def restore(self, model_fname=None):\n",
    "        model_fname = model_fname if model_fname else '{}-{}.ckpt'.format(self.model_name, self.best_global_step)\n",
    "        print \"Restoring model from {} ...\".format(model_fname),\n",
    "        self.saver.restore(self.session, model_fname)\n",
    "        print \"Done\"\n",
    "            \n",
    "    ####################            \n",
    "    # HELPER FUNCTIONS #\n",
    "    ####################\n",
    "    def print_batch_loss(self, loss, epoch_i, batch_i, n_batches):\n",
    "        batch_percent = float(batch_i)/n_batches\n",
    "        progress = \"Epoch {0} : [{1}{2}] {3:2.2f}%, Loss = {4:2.6f}\".format(epoch_i,\n",
    "                                                               int(np.floor(batch_percent*10))*'=',\n",
    "                                                               int(np.ceil((1-batch_percent)*10))*'-',\n",
    "                                                               batch_percent*100,\n",
    "                                                               loss)\n",
    "        if batch_i > 1:\n",
    "            print '\\r',progress,\n",
    "        else:\n",
    "            print\n",
    "            print progress,\n",
    "            \n",
    "    def print_epoch_loss(self, epoch_i, avg_loss, valid_loss, time, n_data):\n",
    "        print '\\rEpoch {0} : Avg Loss = {1:2.4f}, Validation Loss = {2:2.4f}, {3} sec for {4} instances'.format(\n",
    "            epoch_i, avg_loss, valid_loss, int(time), n_data),\n",
    "            \n",
    "    def pad_sequence(self, sequence, pad_char, pad_len):\n",
    "        return sequence + [pad_char]*(pad_len - len(sequence))\n",
    "\n",
    "    def pad_sequences(self, sequences, pad_char, pad_len=None):\n",
    "        if not pad_len:\n",
    "            pad_len = max([len(sequence) for sequence in sequences])\n",
    "        return [ self.pad_sequence(sequence, pad_char, pad_len) for sequence in sequences]\n",
    "\n",
    "    def convert_sequence(self, sequence, conversion_func):\n",
    "        return [ conversion_func(s) for s in sequence ]\n",
    "\n",
    "    def convert_sequences(self, sequences, conversion_func):\n",
    "        return [ self.convert_sequence(sequence, conversion_func) for sequence in sequences ]\n",
    "    \n",
    "    def weights_and_lengths(self, seqs, pad_char):\n",
    "        weights = np.ones_like(seqs).astype(np.float32)\n",
    "        weights[seqs == pad_char] = 0.0\n",
    "        lengths = np.sum(weights, 1).astype(np.int)\n",
    "        return weights, lengths\n",
    "    \n",
    "    def preprocess_batch(self, seqs, vocab):\n",
    "        seqs = self.pad_sequences(seqs, vocab.pad)\n",
    "        seqs = self.convert_sequences(seqs, vocab.idx)\n",
    "        seqs = np.array(seqs)\n",
    "        weights, lengths = self.weights_and_lengths(seqs, vocab.ipad)\n",
    "        return seqs, weights, lengths\n",
    "\n",
    "    def postprocess_batch(self, seqs, vocab, lengths=None):\n",
    "        seqs = seqs.tolist()\n",
    "        seqs = self.convert_sequences(seqs, vocab.token)\n",
    "        if lengths is not None:\n",
    "            for i in range(len(seqs)):\n",
    "                seqs[i] = seqs[i][:lengths[i]]\n",
    "        return seqs\n",
    "    \n",
    "    #################\n",
    "    # VISUALIZATION #\n",
    "    #################\n",
    "    def plot_learning_curve(self, \n",
    "                            logx=False, \n",
    "                            logy=False,\n",
    "                            title='Training Learning Curve',\n",
    "                            xlabel='Epoch',\n",
    "                            ylabel='Loss',\n",
    "                            figsize=(6,4),\n",
    "                            savename=None):\n",
    "        fig, ax = plt.subplots(1, figsize=figsize)\n",
    "        train_means = np.array([ np.mean(epoch_loss) for epoch_loss in self.histories['epoch_losses'] ])\n",
    "        train_stds = np.array([ np.std(epoch_loss) for epoch_loss in self.histories['epoch_losses'] ])\n",
    "        t = xrange(len(self.histories['epoch_losses']))\n",
    "        ax.plot(t, train_means, 'bo-', lw=2,label='Average Per Epoch Training Loss', markersize=1)\n",
    "        ax.fill_between(t, train_means+train_stds, train_means-train_stds, facecolor='b', alpha=0.15)\n",
    "        ax.plot(t, self.histories['valid_losses'], 'go--', lw=2, label='Per Epoch Validation Loss', markersize=1)\n",
    "        ax.set_title(title)\n",
    "        ax.legend(loc='upper right')\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        if logx:\n",
    "            ax.set_xscale('log')\n",
    "        if logy:\n",
    "            ax.set_yscale('log')\n",
    "        if savename:\n",
    "            fig.savefig(savename)\n",
    "        return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building graph... Done\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "options = {\n",
    "    'token_embed_size': 50,\n",
    "    'rnn_hidden_size': 50,\n",
    "    'cell_type':'GRU',\n",
    "    'bidirectional':True,\n",
    "    'learning_rate':.01,\n",
    "    'token_vocab': token_vocab,\n",
    "    'boundary_vocab':boundary_vocab,\n",
    "    'checkpoint_dir':'../checkpoints'\n",
    "}\n",
    "\n",
    "model = Model(sess, 'boundary-only', options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 50 epochs of 7009 samples per with batch size 64\n",
      "Validation Set size is 1752. \n",
      "Early Stop = True with patience: 5\n",
      "\n",
      "Epoch 1 : Avg Loss = 13.6701, Validation Loss = 8.4041, 16 sec for 7009 instances\n",
      "Epoch 2 : Avg Loss = 7.3576, Validation Loss = 6.5666, 15 sec for 7009 instances\n",
      "Epoch 3 : Avg Loss = 5.9459, Validation Loss = 5.6166, 15 sec for 7009 instances\n",
      "Epoch 4 : Avg Loss = 5.0631, Validation Loss = 4.9490, 15 sec for 7009 instances\n",
      "Epoch 5 : Avg Loss = 4.4429, Validation Loss = 4.4742, 15 sec for 7009 instances\n",
      "Epoch 6 : Avg Loss = 3.8876, Validation Loss = 4.0833, 15 sec for 7009 instances\n",
      "Epoch 7 : Avg Loss = 3.4992, Validation Loss = 3.8503, 18 sec for 7009 instances\n",
      "Epoch 8 : Avg Loss = 3.1594, Validation Loss = 4.4072, 16 sec for 7009 instances\n",
      "Epoch 9 : Avg Loss = 2.9688, Validation Loss = 3.3881, 15 sec for 7009 instances\n",
      "Epoch 10 : Avg Loss = 2.6492, Validation Loss = 3.2966, 15 sec for 7009 instances\n",
      "Epoch 11 : Avg Loss = 2.4388, Validation Loss = 3.1626, 16 sec for 7009 instances\n",
      "Epoch 12 : Avg Loss = 2.3160, Validation Loss = 3.3134, 15 sec for 7009 instances\n",
      "Epoch 13 : Avg Loss = 2.1303, Validation Loss = 3.0698, 16 sec for 7009 instances\n",
      "Epoch 14 : Avg Loss = 1.9788, Validation Loss = 3.0614, 16 sec for 7009 instances\n",
      "Epoch 15 : Avg Loss = 1.8657, Validation Loss = 3.0094, 15 sec for 7009 instances\n",
      "Epoch 16 : Avg Loss = 1.7407, Validation Loss = 3.0359, 15 sec for 7009 instances\n",
      "Epoch 17 : Avg Loss = 1.6458, Validation Loss = 3.0199, 15 sec for 7009 instances\n",
      "Epoch 18 : Avg Loss = 1.5240, Validation Loss = 2.9983, 15 sec for 7009 instances\n",
      "Epoch 19 : Avg Loss = 1.4130, Validation Loss = 3.0359, 15 sec for 7009 instances\n",
      "Epoch 20 : Avg Loss = 1.3409, Validation Loss = 3.0697, 15 sec for 7009 instances\n",
      "Epoch 21 : Avg Loss = 1.2305, Validation Loss = 3.2145, 15 sec for 7009 instances\n",
      "Epoch 22 : Avg Loss = 1.1252, Validation Loss = 3.2081, 17 sec for 7009 instances\n",
      "Epoch 23 : Avg Loss = 1.0421, Validation Loss = 3.2816, 20 sec for 7009 instances\n",
      "Epoch 24 : Avg Loss = 0.9515, Validation Loss = 3.3731, 15 sec for 7009 instances \n",
      "Stopping Early... Restoring model with best valid loss = 2.998311 at step: 1962\n",
      "Restoring model from ../checkpoints/boundary-only-1962.ckpt ... Done\n",
      "\n",
      "Total train time 483 sec for 350450 instances\n"
     ]
    }
   ],
   "source": [
    "# first train on sentences\n",
    "model.learning_rate = .001\n",
    "model.best_valid_loss = 1e50\n",
    "model.fit(x_sent_train, y_sent_train, n_epoch=50, validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.figure.Figure at 0x14efc0a90>,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x183cdce50>)"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAGJCAYAAADMo5pWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14efc0a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_learning_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 50 epochs of 337 samples per with batch size 64\n",
      "Validation Set size is 37. \n",
      "Early Stop = True with patience: 5\n",
      "\n",
      "Epoch 1 : Avg Loss = 1453.3549, Validation Loss = 668.7764, 23 sec for 337 instances\n",
      "Epoch 2 : Avg Loss = 671.6950, Validation Loss = 493.0991, 19 sec for 337 instances\n",
      "Epoch 3 : Avg Loss = 427.2218, Validation Loss = 467.2310, 19 sec for 337 instances\n",
      "Epoch 4 : Avg Loss = 360.5211, Validation Loss = 278.3629, 20 sec for 337 instances\n",
      "Epoch 5 : Avg Loss = 276.5233, Validation Loss = 227.8346, 19 sec for 337 instances\n",
      "Epoch 6 : Avg Loss = 242.3035, Validation Loss = 247.0681, 20 sec for 337 instances\n",
      "Epoch 7 : Avg Loss = 182.3973, Validation Loss = 189.3309, 19 sec for 337 instances\n",
      "Epoch 8 : Avg Loss = 180.5199, Validation Loss = 156.8048, 19 sec for 337 instances\n",
      "Epoch 9 : Avg Loss = 159.6523, Validation Loss = 192.6919, 19 sec for 337 instances\n",
      "Epoch 10 : Avg Loss = 142.2939, Validation Loss = 150.5268, 19 sec for 337 instances\n",
      "Epoch 11 : Avg Loss = 149.9012, Validation Loss = 134.8595, 19 sec for 337 instances\n",
      "Epoch 12 : Avg Loss = 122.1896, Validation Loss = 158.0411, 19 sec for 337 instances\n",
      "Epoch 13 : Avg Loss = 110.8012, Validation Loss = 133.2273, 19 sec for 337 instances\n",
      "Epoch 14 : Avg Loss = 106.6711, Validation Loss = 123.2709, 19 sec for 337 instances\n",
      "Epoch 15 : Avg Loss = 94.0571, Validation Loss = 125.8314, 19 sec for 337 instances\n",
      "Epoch 16 : Avg Loss = 87.2753, Validation Loss = 117.3386, 19 sec for 337 instances\n",
      "Epoch 17 : Avg Loss = 84.8757, Validation Loss = 115.8072, 19 sec for 337 instances\n",
      "Epoch 18 : Avg Loss = 79.3783, Validation Loss = 114.8076, 19 sec for 337 instances\n",
      "Epoch 19 : Avg Loss = 76.6060, Validation Loss = 110.3137, 21 sec for 337 instances\n",
      "Epoch 20 : Avg Loss = 74.1129, Validation Loss = 109.1982, 19 sec for 337 instances\n",
      "Epoch 21 : Avg Loss = 71.4905, Validation Loss = 108.6191, 19 sec for 337 instances\n",
      "Epoch 22 : Avg Loss = 69.3743, Validation Loss = 107.4778, 19 sec for 337 instances\n",
      "Epoch 23 : Avg Loss = 67.3598, Validation Loss = 106.5138, 19 sec for 337 instances\n",
      "Epoch 24 : Avg Loss = 65.6794, Validation Loss = 106.2381, 19 sec for 337 instances\n",
      "Epoch 25 : Avg Loss = 63.8833, Validation Loss = 104.4334, 19 sec for 337 instances\n",
      "Epoch 26 : Avg Loss = 62.2155, Validation Loss = 104.6715, 19 sec for 337 instances\n",
      "Epoch 27 : Avg Loss = 61.2148, Validation Loss = 104.2193, 19 sec for 337 instances\n",
      "Epoch 28 : Avg Loss = 59.3623, Validation Loss = 103.4264, 19 sec for 337 instances\n",
      "Epoch 29 : Avg Loss = 58.2381, Validation Loss = 103.1364, 19 sec for 337 instances\n",
      "Epoch 30 : Avg Loss = 56.6803, Validation Loss = 102.4863, 20 sec for 337 instances\n",
      "Epoch 31 : Avg Loss = 55.5085, Validation Loss = 102.6014, 19 sec for 337 instances\n",
      "Epoch 32 : Avg Loss = 54.4202, Validation Loss = 102.0680, 21 sec for 337 instances\n",
      "Epoch 33 : Avg Loss = 53.2915, Validation Loss = 102.0451, 19 sec for 337 instances\n",
      "Epoch 34 : Avg Loss = 52.1499, Validation Loss = 101.5332, 19 sec for 337 instances\n",
      "Epoch 35 : Avg Loss = 51.1647, Validation Loss = 101.5430, 19 sec for 337 instances\n",
      "Epoch 36 : Avg Loss = 50.0575, Validation Loss = 101.5876, 19 sec for 337 instances\n",
      "Epoch 37 : Avg Loss = 49.1303, Validation Loss = 101.5101, 19 sec for 337 instances\n",
      "Epoch 38 : Avg Loss = 48.4205, Validation Loss = 101.3944, 19 sec for 337 instances\n",
      "Epoch 39 : Avg Loss = 47.4922, Validation Loss = 101.3684, 19 sec for 337 instances\n",
      "Epoch 40 : Avg Loss = 46.5827, Validation Loss = 101.2435, 19 sec for 337 instances\n",
      "Epoch 41 : Avg Loss = 45.7249, Validation Loss = 101.5340, 19 sec for 337 instances\n",
      "Epoch 42 : Avg Loss = 45.0846, Validation Loss = 101.5932, 19 sec for 337 instances\n",
      "Epoch 43 : Avg Loss = 44.2778, Validation Loss = 101.4319, 20 sec for 337 instances\n",
      "Epoch 44 : Avg Loss = 43.3447, Validation Loss = 101.5391, 20 sec for 337 instances\n",
      "Epoch 45 : Avg Loss = 42.6757, Validation Loss = 101.6552, 20 sec for 337 instances\n",
      "Epoch 46 : Avg Loss = 41.8841, Validation Loss = 102.3061, 21 sec for 337 instances \n",
      "Stopping Early... Restoring model with best valid loss = 101.243530 at step: 200\n",
      "Restoring model from ../checkpoints/boundary-only-200.ckpt ... Done\n",
      "\n",
      "Total train time 1044 sec for 16850 instances\n"
     ]
    }
   ],
   "source": [
    "# then train on full docs\n",
    "model.learning_rate = .005\n",
    "model.fit(x_train, y_train, n_epoch=50, validation_split=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.figure.Figure at 0x1675a5810>,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x1509b4c50>)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGJCAYAAAC6mSjdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRIZOgURERESG7n8BlsMAO8uQPvkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1675a5810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_learning_curve(logy=True, savename='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mode(L):\n",
    "    \"\"\" Compute the mode of a list \"\"\"\n",
    "    types = {}\n",
    "    for e in L:\n",
    "        if e in types:\n",
    "            types[e] += 1\n",
    "        else:\n",
    "            types[e] = 1\n",
    "    return sorted(types.items(), reverse=True, key=lambda x:x[1])[0][0]\n",
    "\n",
    "def extract_mentions(seq, typed=True):\n",
    "    \"\"\" We extract mentions approximately according to the BIO or BILOU schemes\n",
    "    with some relaxations.\n",
    "    \n",
    "    We start mentions when we see anything but an 'O'. \n",
    "    We end them when we see an 'O'.\n",
    "    \n",
    "    When computing the type of the mention\n",
    "    we simply take the mode of the types of it's constituent tokens.\n",
    "    \"\"\"\n",
    "    mentions = []\n",
    "    in_mention = False\n",
    "    mention_start = mention_end = 0\n",
    "    for i, s in enumerate(seq):\n",
    "        if not in_mention and s.startswith(('B', 'I', 'L', 'U')):\n",
    "            mention_start = i\n",
    "            in_mention = True\n",
    "        elif in_mention and s == 'O':\n",
    "            if typed:\n",
    "                mention_type = mode([ s.split('-')[-1] for s in seq[mention_start:i] ])\n",
    "            else:\n",
    "                mention_type = 'E'\n",
    "            mentions.append((mention_start, i-1, mention_type))\n",
    "            in_mention=False\n",
    "    if in_mention: # we end on a mention\n",
    "        if typed:\n",
    "            mention_type = mode([ s.split('-')[-1] for s in seq[mention_start:i] ])\n",
    "        else:\n",
    "            mention_type = 'E'\n",
    "        mentions.append((mention_start, i, mention_type))\n",
    "    return mentions\n",
    "    \n",
    "def extract_all_mentions(seqs, typed=True):\n",
    "    return [extract_mentions(seq, typed=typed) for seq in seqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mention_precision_recall(true_mentions, pred_mentions):\n",
    "    \"\"\" This function returns the counts of true positives, false positives, and false negatives\n",
    "    which are necessary for calculating precision and recall.\n",
    "    A mention boundary is considered correct if both ends are correct. \n",
    "    \"\"\"\n",
    "    true_mentions = set(true_mentions)\n",
    "    pred_mentions = set(pred_mentions)\n",
    "    tp = len(true_mentions & pred_mentions)\n",
    "    fn = len(true_mentions - pred_mentions)\n",
    "    fp = len(pred_mentions - true_mentions)\n",
    "    return tp, fp, fn\n",
    "\n",
    "def mention_boundary_stats(true_ys, pred_ys, typed=True):\n",
    "    all_true_mentions = extract_all_mentions(true_ys, typed=typed)\n",
    "    all_pred_mentions = extract_all_mentions(pred_ys, typed=typed)\n",
    "    stats = {'tp':0,\n",
    "             'fp':0,\n",
    "             'fn':0}\n",
    "    for true_mentions, pred_mentions in zip(all_true_mentions, all_pred_mentions):\n",
    "        tp, fp, fn = mention_precision_recall(true_mentions, pred_mentions)\n",
    "        stats['tp'] += tp\n",
    "        stats['fp'] += fp\n",
    "        stats['fn'] += fn\n",
    "    stats['precision'] = tp / float(tp + fp)\n",
    "    stats['recall'] = tp / float(tp + fn)\n",
    "    stats['f1'] = 2*stats['precision']*stats['recall']/(stats['precision']+stats['recall'])\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: 0.8511, R: 0.7407, F1: 0.7921\n"
     ]
    }
   ],
   "source": [
    "f1_stats = mention_boundary_stats(y_test, model.predict(x_test), typed=True)\n",
    "print \"P: {s[precision]:2.4f}, R: {s[recall]:2.4f}, F1: {s[f1]:2.4f}\".format(s=f1_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'<', 'O', 'O'),\n",
       " (u'DOC', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'DOCID', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'CNN_ENG_20030509_090025.5', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'/DOCID', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'DOCTYPE', 'O', 'O'),\n",
       " (u'SOURCE=\"broadcast', 'O', 'O'),\n",
       " (u'news', 'O', 'O'),\n",
       " (u'\"', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'NEWS', 'O', 'O'),\n",
       " (u'STORY', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'/DOCTYPE', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'DATETIME', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'2003', 'O', 'O'),\n",
       " (u'-', 'O', 'O'),\n",
       " (u'05', 'O', 'O'),\n",
       " (u'-', 'O', 'O'),\n",
       " (u'09', 'O', 'O'),\n",
       " (u'11:31:13', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'/DATETIME', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'BODY', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'TEXT', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'TURN', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'a', 'O', 'O'),\n",
       " (u'former', 'O', 'O'),\n",
       " (u'fbi', u'U-ORG', u'U-ORG'),\n",
       " (u'informant', u'U-PER', u'U-GPE'),\n",
       " (u'accused', 'O', 'O'),\n",
       " (u'of', 'O', 'O'),\n",
       " (u'being', 'O', 'O'),\n",
       " (u'a', 'O', 'O'),\n",
       " (u'double', 'O', 'O'),\n",
       " (u'agent', u'U-PER', u'U-PER'),\n",
       " (u'has', 'O', 'O'),\n",
       " (u'been', 'O', 'O'),\n",
       " (u'indicted', 'O', 'O'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'the', 'O', 'O'),\n",
       " (u'charges', 'O', 'O'),\n",
       " (u'against', 'O', 'O'),\n",
       " (u'katrina', u'B-PER', u'U-ORG'),\n",
       " (u'leung', u'L-PER', 'O'),\n",
       " (u'are', 'O', 'O'),\n",
       " (u'the', 'O', 'O'),\n",
       " (u'latest', 'O', 'O'),\n",
       " (u'in', 'O', 'O'),\n",
       " (u'an', 'O', 'O'),\n",
       " (u'alleged', 'O', 'O'),\n",
       " (u'case', 'O', 'O'),\n",
       " (u'of', 'O', 'O'),\n",
       " (u'sex', 'O', 'O'),\n",
       " (u',', 'O', 'O'),\n",
       " (u'spies', u'U-PER', 'O'),\n",
       " (u',', 'O', 'O'),\n",
       " (u'and', 'O', 'O'),\n",
       " (u'international', 'O', 'O'),\n",
       " (u'intrigue', 'O', 'O'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'charles', u'B-PER', u'B-PER'),\n",
       " (u'feldman', u'L-PER', u'L-PER'),\n",
       " (u'is', 'O', 'O'),\n",
       " (u'in', 'O', 'O'),\n",
       " (u'los', u'B-GPE', u'B-FAC'),\n",
       " (u'angeles', u'L-GPE', 'O'),\n",
       " (u'with', 'O', 'O'),\n",
       " (u'details', 'O', 'O'),\n",
       " (u'on', 'O', 'O'),\n",
       " (u'this', 'O', 'O'),\n",
       " (u'one', 'O', u'U-PER'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'/TURN', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'TURN', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'reporter', 'O', 'O'),\n",
       " (u':', 'O', 'O'),\n",
       " (u'this', 'O', 'O'),\n",
       " (u'is', 'O', 'O'),\n",
       " (u'a', 'O', 'O'),\n",
       " (u'story', 'O', 'O'),\n",
       " (u'that', 'O', 'O'),\n",
       " (u'has', 'O', 'O'),\n",
       " (u'made', 'O', 'O'),\n",
       " (u'the', 'O', 'O'),\n",
       " (u'fbi', u'U-ORG', u'U-ORG'),\n",
       " (u'look', 'O', 'O'),\n",
       " (u'--', 'O', 'O'),\n",
       " (u'well', 'O', 'O'),\n",
       " (u',', 'O', 'O'),\n",
       " (u'kind', 'O', 'O'),\n",
       " (u'of', 'O', 'O'),\n",
       " (u'dopey', 'O', 'O'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'it', 'O', 'O'),\n",
       " (u'has', 'O', 'O'),\n",
       " (u'put', 'O', 'O'),\n",
       " (u'a', 'O', 'O'),\n",
       " (u'spotlight', 'O', 'O'),\n",
       " (u'on', 'O', 'O'),\n",
       " (u'u.s./china', u'U-GPE', 'O'),\n",
       " (u'relations', 'O', 'O'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'like', 'O', 'O'),\n",
       " (u'any', 'O', 'O'),\n",
       " (u'good', 'O', 'O'),\n",
       " (u'spy', u'U-PER', u'U-PER'),\n",
       " (u'movie', 'O', 'O'),\n",
       " (u',', 'O', 'O'),\n",
       " (u'it', 'O', u'U-ORG'),\n",
       " (u\"'s\", 'O', 'O'),\n",
       " (u'already', 'O', 'O'),\n",
       " (u'had', 'O', 'O'),\n",
       " (u'a', 'O', 'O'),\n",
       " (u'sequel', 'O', 'O'),\n",
       " (u'with', 'O', 'O'),\n",
       " (u'the', 'O', 'O'),\n",
       " (u'first', 'O', 'O'),\n",
       " (u'indictment', 'O', 'O'),\n",
       " (u'earlier', 'O', 'O'),\n",
       " (u'in', 'O', 'O'),\n",
       " (u'the', 'O', 'O'),\n",
       " (u'week', 'O', 'O'),\n",
       " (u'and', 'O', 'O'),\n",
       " (u'another', 'O', 'O'),\n",
       " (u'one', 'O', 'O'),\n",
       " (u'just', 'O', 'O'),\n",
       " (u'yesterday', 'O', 'O'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'on', 'O', 'O'),\n",
       " (u'thursday', 'O', 'O'),\n",
       " (u',', 'O', 'O'),\n",
       " (u'the', 'O', 'O'),\n",
       " (u'other', 'O', 'O'),\n",
       " (u'shoe', 'O', 'O'),\n",
       " (u'dropped', 'O', 'O'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'just', 'O', 'O'),\n",
       " (u'one', 'O', 'O'),\n",
       " (u'day', 'O', 'O'),\n",
       " (u'after', 'O', 'O'),\n",
       " (u'a', 'O', 'O'),\n",
       " (u'former', 'O', 'O'),\n",
       " (u'fbi', u'U-ORG', u'B-FAC'),\n",
       " (u'counterintelligence', 'O', u'U-GPE'),\n",
       " (u'agent', u'U-PER', u'U-PER'),\n",
       " (u'was', 'O', 'O'),\n",
       " (u'indicted', 'O', 'O'),\n",
       " (u'on', 'O', 'O'),\n",
       " (u'charges', 'O', 'O'),\n",
       " (u'of', 'O', 'O'),\n",
       " (u'gross', 'O', 'O'),\n",
       " (u'negligence', 'O', 'O'),\n",
       " (u',', 'O', 'O'),\n",
       " (u'his', u'U-PER', u'U-PER'),\n",
       " (u'mistress', u'U-PER', 'O'),\n",
       " (u'of', 'O', 'O'),\n",
       " (u'two', 'O', 'O'),\n",
       " (u'decades', 'O', 'O'),\n",
       " (u',', 'O', 'O'),\n",
       " (u'katrina', u'B-PER', 'O'),\n",
       " (u'leung', u'L-PER', 'O'),\n",
       " (u',', 'O', 'O'),\n",
       " (u'was', 'O', 'O'),\n",
       " (u'herself', u'U-PER', u'U-PER'),\n",
       " (u'indicted', 'O', 'O'),\n",
       " (u'on', 'O', 'O'),\n",
       " (u'more', 'O', 'O'),\n",
       " (u'serious', 'O', 'O'),\n",
       " (u'charges', 'O', 'O'),\n",
       " (u'of', 'O', 'O'),\n",
       " (u'copying', 'O', 'O'),\n",
       " (u'and', 'O', 'O'),\n",
       " (u'possessing', 'O', 'O'),\n",
       " (u'documents', 'O', 'O'),\n",
       " (u'relating', 'O', 'O'),\n",
       " (u'to', 'O', 'O'),\n",
       " (u'the', 'O', 'O'),\n",
       " (u'national', 'O', 'O'),\n",
       " (u'security', 'O', 'O'),\n",
       " (u'of', 'O', 'O'),\n",
       " (u'the', 'O', 'O'),\n",
       " (u'united', u'B-GPE', u'B-GPE'),\n",
       " (u'states', u'L-GPE', u'U-GPE'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'documents', 'O', 'O'),\n",
       " (u'she', u'U-PER', u'U-PER'),\n",
       " (u'allegedly', 'O', 'O'),\n",
       " (u'lifted', 'O', 'O'),\n",
       " (u'on', 'O', 'O'),\n",
       " (u'many', 'O', 'O'),\n",
       " (u'occasions', 'O', 'O'),\n",
       " (u'from', 'O', 'O'),\n",
       " (u'the', 'O', 'O'),\n",
       " (u'briefcase', 'O', 'O'),\n",
       " (u'of', 'O', 'O'),\n",
       " (u'her', u'U-PER', u'U-PER'),\n",
       " (u'ex', 'O', u'U-PER'),\n",
       " (u'-', 'O', u'I-PER'),\n",
       " (u'fbi', u'U-ORG', u'U-ORG'),\n",
       " (u'handler', u'U-PER', u'L-PER'),\n",
       " (u',', 'O', 'O'),\n",
       " (u'james', u'B-PER', u'L-PER'),\n",
       " (u'smith', u'L-PER', u'L-PER'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'leung', u'U-PER', 'O'),\n",
       " (u\"'s\", 'O', 'O'),\n",
       " (u'lawyers', u'U-PER', u'U-PER'),\n",
       " (u'wasted', 'O', 'O'),\n",
       " (u'little', 'O', 'O'),\n",
       " (u'time', 'O', 'O'),\n",
       " (u'responding', 'O', 'O'),\n",
       " (u'to', 'O', 'O'),\n",
       " (u'the', 'O', 'O'),\n",
       " (u'grand', 'O', 'O'),\n",
       " (u'jury', u'U-PER', u'U-PER'),\n",
       " (u'indictment', 'O', 'O'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'/TURN', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'TURN', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'katrina', u'B-PER', 'O'),\n",
       " (u'leung', u'L-PER', 'O'),\n",
       " (u'is', 'O', 'O'),\n",
       " (u'no', 'O', 'O'),\n",
       " (u'matt', u'B-PER', 'O'),\n",
       " (u'aharry', u'L-PER', 'O'),\n",
       " (u',', 'O', 'O'),\n",
       " (u'as', 'O', 'O'),\n",
       " (u'people', u'U-PER', u'U-PER'),\n",
       " (u'have', 'O', 'O'),\n",
       " (u'suggested', 'O', 'O'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'she', u'U-PER', u'U-PER'),\n",
       " (u'was', 'O', 'O'),\n",
       " (u'recruited', 'O', 'O'),\n",
       " (u'actively', 'O', 'O'),\n",
       " (u'by', 'O', 'O'),\n",
       " (u'the', 'O', 'O'),\n",
       " (u'fbi', u'U-ORG', u'U-ORG'),\n",
       " (u'because', 'O', 'O'),\n",
       " (u'of', 'O', 'O'),\n",
       " (u'what', 'O', 'O'),\n",
       " (u'she', u'U-PER', u'U-PER'),\n",
       " (u'could', 'O', 'O'),\n",
       " (u'do', 'O', 'O'),\n",
       " (u'and', 'O', 'O'),\n",
       " (u'because', 'O', 'O'),\n",
       " (u'of', 'O', 'O'),\n",
       " (u'what', 'O', 'O'),\n",
       " (u'she', u'U-PER', u'U-PER'),\n",
       " (u'knew', 'O', 'O'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'she', u'U-PER', u'U-PER'),\n",
       " (u'd', 'O', 'O'),\n",
       " (u'not', 'O', 'O'),\n",
       " (u'go', 'O', 'O'),\n",
       " (u'out', 'O', 'O'),\n",
       " (u'to', 'O', 'O'),\n",
       " (u'get', 'O', 'O'),\n",
       " (u'this', 'O', 'O'),\n",
       " (u'job', 'O', 'O'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'/TURN', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'TURN', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'reporter', 'O', 'O'),\n",
       " (u':', 'O', 'O'),\n",
       " (u'leung', u'U-PER', 'O'),\n",
       " (u',', 'O', 'O'),\n",
       " (u'a', 'O', 'O'),\n",
       " (u'prominent', 'O', u'U-PER'),\n",
       " (u'chinese', u'U-GPE', u'U-GPE'),\n",
       " (u'-', 'O', 'O'),\n",
       " (u'american', u'U-PER', u'U-PER'),\n",
       " (u',', 'O', 'O'),\n",
       " (u'was', 'O', 'O'),\n",
       " (u'practically', 'O', 'O'),\n",
       " (u'the', 'O', 'O'),\n",
       " (u'toast', u'U-PER', 'O'),\n",
       " (u'of', 'O', 'O'),\n",
       " (u'l.a', u'U-GPE', 'O'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'she', u'U-PER', u'U-PER'),\n",
       " (u'was', 'O', 'O'),\n",
       " (u'seemingly', 'O', 'O'),\n",
       " (u'present', 'O', 'O'),\n",
       " (u'for', 'O', 'O'),\n",
       " (u'just', 'O', 'O'),\n",
       " (u'about', 'O', 'O'),\n",
       " (u'every', 'O', 'O'),\n",
       " (u'event', 'O', 'O'),\n",
       " (u'involving', 'O', 'O'),\n",
       " (u'local', 'O', 'O'),\n",
       " (u'politicians', u'U-PER', 'O'),\n",
       " (u',', 'O', 'O'),\n",
       " (u'sometimes', 'O', 'O'),\n",
       " (u'national', 'O', 'O'),\n",
       " (u'ones', u'U-PER', 'O'),\n",
       " (u',', 'O', 'O'),\n",
       " (u'and', 'O', 'O'),\n",
       " (u'various', 'O', 'O'),\n",
       " (u'high', 'O', 'O'),\n",
       " (u'-', 'O', 'O'),\n",
       " (u'ranking', 'O', 'O'),\n",
       " (u'officials', u'U-PER', u'U-PER'),\n",
       " (u'of', 'O', 'O'),\n",
       " (u'the', 'O', 'O'),\n",
       " (u'chinese', u'U-GPE', u'U-GPE'),\n",
       " (u'government', u'U-GPE', u'U-GPE'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'that', 'O', 'O'),\n",
       " (u'part', 'O', 'O'),\n",
       " (u',', 'O', 'O'),\n",
       " (u'at', 'O', 'O'),\n",
       " (u'least', 'O', 'O'),\n",
       " (u',', 'O', 'O'),\n",
       " (u'was', 'O', 'O'),\n",
       " (u'by', 'O', 'O'),\n",
       " (u'design', 'O', 'O'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'leung', u'U-PER', 'O'),\n",
       " (u'was', 'O', 'O'),\n",
       " (u'hired', 'O', 'O'),\n",
       " (u'by', 'O', 'O'),\n",
       " (u'the', 'O', 'O'),\n",
       " (u'fbi', u'U-ORG', u'U-ORG'),\n",
       " (u'and', 'O', 'O'),\n",
       " (u'paid', 'O', 'O'),\n",
       " (u'almost', 'O', 'O'),\n",
       " (u'$', 'O', 'O'),\n",
       " (u'2', 'O', 'O'),\n",
       " (u'million', 'O', 'O'),\n",
       " (u'over', 'O', 'O'),\n",
       " (u'20', 'O', 'O'),\n",
       " (u'years', 'O', 'O'),\n",
       " (u'to', 'O', 'O'),\n",
       " (u'spy', 'O', 'O'),\n",
       " (u'on', 'O', 'O'),\n",
       " (u'the', 'O', 'O'),\n",
       " (u'chinese', u'U-GPE', u'U-GPE'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'federal', 'O', 'O'),\n",
       " (u'prosecutors', u'U-PER', u'U-PER'),\n",
       " (u'now', 'O', 'O'),\n",
       " (u'say', 'O', 'O'),\n",
       " (u'she', u'U-PER', u'U-PER'),\n",
       " (u'pulled', 'O', 'O'),\n",
       " (u'a', 'O', 'O'),\n",
       " (u'fast', 'O', 'O'),\n",
       " (u'one', 'O', u'U-PER'),\n",
       " (u'and', 'O', 'O'),\n",
       " (u'actually', 'O', 'O'),\n",
       " (u'spied', 'O', 'O'),\n",
       " (u'on', 'O', 'O'),\n",
       " (u'the', 'O', 'O'),\n",
       " (u'u.s', u'U-GPE', u'U-GPE'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'for', 'O', 'O'),\n",
       " (u'the', 'O', 'O'),\n",
       " (u'chinese', u'U-GPE', u'U-GPE'),\n",
       " (u'.', 'O', 'O'),\n",
       " (u'this', 'O', 'O'),\n",
       " (u'case', 'O', 'O'),\n",
       " (u'is', 'O', 'O'),\n",
       " (u'a', 'O', 'O'),\n",
       " (u'major', 'O', 'O'),\n",
       " (u'embarrassment', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'/TURN', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'/TEXT', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'/BODY', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'ENDTIME', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'2003', 'O', 'O'),\n",
       " (u'-', 'O', 'O'),\n",
       " (u'05', 'O', 'O'),\n",
       " (u'-', 'O', 'O'),\n",
       " (u'09', 'O', 'O'),\n",
       " (u'11:33:03', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'/ENDTIME', 'O', 'O'),\n",
       " (u'>', 'O', 'O'),\n",
       " (u'<', 'O', 'O'),\n",
       " (u'/DOC', 'O', 'O'),\n",
       " (u'>', 'O', 'O')]"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(x_test[0], y_test[0], model.predict(x_test[:1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
